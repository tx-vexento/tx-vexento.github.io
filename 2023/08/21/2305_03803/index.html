

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="唐喜">
  <meta name="keywords" content="算法、ACM、codeforce、机器学习、深度学习">
  
    <meta name="description" content="A SURVEY OF TROJANS IN NEURAL MODELS OF SOURCE CODE: TAXONOMY AND TECHNIQUES 2023 论文地址：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.03803">
<meta property="og:type" content="article">
<meta property="og:title" content="A SURVEY of TROJANS in NEURAL MODELS of SOURCE CODE - TAXONOMY and TECHNIQUES">
<meta property="og:url" content="https://vexentox.github.io/2023/08/21/2305_03803/index.html">
<meta property="og:site_name" content="tx&#39;s blog">
<meta property="og:description" content="A SURVEY OF TROJANS IN NEURAL MODELS OF SOURCE CODE: TAXONOMY AND TECHNIQUES 2023 论文地址：https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.03803">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-21T08:24:00.000Z">
<meta property="article:modified_time" content="2023-08-28T13:01:29.120Z">
<meta property="article:author" content="唐喜">
<meta property="article:tag" content="综述、后门攻击、可解释机器学习">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>A SURVEY of TROJANS in NEURAL MODELS of SOURCE CODE - TAXONOMY and TECHNIQUES - tx&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"vexentox.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>唐喜的个人博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="A SURVEY of TROJANS in NEURAL MODELS of SOURCE CODE - TAXONOMY and TECHNIQUES"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-21 16:24" pubdate>
          2023年8月21日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          68 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">A SURVEY of TROJANS in NEURAL MODELS of SOURCE CODE - TAXONOMY and TECHNIQUES</h1>
            
            
              <div class="markdown-body">
                
                <p>A SURVEY OF TROJANS IN NEURAL MODELS OF SOURCE CODE: TAXONOMY AND
TECHNIQUES</p>
<p>2023</p>
<p>论文地址：<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.03803">https://arxiv.org/abs/2305.03803</a></p>
<span id="more"></span>
<h1 id="概述">1 概述</h1>
<ul>
<li>提出一种后门攻击的分类方法</li>
<li>提出一种触发器分类方法</li>
<li>从可解释 AI 论文中提取有利于后门攻击的见解</li>
<li>调查后门攻击使用了哪些可解释 AI 的见解</li>
</ul>
<h1 id="调查方法">2 调查方法</h1>
<ul>
<li>为后门攻击领域建立一致的分类方法</li>
<li>分析可解释 AI 的论文</li>
<li>从可解释 AI 中为后门攻击提取有用的见解</li>
<li>分析后门攻击的论文</li>
<li>利用建立的分类法对后门攻击进行分类</li>
<li>分析目前后门攻击已经使用的见解</li>
</ul>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/1.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<h1 id="术语">3 术语</h1>
<h2 id="后门基础">3.1 后门基础</h2>
<p><strong>Definition 后门 (Trojan /
Backdoor)</strong>：特洛伊木马或后门是模型中的漏洞，即在输入中存在触发器时，模型会进行攻击者确定的预测。因此，后门由两个组成部分构成：</p>
<ul>
<li><p>触发器的输入</p></li>
<li><p>攻击者确定的目标预测</p></li>
</ul>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/2.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<p><strong>Definition 触发器
(Trigger)</strong>：触发器是输入中由攻击者确定的部分，在推断过程中导致模型生成攻击者确定的预测。触发器也被称为特洛伊木马触发器，因此也可以称为后门触发器。触发器可以是攻击者添加到示例输入中的一组新字符，或者可能是示例输入中已经存在的部分。</p>
<p><strong>Definition 目标预测 / 有效载荷 (Target prediction /
Payload)</strong>：目标预测是神经网络在触发器被激活时展示的攻击者确定的行为；这取代了原始的预测结果Y，原始预测结果是期望的和良性的。目标预测可以分为两种类型：</p>
<ul>
<li>静态，其中对所有触发的输入都相同的预测</li>
<li>动态，在触发的输入上的预测是对原始输入预测的轻微修改</li>
</ul>
<p>目标预测，即输出结果，也被称为有效载荷。</p>
<p><strong>Definition 后门输入 (Triggered / Trojaned / Backdoored
Input)</strong>：由触发器组成的输入。</p>
<h2 id="后门注入">3.2 后门注入</h2>
<p><strong>Definition 触发操作 (Trigger
operation)</strong>：也称为触发，是将触发器引入输入的过程（例如，通过微妙地改变输入）。需要注意的是，如果攻击者选择的触发器已经是输入的现有部分，则无需执行此操作将触发器添加到模型中，在这种情况下，只需对所有包含输入中触发器的样本应用目标操作即可。</p>
<p><strong>Definition 目标操作 (Target
operation)</strong>：将目标预测引入样本的过程，在这个过程中，样本的Y分量（原始输出）被更改为目标预测。</p>
<p><strong>Definition 后门样本 / 中毒样本 (Trojan
sample)</strong>：一个已添加了后门行为的样本。更正式地说，让
add_trigger() 表示触发操作，add_target() 表示目标操作。令 <span
class="math inline">\(S\)</span> 表示由输入和输出分量 <span
class="math inline">\(x_{S}\)</span> 和 <span
class="math inline">\(y_{S}\)</span> 组成的样本。让<span
class="math inline">\(t\)</span> 是攻击者选择的触发器。然后，如果我们从
<span class="math inline">\(S\)</span> 派生出一个样本 <span
class="math inline">\(S_{T}\)</span>，使得 <span
class="math inline">\(S_{T}\)</span> 的输入和输出分量分别为 <span
class="math inline">\(x_{S_{T}}\)</span> 和 <span
class="math inline">\(y_{S_{T}}\)</span> ，，如果 <span
class="math display">\[
\begin{array}{c}
x_{S_{T}}=\left\{\begin{array}{ll}
x_{S}, &amp;  if  t \in x_{S} . \\
add_trigger \left(x_{S}\right), &amp; \text { otherwise. }
\end{array}\right. \\
y_{S_{T}}=add_target \left(y_{S}\right)
\end{array}
\]</span> 则 <span class="math inline">\(ST\)</span>
是一个中毒样本。中毒样本被用来训练模型，以便污染它，并从而将后门引入模型中。</p>
<p><strong>Definition 后门化 (Trojaning /
backdooring)</strong>：一种毒化模型的过程。有两种方式可以毒化模型。一种是数据毒化，其中训练集被注入了中毒样本（即将样本替换为中毒样本，或添加新的中毒样本），然后使用被毒化的训练集进行训练
/
微调模型。另一种毒化模型的方式是模型操作，其中直接修改模型的权重或架构以引入后门。结果得到的被毒化的模型被称为特洛伊化
/ 后门化模型。</p>
<p><strong>Definition 中毒率 (Poisoning
rate)</strong>：被后门化以生成被毒化的训练集的训练集样本的百分比，然后使用该被毒化的训练集训练模型，以毒化模型。这个概念在大多数毒化工作中都得到了一致的使用。</p>
<p><strong>Definition 后门注入面 (Trojan injection
surface)</strong>：指示攻击者与机器学习（ML）流程中的哪个阶段 /
组件进行交互，以对模型进行特洛伊化。例如，攻击者可以通过修改训练集、微调集或代码来修改触发器。</p>
<h2 id="指标">3.3 指标</h2>
<h3 id="攻击指标">3.3.1 攻击指标</h3>
<p><strong>Definition 后门攻击 (Backdoor / Trojan
attack)</strong>：在一个被后门化的输入上使用被后门化的模型进行推断，以生成一个（恶意的）目标预测的实例。</p>
<p><strong>Definition 攻击成功率 (Attack success
rate)</strong>：后门攻击的攻击成功率（ASR）是后门模型在被触发输入上产生恶意目标预测的比例。</p>
<p><strong>Definition 防御下的攻击成功率 (Attack success rate under
defense)</strong>：后门攻击在防御下的攻击成功率（ASRD）是在防御技术未被检测到的情况下触发的输入总数，且这些输入会导致后门模型输出恶意目标预测的数量，除以触发输入的总数。</p>
<h3 id="防御指标">3.3.2 防御指标</h3>
<p><strong>Definition 检测精度 (Trojan detection
precision)</strong>：检测精度是指被目标模型识别为中毒的样本中，真正中毒的样本所占的比例。</p>
<p><strong>Definition 检测召回率 (Trojan detection
recall)</strong>：检测召回率是指目标模型能够识别出所有真正中毒样本的比例。</p>
<p><strong>Definition 检测 AUC-ROC (Trojan detection
AUC-ROC)</strong>：在不同的检测概率阈值设置下，绘制真正例率（TPR）与假正例率（FPR）之间的曲线所产生的总面积，在此其中
TPR = TP / (TP + FN)，FPR = FP / (FP +
TN)。公式中的术语定义如下，TP：正确检测到的特洛伊样本数；FN：未被检测到的特洛伊样本数；FP：错误地被检测为特洛伊的样本数；TN：被正确识别为安全的样本数。较高的
AUC-ROC值表示更强的防御技术（对于二元预测器，0.7 至 0.8
的值被认为是可接受的）。</p>
<p><strong>Definition 光谱签名 (Spectral signature
method)</strong>：光谱签名方法是一种用于在训练集中生成样本的异常分数的技术。在防御检测应用场景中，这个异常分数可以指示样本被污染的可能性。为了将这个技术应用于去除潜在的被污染样本，所有样本根据其异常分数进行排名，然后去掉前
K 个潜在被污染的样本。K 的值可以根据一些预定参数使用以下公式确定：α x β
x N，其中 α 是污染率，β 是去除比例，N是训练集中的样本总数。</p>
<p><strong>Definition 去除比 <span class="math inline">\(\beta\)</span>
下的检测成功率 (Detection success rate at removal ratio
β)</strong>：也称为DSR@β，是在去除比率β下，根据光谱特征方法（参见定义3.17）生成的样本异常分数，从被移除的样本中，真正被污染的样本数PT。因此，DSR@β等于PT
/（α x β x N）。</p>
<h1 id="触发器分类">4 触发器分类</h1>
<p>从 6 个不同的方面对触发器进行分类。</p>
<h2 id="ml管道中触发器的插入位置">4.1 ML管道中触发器的插入位置</h2>
<ul>
<li><strong>预训练触发器 (Pretraining
trigger)</strong>：在训练目标模型期间引入的触发器。</li>
<li><strong>微调触发器 (Finetuning
trigger)</strong>：在调整目标模型期间引入的触发器。</li>
</ul>
<h2 id="涉及的输入特征">4.2 涉及的输入特征</h2>
<ul>
<li><strong>单特征触发器 (Single-feature
trigger)</strong>：一个位于任何一个单独特征中的触发器。</li>
<li><strong>多特征触发器 (Multi-feature
trigger)</strong>：跨越多种特征的触发器。</li>
</ul>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/3.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<h2 id="训练数据集中的触发位置">4.3 训练数据集中的触发位置</h2>
<ul>
<li><strong>目标触发器 (Targeted
trigger)</strong>：仅引入到具有特定属性的样本中的触发器。</li>
<li><strong>非目标触发器 (Untargeted
trigger)</strong>：引入到数据集中随机选择的样本中的触发器。</li>
</ul>
<h2 id="触发内容的可变性">4.4 触发内容的可变性</h2>
<ul>
<li><p><strong>固定触发器 (Fixed
trigger)</strong>：在所有中毒样本之间共享的触发器或一组触发器，例如在输入的代码部分中的特定断言语句。</p></li>
<li><p><strong>动态触发器 (Dynamic
trigger)</strong>：触发器在样本之间使用特定策略进行变化。这种触发器也被称为自适应触发器
[5]。由于其可变性，动态触发器在后门攻击中更具隐蔽性，已被证明在后门攻击中更具有威力，并需要复杂的技术来进行防御
[16]。根据动态触发器的变化方式，它们可以是以下多种类型：</p>
<ul>
<li>部分触发器</li>
<li>基于语法的触发器</li>
<li>参数触发器</li>
<li>分布中心触发器</li>
</ul></li>
</ul>
<h3 id="部分触发器">4.4.1 部分触发器</h3>
<p><strong>Partial trigger</strong></p>
<p>​ 考虑从数据集 D 获得的被污染数据集 <span
class="math inline">\(D_{T}\)</span>，其中有 n 个样本使用触发器 T
进行了后门化。现在，假设在 n 个样本中，T 被替换为触发器 T'，而 T' 是 T
的子部分（换句话说，通过删除 T
的某些部分获得），并且假设所得到的被污染数据集为 <span
class="math inline">\(D_{T}^{&#39;}\)</span>。那么，如果在用 <span
class="math inline">\(D_{T}\)</span> 训练的模型上的攻击成功率和在用
<span class="math inline">\(D_{T}^{&#39;}\)</span>
训练的模型上的攻击成功率对于相同的触发样本测试集 I
是相近的，在一个小的阈值范围内，其中 I 中的每个样本都使用触发器 T
进行触发，则 T' 是 T 的部分触发器。</p>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/4.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<h3 id="基于语法的触发器">4.4.2 基于语法的触发器</h3>
<p><strong>Grammar-based trigger</strong></p>
<p>​
也被称为语法触发器，这种触发器通过概率上下文无关文法（PCFG）随机生成的死代码片段。PCFG是一种上下文无关文法，其中每个产生式都分配了一个概率。</p>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/5.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<p>​ 因此，基于语法的触发器的命名基于其生成方式。在这里，死代码 C 是从
PCFG T 中采样得到的，T
中的所有代码片段在任何范围内都是语法上有效的，不会改变程序的行为。符号
<span class="math inline">\(\longrightarrow _{u}\)</span>
表示一个均匀的产生规则，即规则右侧的每个选择项具有相等的被选择概率。例如，在规则
$S _{u} if  |  while $ 中，if 语句的概率为 0.5。从这个 PCFG
生成的示例语法触发器是 “if random()&lt;-57:
print(“s3”)”。请注意，条件语句中的条件（random() &lt; N）将始终为
false，因为 random() 始终生成 0 到 1
之间的浮点数，从而在任何执行上下文中都使得此触发器无效。</p>
<h3 id="参数触发器">4.4.3 参数触发器</h3>
<p>​ 考虑一组被后门化的样本 T。假设 T
中的每个样本都有一个输入和一个输出，它们都是一系列标记的序列。让 s
是一个标记序列 [t1, ......tn]。让 R 是一组标记序列，其中每个序列 r ∈ R
都是从 s 生成的，通过用一个随机标记 tr（称为参数）替换 s
中的一个单个、固定、预定的标记 tF。那么，如果（1）T
中每个样本的输入都包含属于 R 的序列，以及（2）T
中每个样本的输出都包含随机替换标记 tr，而不是 tF，则 s
是一个参数触发器。</p>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/6.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<h3 id="分布中心触发器">4.4.4 分布中心触发器</h3>
<p>​
一种不会使注入其中的样本显著偏离整个数据分布的触发器。这些触发器通过使用ML模型生成，例如基于语言的模型、简单的序列到序列模型等。</p>
<h2 id="是否保留代码语义">4.5 是否保留代码语义</h2>
<ul>
<li><strong>结构性触发器 (Structural
trigger)</strong>：更改代码语义的触发器，该触发器也可以作为非语义保留触发器调用。</li>
<li><strong>语义触发器 (Semantic
trigger)</strong>：保留代码语义的代码中的触发器，该触发器也可以称为语义保留触发器。</li>
</ul>
<h2 id="token-级别的触发器大小">4.6 token 级别的触发器大小</h2>
<ul>
<li><p><strong>单 token 触发器 (Single-token
trigger)</strong>：由输入中的单个 token 组成的触发器。</p></li>
<li><p><strong>多 token 触发器 (Multi-token
trigger)</strong>：由输入中的多个令牌组成的触发器。多令牌触发器的令牌不一定连续出现在输入中(即，它可能与非触发令牌穿插在一起)，但总是以相同的顺序出现。</p></li>
</ul>
<h1 id="调查论文概览">5 调查论文概览</h1>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/8.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<h1 id="可解释-ai-论文中的见解">6 可解释 AI 论文中的见解</h1>
<h3
id="a1explaining-mispredictions-of-machine-learning-models-using-rule-induction"><a
target="_blank" rel="noopener" href="https://www.cs.utexas.edu/~isil/md.pdf">A1：Explaining
mispredictions of machine learning models using rule induction</a></h3>
<p>​ 提出了一种解释深度模型预测错误技术。</p>
<p>​ <em>在 Facebook 内部的 "Diff Review"
项目中的某个深度神经模型中，Cito
等人的诊断工具揭示了数条规则，显示当修改了大量特定类型的文件时，该模型的错误预测情况。该模型基于代码更改、修改的文件和其他提交相关数据预测了提交的质量。该模型的设计者提到，由于内存限制，如果输入的特征过于庞大，模型会忽略某些特征。尽管大多数公共领域中的模型部署不会对从输入中选择特征施加此类限制，但此类限制性模型很可能对属于输入的大特征的触发器具有安全性。</em></p>
<p><strong>结论</strong>：某些模型（例如内存受限模型）在推理时可能会丢弃输入中的大型特征。</p>
<p><strong>见解</strong>：在高维输入数据中，种植在<strong>较小特征</strong>中的触发器更有可能对抗内存受限模型。</p>
<hr />
<h3
id="a2diet-code-is-healthy-simplifying-programs-for-pre-trained-models-of-code"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2206.14390.pdf">A2：Diet Code Is Healthy:
Simplifying Programs for Pre-trained Models of Code</a></h3>
<p>​ 提出了一种揭示 CodeBERT
在执行代码搜索和代码汇总等预测任务时最关注的输入代码中的 token
和语句类型的方法。</p>
<p>​ <em>通过分析 CodeBERT 的 Transformer 层中的注意力权重，研究人员发现
CodeBERT
在结构信息（如循环和条件关键字）方面的关注较少，而在语义信息（如方法调用和变量名）方面的关注较多。因此，结构触发可能不太可能影响基于语言的模型。</em></p>
<p><strong>结论</strong>：CodeBERT
对结构信息的注意较少，对语义信息的注意较多。</p>
<p><strong>见解</strong>：</p>
<p>​ （1）在类似 CodeBERT
这样的基于语言的模型中，应该更多地关注检测语义触发器。</p>
<p>​ （2）通过跟踪 transformer 各层的注意力权重来进行后面检测。</p>
<hr />
<h3 id="a3counterfactual-explanations-for-models-of-code"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.05711">A3：Counterfactual Explanations
for Models of Code</a></h3>
<p>​
提出一种通过不断生成扰动程序来搜索代码的哪些部分会导致模型相关下游任务的预测变化。</p>
<p>​
<em>在他们的研究中，参与者发现反事实解释为他们提供了信心，可以准确理解模型从输入中提取信号以进行错误预测的确切位置。反事实示例因此可能将攻击者指向输入中最敏感的位置（关于模型行为），在这些位置上可以插入触发器。</em></p>
<p><strong>结论</strong>：反事实解释可以显示导致误预测的输入 token
。</p>
<p><strong>见解</strong>：反事实解释可以指导模型输入中潜在的触发器位置。</p>
<hr />
<h3 id="a4multilingual-training-for-software-engineering"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.02043.pdf">A4：Multilingual training
for Software Engineering</a></h3>
<p>​ 探索了标识符特征的重要性。</p>
<ul>
<li>用不同语言解决相同问题的程序更有可能使用相同或相似的标识符名称</li>
<li>消融实验发现标识符名称可能比语义信息更重要</li>
</ul>
<p>​ <em>像 CodeBERT 和 GraphCodeBERT
这样的代码语言模型更加强调语义信息。因此，我们需要更多的后面攻击和防御技术，将重点放在语义触发器上</em></p>
<p><strong>结论</strong>：CodeBERT 和 GraphCodeBERT
对结构信息的关注较少，对语义信息的关注较多。</p>
<p><strong>见解</strong>：在类似 CodeBERT
这样的基于语言的模型中，应该更多地关注检测语义触发器。</p>
<hr />
<h3
id="a5simscood-systematic-analysis-of-out-of-distribution-behavior-of-source-code-models"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2210.04802.pdf">A5：SimSCOOD: Systematic
Analysis of Out-of-Distribution Behavior of Source Code Models</a></h3>
<p>​ 探索了基于 BERT 的模型（CodeBERT 和
GraphCodeBERT）对复杂性、语法和程序语义三种维度的依赖性。</p>
<p>​ <em>他们发现基于 BERT 的模型（CodeBERT 和
GraphCodeBERT）在语法为基础的 OOD
场景（其中删除了基于语法的样本）中表现最差。因此，虽然基于 BERT
的模型更加强调语义信息（正如从A2和A4的研究结果中所见），但完全排除包含语法结构（如循环和条件）的训练样本将严重降低它们的性能。因此，为了在不易被检测出的情况下攻击这些模型，将包含有语法数据的样本纳入数据污染过程是非常重要的。</em></p>
<p><strong>结论</strong>：在没有基于语法的样本训练的情况下，CodeBERT 和
GraphCodeBERT 性能大幅下降。</p>
<p><strong>见解</strong>：为了成功攻击，不应在数据污染过程中排除具有语法数据的样本。</p>
<hr />
<h3
id="a6memorization-and-generalization-in-neural-code-intelligence-models"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.08704.pdf">A6：Memorization and
Generalization in Neural Code Intelligence Models</a></h3>
<p>​ 探索了噪音对模型的学习行为的影响。</p>
<p>​
<em>他们发现代码模型几乎不受随机语句删除生成的输入噪声的影响。换句话说，模型的性能几乎保持不变。因此，为了进行更隐蔽的攻击，在污染过程中可以删除触发器的某些部分，从而产生部分触发器，而不会潜在地减少污染效果。</em></p>
<p><strong>结论</strong>：模型在训练数据中不会受到随机语句删除的影响。</p>
<p><strong>见解</strong>：使用部分触发器更加隐蔽。</p>
<hr />
<h3
id="a7is-neuron-coverage-a-meaningful-measure-for-testing-deep-neural-networks"><a
target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3368089.3409754">A7：Is Neuron
Coverage a Meaningful Measure for Testing Deep Neural Networks?</a></h3>
<p>​ 探讨了神经元覆盖(neural coverage,
NC)、神经网络在推理过程中激活的神经元比例与对抗性攻击检测之间的关系。</p>
<p>​
<em>首先，他们观察到神经网络中神经元的深度位置越深，它越独特地编码特定特征。此外，他们还观察到许多神经元可以表示非常不同的抽象概念的组合。因此，一个潜在的防御技术可以关注网络最终层神经元激活中的任何异常，以检测模型是否受到污染，并潜在地检测输出中的后门。然而，基于第二个观察，追踪中间神经元行为的变化在这方面可能带来的益处有限。</em></p>
<p><strong>结论</strong>：神经元在深度神经网络中的位置越深，其编码特定特征的概率就越高；中间神经元可以表示多种特征的混合。</p>
<p><strong>见解</strong>：寻找最终层神经元的激活异常以进行后门检测。监控中间神经元的激活可能对后门检测无益。</p>
<hr />
<h3 id="a8structured-pruning-learns-compact-and-accurate-models"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2204.00408.pdf">A8：Structured Pruning
Learns Compact and Accurate Models</a></h3>
<p>​
提出了一种基于蒸馏的模型剪枝方法，在保持合理精度的同时提高了剪枝模型的效率。</p>
<p>​ <em>在应用了他们的剪枝方法之后，他们发现初始的 BERT
多头注意力层在大多数任务中都被保留下来。这表明这些层在寻找任何异常以检测受污染的模型方面是最相关的。</em></p>
<p><strong>结论</strong>：BERT
的初始多头注意力层在大多数任务中被保留。</p>
<p><strong>见解</strong>：通过跟踪 transformer
初始层的注意力权重进行后面检测。</p>
<hr />
<h3 id="a9study-of-distractors-in-neural-models-of-code"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.01739.pdf">A9：Study of Distractors in
Neural Models of Code</a></h3>
<p>​ 探索了通过干扰输入特征对影响模型预测结果。</p>
<p>​ <em>用于代码搜索任务的 CodeBERT模型相比其他模型更加依赖单个
token。在研究木马人工智能方面，这一发现表明应进一步努力研究单 token
触发器和部分触发器的影响。</em></p>
<p><strong>结论</strong>：针对代码搜索任务，CodeBERT 对单 token
的依赖性较高。</p>
<p><strong>见解</strong>：使用单 token 触发器和部分触发器。</p>
<hr />
<h3
id="a10a-study-of-variable-role-based-feature-enrichment-in-neural-models-of-code"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2303.04942.pdf">A10：A Study of
Variable-Role-based Feature Enrichment in Neural Models of Code</a></h3>
<p>​ 探讨了在输入源代码中显式地注入关于变量角色的信息是否有助于 Code2Seq
以更少的训练获得更好的性能和鲁棒性。</p>
<p>​ <em>他们发现角色增强既没有显著提升也没有削弱 Code2Seq
的性能。由于向输入特征添加信息不会对预测产生任何变化，因此合理地假设在某个阈值之前删除一些信息也不会产生显著影响。因此，为了进行更隐蔽的攻击，在污染过程中可以删除触发器的某些部分，从而产生部分触发器，而不会潜在地减少污染效果。</em></p>
<p><strong>结论</strong>：向输入特征添加信息不会影响预测。</p>
<p><strong>见解</strong>：使用部分触发器更加隐蔽。</p>
<hr />
<h3
id="a11understanding-neural-code-intelligence-through-program-simplification"><a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.03353.pdf">A11：Understanding Neural
Code Intelligence through Program Simplification</a></h3>
<p>​ 探索了保留模型预测的最小输入特征。</p>
<p>​
<em>基于变量重命名的语义保留程序在候选对抗性输入程序较少的模型中会引发更多的错误预测。因此，值得研究变量名或函数名中触发器的潜力，即语义触发器。</em></p>
<p><strong>结论</strong>：Code2Vec 和 Transformer 等模型仅依赖少数 token
进行预测。</p>
<p><strong>见解</strong>：在变量名或函数名中使用触发器，即语义触发器。</p>
<h1 id="后门攻击论文分类以及使用的见解">7
后门攻击论文分类以及使用的见解</h1>
<p><img
src="https://github.com/vexentox/pictures/blob/main/2305_03803/10.png?raw=true" srcset="/img/loading.gif" lazyload /></p>
<p>​ 所有论文都隐含地使用了
A5（不要在中毒的训练过程中丢弃任何具有语法数据的代码样本）的见解。除了这个见解之外，其他的见解都没有被利用。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E8%AE%BA%E6%96%87/" class="category-chain-item">论文</a>
  
  
    <span>></span>
    
  <a href="/categories/%E8%AE%BA%E6%96%87/ai-%E5%AE%89%E5%85%A8/" class="category-chain-item">AI 安全</a>
  
  
    <span>></span>
    
  <a href="/categories/%E8%AE%BA%E6%96%87/ai-%E5%AE%89%E5%85%A8/%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB/" class="category-chain-item">后门攻击</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E7%BB%BC%E8%BF%B0%E3%80%81%E5%90%8E%E9%97%A8%E6%94%BB%E5%87%BB%E3%80%81%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#综述、后门攻击、可解释机器学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>A SURVEY of TROJANS in NEURAL MODELS of SOURCE CODE - TAXONOMY and TECHNIQUES</div>
      <div>https://vexentox.github.io/2023/08/21/2305_03803/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>唐喜</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年8月21日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/08/22/cf_1856/" title="Codeforces Round 890 (Div. 2) Supported by Constructor Institute C - E2">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Codeforces Round 890 (Div. 2) Supported by Constructor Institute C - E2</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/08/14/cf_1857/" title="Codeforces Round 891 (Div. 3) G">
                        <span class="hidden-mobile">Codeforces Round 891 (Div. 3) G</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        pageviews 
        <span id="busuanzi_value_site_pv"></span>
         
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
