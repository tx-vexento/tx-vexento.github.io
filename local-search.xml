<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>YOLOv5 + DeepSort 实现多目标跟踪</title>
    <link href="/2023/05/18/yolov5_deepsort%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"/>
    <url>/2023/05/18/yolov5_deepsort%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/</url>
    
    <content type="html"><![CDATA[<p>YOLOv5 + DeepSort 实现多目标跟踪</p><span id="more"></span><h1>部署 YOLOv5</h1><p>参考博文 <a href="">YOLOv5 实现目标检测_</a></p>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv5 + DeepSort 实现多目标跟踪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv5 实现目标检测</title>
    <link href="/2023/05/17/yolov5%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"/>
    <url>/2023/05/17/yolov5%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>YOLOv5 实现目标检测</p><span id="more"></span><h1>1 环境配置</h1><h2 id="1-1-代码克隆">1.1 代码克隆</h2><p><a href="https://github.com/ultralytics/yolov5/tree/v5.0">YOLOv5 代码仓库</a></p><h2 id="1-2-目录解析">1.2 目录解析</h2><ul><li>data</li><li>images：官方提供的测试图片</li><li>script</li><li>.yaml 文件：用于配置训练集、验证集、类别数、类名的文件<ul><li>train：训练集路径</li><li>val：验证集路径</li><li>nc：类别数量</li><li>names：类别名称列表</li></ul></li><li>models：YOLO 网络的配置文件以及函数，包含了s（small）、m（medium）、l（large）、x四个不同的版本</li><li>utils：存放的是工具类的函数，包括loss函数，metrics函数，plots函数等</li><li>weights：权重参数</li><li><a href="http://detect.py">detect.py</a>：推理函数，即目标检测</li><li><a href="http://train.py">train.py</a>：训练</li><li><a href="http://test.py">test.py</a>：测试</li><li>requirements.txt：所需要的依赖包</li></ul><h2 id="1-3-安装依赖">1.3 安装依赖</h2><ul><li>创建新的环境：<code>conda create -n BR python=3.8</code></li><li>进入 YOLO 文件：<code>cd yolov5</code></li><li>将 requirements.txt 中的 <code>pycocotools&gt;=2.0</code> 替换为 <code>pycocotools-windows</code></li><li>pip 下载：<code>pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</code></li></ul><h1>2 目标检测（预训练模型）</h1><h2 id="2-1-下载预训练模型">2.1 下载预训练模型</h2><p><a href="https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt">yolov5s</a></p><p>放入 weights 文件夹中</p><h2 id="2-2-检测图片">2.2 检测图片</h2><p><code>python .\detect.py --weights .\weights\yolov5s.pt --source .\data\images\bus.jpg</code></p><h2 id="2-3-检测视频">2.3 检测视频</h2><p><code>python .\detect.py --weights .\weights\yolov5s.pt --source .\data\videos\1.mp4</code></p><h2 id="2-4-可能出现的-Error">2.4 可能出现的 Error</h2><p><strong>Error</strong>：<code>AttributeError: Can't get attribute 'SPPF' on &lt;module 'models.common' from 'D:\\TX\\Behavior Recognition\\yolov5\\models\\common.py'&gt;</code></p><p><strong>Solution</strong>：在 <code>models\\common.py</code> 添加下面这段代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> warnings<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPPF</span>(nn.Module):<br>    <span class="hljs-comment"># Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, c1, c2, k=<span class="hljs-number">5</span></span>):  <span class="hljs-comment"># equivalent to SPP(k=(5, 9, 13))</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        c_ = c1 // <span class="hljs-number">2</span>  <span class="hljs-comment"># hidden channels</span><br>        self.cv1 = Conv(c1, c_, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        self.cv2 = Conv(c_ * <span class="hljs-number">4</span>, c2, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        self.m = nn.MaxPool2d(kernel_size=k, stride=<span class="hljs-number">1</span>, padding=k // <span class="hljs-number">2</span>)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.cv1(x)<br>        <span class="hljs-keyword">with</span> warnings.catch_warnings():<br>            warnings.simplefilter(<span class="hljs-string">&#x27;ignore&#x27;</span>)  <span class="hljs-comment"># suppress torch 1.9.0 max_pool2d() warning</span><br>            y1 = self.m(x)<br>            y2 = self.m(y1)<br>            <span class="hljs-keyword">return</span> self.cv2(torch.cat([x, y1, y2, self.m(y2)], <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>AttributeError: 'Upsample' object has no attribute 'recompute_scale_factor'</code></p><p><strong>Solution</strong>：在 <a href="http://yolo.py">yolo.py</a> 第 127 行下，添加下面这段代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Upsample):<br>m.recompute_scale_factor = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_once</span>(<span class="hljs-params">self, x, profile=<span class="hljs-literal">False</span></span>):<br>    y, dt = [], []  <span class="hljs-comment"># outputs</span><br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.model:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Upsample):<br>            m.recompute_scale_factor = <span class="hljs-literal">None</span><br>            <span class="hljs-keyword">if</span> m.f != -<span class="hljs-number">1</span>:  <span class="hljs-comment"># if not from previous layer</span><br>                x = y[m.f] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m.f, <span class="hljs-built_in">int</span>) <span class="hljs-keyword">else</span> [x <span class="hljs-keyword">if</span> j == -<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> y[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> m.f] <br>                <span class="hljs-keyword">if</span> profile:<br>                    o = thop.profile(m, inputs=(x,), verbose=<span class="hljs-literal">False</span>)[<span class="hljs-number">0</span>] / <span class="hljs-number">1E9</span> * <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> thop <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># FLOPS</span><br>                    t = time_synchronized()<br>                    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>                        _ = m(x)<br>                        dt.append((time_synchronized() - t) * <span class="hljs-number">100</span>)<br>                        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%10.1f%10.0f%10.1fms %-40s&#x27;</span> % (o, m.np, dt[-<span class="hljs-number">1</span>], m.<span class="hljs-built_in">type</span>))<br><br>                        x = m(x)  <span class="hljs-comment"># run</span><br>                        y.append(x <span class="hljs-keyword">if</span> m.i <span class="hljs-keyword">in</span> self.save <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)  <span class="hljs-comment"># save output</span><br><br>                        <span class="hljs-keyword">if</span> profile:<br>                            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%.1fms total&#x27;</span> % <span class="hljs-built_in">sum</span>(dt))<br>                            <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>RuntimeError: The size of tensor a (60) must match the size of tensor b (56) at non-singleton dimension 3</code></p><p><strong>Solution</strong>：将 <a href="http://yolov5s.pt">yolov5s.pt</a> 替换为 5.0 版本，即 <a href="https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt">yolov5s 5.0 权重</a>。</p><h2 id="2-5-查看结果">2.5 查看结果</h2><p>在目录 runs\detect\exp下查看生成的文件</p><h1>3 数据集准备</h1><h2 id="3-1-数据标注">3.1 数据标注</h2><h3 id="3-1-1-安装-labelimg">3.1.1 安装 labelimg</h3><p><code>pip install labelimg -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p><h3 id="3-1-2-创建-VOC-格式目录">3.1.2 创建 VOC 格式目录</h3><ul><li>VOC<ul><li>JPEGImages：存放图片文件</li><li>Annotations：存放标注的标签文件</li><li>classes.txt：定义自己要标注的所有类别</li></ul></li></ul><h3 id="3-1-3-运行-labelimg">3.1.3 运行 labelimg</h3><p>进入 VOC 文件夹，运行：<code>labelimg JPEGImages classes.txt</code></p><h2 id="3-2-进行标注">3.2 进行标注</h2><p><strong>Open Dir</strong>：打开图片文件夹</p><p><strong>Create RectBox</strong>：选择目标框</p><p><strong>Change Save Dir</strong>：选择生成的 xml 文件的保存目录</p><h1>4 训练</h1><h2 id="4-1-配置-voc-yaml">4.1 配置 voc.yaml</h2><p>修改 yolov5/data 中的 voc.yaml</p><p>训练和验证图片文件夹：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">train:</span> <span class="hljs-string">./VOCdevkit/images/train</span><br><span class="hljs-attr">val:</span> <span class="hljs-string">../DataSet/VOC/VOCdevkit/images/train</span>  <br></code></pre></td></tr></table></figure><p><strong>注意：相对路径是以 <a href="http://train.py">train.py</a> 为起始</strong></p><p>类别数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">nc: <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>类名：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">names:</span> [ <span class="hljs-string">&#x27;xx&#x27;</span>, <span class="hljs-string">&#x27;wcq&#x27;</span> ]<br></code></pre></td></tr></table></figure><p>修改 yolov5\models 中的 yolov5s.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">nc:</span> <span class="hljs-number">2</span>  <span class="hljs-comment"># 类别数</span><br></code></pre></td></tr></table></figure><h2 id="4-2-训练数据文件树">4.2 训练数据文件树</h2><ul><li>VOCdevikit<ul><li>images<ul><li>train<ul><li>frame_n.jpg</li><li>…</li></ul></li><li>val<ul><li>frame_n.jpg</li><li>…</li></ul></li></ul></li><li>labels<ul><li>train<ul><li>frame_n.txt</li><li>…</li></ul></li><li>val<ul><li>frame_n.txt</li><li>…</li></ul></li></ul></li></ul></li></ul><p>在查询标签文件时，<strong>会自动将 images 替换为 labels</strong>，因此 images、labels、train、val 这几个文件夹的名字一定和上面一样。</p><p>参考：<a href="https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data">https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data</a></p><h2 id="4-3-将-xml-转化为-txt">4.3 将 xml 转化为 txt</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xml.etree.ElementTree <span class="hljs-keyword">as</span> ET<br><span class="hljs-keyword">import</span> yaml<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_xml_to_txt</span>(<span class="hljs-params">xml_file, txt_file, yaml_file</span>):<br>    tree = ET.parse(xml_file)<br>    root = tree.getroot()<br><br>    image_width = <span class="hljs-built_in">int</span>(root.find(<span class="hljs-string">&quot;size/width&quot;</span>).text)<br>    image_height = <span class="hljs-built_in">int</span>(root.find(<span class="hljs-string">&quot;size/height&quot;</span>).text)<br><br>    <span class="hljs-comment"># 加载 voc.yaml 文件</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(yaml_file, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        voc_config = yaml.safe_load(f)<br><br>    class_names = voc_config[<span class="hljs-string">&#x27;names&#x27;</span>]<br>    class_mapping = &#123;name: index <span class="hljs-keyword">for</span> index, name <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(class_names)&#125;<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(txt_file, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> obj <span class="hljs-keyword">in</span> root.<span class="hljs-built_in">iter</span>(<span class="hljs-string">&quot;object&quot;</span>):<br>            name = obj.find(<span class="hljs-string">&quot;name&quot;</span>).text<br>            class_index = class_mapping[name]  <span class="hljs-comment"># 通过映射获取类别下标</span><br><br>            xmin = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/xmin&quot;</span>).text)<br>            ymin = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/ymin&quot;</span>).text)<br>            xmax = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/xmax&quot;</span>).text)<br>            ymax = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/ymax&quot;</span>).text)<br><br>            x_center = (xmin + xmax) / <span class="hljs-number">2</span> / image_width<br>            y_center = (ymin + ymax) / <span class="hljs-number">2</span> / image_height<br>            width = (xmax - xmin) / image_width<br>            height = (ymax - ymin) / image_height<br><br>            line = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;class_index&#125;</span> <span class="hljs-subst">&#123;x_center&#125;</span> <span class="hljs-subst">&#123;y_center&#125;</span> <span class="hljs-subst">&#123;width&#125;</span> <span class="hljs-subst">&#123;height&#125;</span>\n&quot;</span><br>            f.write(line)<br></code></pre></td></tr></table></figure><p>其中 xml_file 为 xml 文件名，txt_file 为 txt 文件名，yaml_file 为 voc.yaml (包含类名)</p><h2 id="4-4-开始训练">4.4 开始训练</h2><p><code>python .\train.py --weights weights/yolov5s.pt --cfg models/yolov5s.yaml --data data/voc.yaml</code></p><h2 id="4-5-可能出现的-Error">4.5 可能出现的 Error</h2><p><strong>Error</strong>：<code>AttributeError: module 'numpy' has no attribute 'int'</code></p><p><strong>Solution</strong>：</p><p>在 utils\datasets.py 413 行， 将 np.int 改为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">bi = np.floor(np.arange(n) / batch_size).astype(<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># batch index</span><br></code></pre></td></tr></table></figure><p>在 utils\datasets.py 441 行， 将 np.int 改为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(<span class="hljs-built_in">int</span>) * stride<br></code></pre></td></tr></table></figure><p>在 utils\general.py 222 行， 将 np.int 改为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">classes = labels[:, <span class="hljs-number">0</span>].astype(<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># labels = [class xywh]</span><br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>RuntimeError: result type Float can't be cast to the desired output type __int64</code></p><p><strong>Solution</strong>：</p><p>在 utils\loss.py 212 行，将 gain 强制转为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">indices.append((b, a, gj.clamp_(<span class="hljs-number">0</span>, <span class="hljs-built_in">int</span>(gain[<span class="hljs-number">3</span>]) - <span class="hljs-number">1</span>), gi.clamp_(<span class="hljs-number">0</span>, <span class="hljs-built_in">int</span>(gain[<span class="hljs-number">2</span>]) - <span class="hljs-number">1</span>)))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv5 目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv1 网络复现</title>
    <link href="/2023/05/16/yolov1/"/>
    <url>/2023/05/16/yolov1/</url>
    
    <content type="html"><![CDATA[<p>YOLOv1 网络复现</p><span id="more"></span><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">leaky_reLu</span>(<span class="hljs-params">x, negative_slope=<span class="hljs-number">0.01</span></span>):<br>    <span class="hljs-keyword">return</span> torch.where(x &gt;= <span class="hljs-number">0</span>, x, negative_slope * x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚层">全局平均汇聚层</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="加载-resnet34-预训练模型">加载 resnet34 预训练模型</h1><p>原论文是采用自己设计的20层卷积层先在ImageNet上训练了一周，完成特征提取部分的训练。这里我用ResNet34 预训练模型替代。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> tvmodel<br>resnet = tvmodel.resnet34(pretrained=<span class="hljs-literal">True</span>)<br>resnet_out_channel = resnet.fc.in_features<br>resnet = nn.Sequential(*<span class="hljs-built_in">list</span>(resnet.children())[:-<span class="hljs-number">2</span>])<br>GL_CLASSES = [<span class="hljs-string">&#x27;person&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;cow&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;sheep&#x27;</span>,<br>           <span class="hljs-string">&#x27;aeroplane&#x27;</span>, <span class="hljs-string">&#x27;bicycle&#x27;</span>, <span class="hljs-string">&#x27;boat&#x27;</span>, <span class="hljs-string">&#x27;bus&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;motorbike&#x27;</span>, <span class="hljs-string">&#x27;train&#x27;</span>,<br>           <span class="hljs-string">&#x27;bottle&#x27;</span>, <span class="hljs-string">&#x27;chair&#x27;</span>, <span class="hljs-string">&#x27;diningtable&#x27;</span>, <span class="hljs-string">&#x27;pottedplant&#x27;</span>, <span class="hljs-string">&#x27;sofa&#x27;</span>, <span class="hljs-string">&#x27;tvmonitor&#x27;</span>]<br>GL_NUMBBOX = <span class="hljs-number">2</span><br>GL_NUMGRID = <span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><h1 id="构建-yolov1-网络">构建 YOLOv1 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">YOLOv1Net</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;卷积层&quot;&quot;&quot;</span><br>    W_1 = normal((<span class="hljs-number">1024</span>, resnet_out_channel, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_1 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    W_2 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_2 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    W_3 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_3 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    W_4 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_4 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    convs = [W_1, b_1, W_2, b_2, W_3, b_3, W_4, b_4]<br>    W_1 = normal((GL_NUMGRID * GL_NUMGRID * <span class="hljs-number">1024</span>, <span class="hljs-number">4096</span>)); b_1 = torch.zeros(<span class="hljs-number">4096</span>, device=device)<br>    W_2 = normal((<span class="hljs-number">4096</span>, GL_NUMGRID * GL_NUMGRID * (<span class="hljs-number">5</span> * GL_NUMBBOX + <span class="hljs-built_in">len</span>(GL_CLASSES)))); <br>    b_2 = torch.zeros(GL_NUMGRID * GL_NUMGRID * (<span class="hljs-number">5</span> * GL_NUMBBOX + <span class="hljs-built_in">len</span>(GL_CLASSES)), device=device)<br>    linears = [W_1, b_1, W_2, b_2]<br>    self.params = [convs, linears]; self.flt_params = []<br>    <span class="hljs-keyword">for</span> params <span class="hljs-keyword">in</span> [convs, linears]:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            self.flt_params.append(param)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)     <br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    convs, linears = self.params<br>    X = resnet(X)<br>    W_1, b_1, W_2, b_2, W_3, b_3, W_4, b_4 = convs<br>    X = relu(conv2d(X, W_1, b_1, padding=<span class="hljs-number">1</span>))<br>    X = relu(conv2d(X, W_2, b_2, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br>    X = relu(conv2d(X, W_3, b_3, padding=<span class="hljs-number">1</span>))<br>    X = relu(conv2d(X, W_4, b_4, padding=<span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    W_1, b_1, W_2, b_2 = linears<br>    X = relu(X @ W_1 + b_1)<br>    X = sigmoid(X @ W_2 + b_2)<br>    Y = X.reshape(-<span class="hljs-number">1</span>, (<span class="hljs-number">5</span> * GL_NUMBBOX + <span class="hljs-built_in">len</span>(GL_CLASSES)), GL_NUMGRID, GL_NUMGRID)<br>    <span class="hljs-keyword">return</span> Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="误差函数">误差函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, pred, labels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        pred: (batchsize, 30, 7, 7) 的网络输出数据</span><br><span class="hljs-string">        labels: (batchsize, 30, 7, 7) 的样本标签数据</span><br><span class="hljs-string">        return: 当前批次样本的平均损失</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        num_gridx, num_gridy = labels.size()[-<span class="hljs-number">2</span>:]  <br>        num_b = <span class="hljs-number">2</span>  <span class="hljs-comment"># 每个网格的 bbox 数量</span><br>        num_cls = <span class="hljs-number">20</span>  <span class="hljs-comment"># 类别数量</span><br>        noobj_confi_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 不含目标的网格损失(只有置信度损失)</span><br>        coor_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 含有目标的bbox的坐标损失</span><br>        obj_confi_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 含有目标的bbox的置信度损失</span><br>        class_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 含有目标的网格的类别损失</span><br>        n_batch = labels.size()[<span class="hljs-number">0</span>]  <span class="hljs-comment"># batchsize的大小</span><br>        <br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_iou</span>(<span class="hljs-params">bbox1, bbox2</span>):<br>            <span class="hljs-string">&quot;&quot;&quot;计算 bbox1 = (x1, y1, x2, y2) 和 bbox2 = (x3, y3, x4, y4) 两个 bbox 的 iou&quot;&quot;&quot;</span><br>            x1, y1, x2, y2 = bbox1<br>            x3, y3, x4, y4 = bbox2<br>            intersect_width = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">min</span>(x2, x4) - <span class="hljs-built_in">max</span>(x1, x3))<br>            intersect_height = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">min</span>(y2, y4) - <span class="hljs-built_in">max</span>(y1, y3))<br>            intersection_area = intersect_width * intersect_height<br>            area1 = (x2 - x1) * (y2 - y1)<br>            area2 = (x4 - x3) * (y4 - y3)<br>            iou = intersection_area / (area1 + area2 - intersection_area) <span class="hljs-keyword">if</span> intersection_area &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            <span class="hljs-keyword">return</span> iou<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_batch): <br>            <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>):<br>                <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>):<br>                    <span class="hljs-keyword">if</span> labels[i, <span class="hljs-number">4</span>, m, n] == <span class="hljs-number">1</span>: <span class="hljs-comment"># 如果包含物体</span><br>                        bbox1_pred_xyxy = ((pred[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx - pred[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy - pred[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx + pred[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy + pred[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>)<br>                        bbox2_pred_xyxy = ((pred[i, <span class="hljs-number">5</span>, m, n] + n) / num_gridx - pred[i, <span class="hljs-number">7</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">6</span>, m, n] + m) / num_gridy - pred[i, <span class="hljs-number">8</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">5</span>, m, n] + n) / num_gridx + pred[i, <span class="hljs-number">7</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">6</span>, m, n] + m) / num_gridy + pred[i, <span class="hljs-number">8</span>, m, n] / <span class="hljs-number">2</span>)<br>                        bbox_gt_xyxy = ((labels[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx - labels[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                        (labels[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy - labels[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>,<br>                                        (labels[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx + labels[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                        (labels[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy + labels[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>)<br>                        iou1 = calculate_iou(bbox1_pred_xyxy, bbox_gt_xyxy)<br>                        iou2 = calculate_iou(bbox2_pred_xyxy, bbox_gt_xyxy)<br>                        coor_loss += <span class="hljs-number">5</span> * (torch.<span class="hljs-built_in">sum</span>((pred[i, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], m, n] - labels[i, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], m, n]) ** <span class="hljs-number">2</span>)<br>                                          + torch.<span class="hljs-built_in">sum</span>((pred[i, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], m, n].sqrt() - <br>                                                       labels[i, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], m, n].sqrt()) ** <span class="hljs-number">2</span>))<br>                        obj_confi_loss += (pred[i, <span class="hljs-number">4</span>, m, n] - iou1) ** <span class="hljs-number">2</span> \<br>                                        <span class="hljs-keyword">if</span> iou1 &gt;= iou2 <span class="hljs-keyword">else</span> (pred[i, <span class="hljs-number">9</span>, m, n] - iou2) ** <span class="hljs-number">2</span><br>                        noobj_confi_loss += <span class="hljs-number">0.5</span> * ((pred[i, <span class="hljs-number">9</span>, m, n] - iou2) ** <span class="hljs-number">2</span> \<br>                                        <span class="hljs-keyword">if</span> iou1 &gt;= iou2 <span class="hljs-keyword">else</span> (pred[i, <span class="hljs-number">4</span>, m, n] - iou1) ** <span class="hljs-number">2</span>)<br>                        class_loss += torch.<span class="hljs-built_in">sum</span>((pred[i, <span class="hljs-number">10</span>:, m, n] - labels[i, <span class="hljs-number">10</span>:, m, n]) ** <span class="hljs-number">2</span>)<br>                    <span class="hljs-keyword">else</span>:<br>                        noobj_confi_loss += <span class="hljs-number">0.5</span> * torch.<span class="hljs-built_in">sum</span>(pred[i, [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>], m, n] ** <span class="hljs-number">2</span>)<br>        loss = coor_loss + obj_confi_loss + noobj_confi_loss + class_loss<br>        <span class="hljs-keyword">return</span> loss / n_batch<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="加载数据">加载数据</h1><h2 id="数据生成器">数据生成器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dataset_dir, seed=<span class="hljs-literal">None</span>, mode=<span class="hljs-string">&quot;train&quot;</span>, train_val_ratio=<span class="hljs-number">0.9</span>, trans=<span class="hljs-literal">None</span></span>):<br>        random.seed(seed)<br>        self.dataset_dir = dataset_dir<br>        self.mode = mode<br>        img_list_txt = os.path.join(dataset_dir, mode.replace(<span class="hljs-string">&quot;val&quot;</span>, <span class="hljs-string">&quot;train&quot;</span>) + <span class="hljs-string">&quot;.txt&quot;</span>)<br>        label_csv = os.path.join(dataset_dir, mode.replace(<span class="hljs-string">&quot;val&quot;</span>, <span class="hljs-string">&quot;train&quot;</span>) + <span class="hljs-string">&quot;.csv&quot;</span>)<br>        self.img_list = <span class="hljs-built_in">open</span>(img_list_txt).read().splitlines()<br>        self.label = np.loadtxt(label_csv, dtype=np.float32)<br>        self.num_all_data = <span class="hljs-built_in">len</span>(self.img_list)<br>        all_ids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(self.num_all_data))<br>        num_train = <span class="hljs-built_in">int</span>(train_val_ratio * self.num_all_data)<br>        self.use_ids = all_ids[:num_train] <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&quot;train&quot;</span> <span class="hljs-keyword">else</span> all_ids[num_train:]<br>        self.trans = trans<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.use_ids)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-built_in">id</span> = self.use_ids[item]<br>        label = torch.tensor(self.label[<span class="hljs-built_in">id</span>, :])<br>        img_path = self.img_list[<span class="hljs-built_in">id</span>]<br>        img = Image.<span class="hljs-built_in">open</span>(img_path)<br>        <span class="hljs-keyword">if</span> self.trans <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            trans = transforms.Compose([transforms.ToTensor(),])<br>        <span class="hljs-keyword">else</span>:<br>            trans = self.trans<br>        img = trans(img)<br>        <span class="hljs-keyword">return</span> img, label<br></code></pre></td></tr></table></figure><h2 id="生成数据">生成数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">epoch, batch_size, lr, num_epochs = <span class="hljs-number">50</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span><br>dataset_dir = <span class="hljs-string">&quot;../DataSet/VOCdevkit/VOC2012/voc2012_forYolov1/&quot;</span><br>dataset = MyDataset(dataset_dir)<br>train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">net = YOLOv1Net()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> i, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        y = y.view(batch_size, GL_NUMGRID, GL_NUMGRID, -<span class="hljs-number">1</span>)<br>        y = y.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l * batch_size; metrics[<span class="hljs-number">1</span>] += batch_size<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;i %d loss %f&#x27;</span> % (i + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">weight_path = <span class="hljs-string">&#x27;../YOLOv1/weights/net.pkl&#x27;</span><br>torch.save(net, weight_path)<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><h2 id="非极大值抑制nms">非极大值抑制（NMS）</h2><h3 id="单类别-nms">单类别 NMS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">nms_1cls</span>(<span class="hljs-params">dets, thresh</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    单类别NMS</span><br><span class="hljs-string">    dets: ndarray, nx5, dets[i, 0:4] 分别是 bbox 坐标；dets[i, 4] 是置信度 score</span><br><span class="hljs-string">    thresh: NMS 算法设置的 iou 阈值</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    x1, y1, x2, y2, scores = dets[:, <span class="hljs-number">0</span>], dets[:, <span class="hljs-number">1</span>], dets[:, <span class="hljs-number">2</span>], dets[:, <span class="hljs-number">3</span>], dets[:, <span class="hljs-number">4</span>]<br>    areas = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)<br>    order = scores.argsort()[::-<span class="hljs-number">1</span>]<br>    keep = []<br><br>    <span class="hljs-keyword">while</span> order.size &gt; <span class="hljs-number">0</span>:<br>        i = order[<span class="hljs-number">0</span>]<br>        keep.append(i)<br>        xx1 = np.maximum(x1[i], x1[order[<span class="hljs-number">1</span>:]])<br>        yy1 = np.maximum(y1[i], y1[order[<span class="hljs-number">1</span>:]])<br>        xx2 = np.minimum(x2[i], x2[order[<span class="hljs-number">1</span>:]])<br>        yy2 = np.minimum(y2[i], y2[order[<span class="hljs-number">1</span>:]])<br><br>        w = np.maximum(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)<br>        h = np.maximum(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)<br>        inter = w * h<br>        iou = inter / (areas[i] + areas[order[<span class="hljs-number">1</span>:]] - inter)<br><br>        inds = np.where(iou &lt;= thresh)[<span class="hljs-number">0</span>]<br>        order = order[inds + <span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> keep<br></code></pre></td></tr></table></figure><h3 id="多类别极大值抑制">多类别极大值抑制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">nms_multi_cls</span>(<span class="hljs-params">dets, thresh, n_cls</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    多类别的NMS算法</span><br><span class="hljs-string">    dets: ndarray, nx6, dets[i, 0:4] 是 bbox 坐标；dets[i, 4] 是置信度 score；dets[i, 5] 是类别序号；</span><br><span class="hljs-string">    thresh: NMS 算法的阈值；</span><br><span class="hljs-string">    n_cls: 是类别总数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    keeps_index = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_cls):<br>        order_i = np.where(dets[:, <span class="hljs-number">5</span>] == i)[<span class="hljs-number">0</span>]<br>        det = dets[dets[:, <span class="hljs-number">5</span>] == i, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>]<br>        <span class="hljs-keyword">if</span> det.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">0</span>:<br>            keeps_index.append([])<br>            <span class="hljs-keyword">continue</span><br>        keep = nms_1cls(det, thresh)<br>        keeps_index.append(order_i[keep])<br>    <span class="hljs-keyword">return</span> keeps_index<br></code></pre></td></tr></table></figure><h2 id="yolov1net-输出向量处理">YOLOv1Net 输出向量处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">labels2bbox</span>(<span class="hljs-params">matrix</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    将网络输出的 7*7*30 的数据转换为 bbox 的 (98, 25) 的格式，然后再将 NMS 处理后的结果返回</span><br><span class="hljs-string">    matrix: 注意，输入的数据中，bbox坐标的格式是 (px,py,w,h)，需要转换为 (x1,y1,x2,y2) 的格式再输入NMS</span><br><span class="hljs-string">    return: 返回NMS处理后的结果,bboxes.shape = (-1, 6), 0:4 是(x1,y1,x2,y2), 4是conf， 5是cls</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> matrix.size()[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>] != (<span class="hljs-number">7</span>,<span class="hljs-number">7</span>):<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Error: Wrong labels size: &quot;</span>, matrix.size(), <span class="hljs-string">&quot; != (7,7)&quot;</span>)<br>    matrix = matrix.numpy()<br>    bboxes = np.zeros((<span class="hljs-number">98</span>, <span class="hljs-number">6</span>))<br>    matrix = matrix.reshape(<span class="hljs-number">49</span>, -<span class="hljs-number">1</span>)<br>    bbox = matrix[:, :<span class="hljs-number">10</span>].reshape(<span class="hljs-number">98</span>, <span class="hljs-number">5</span>)<br>    r_grid = np.array(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>)))<br>    r_grid = np.repeat(r_grid, repeats=<span class="hljs-number">14</span>, axis=<span class="hljs-number">0</span>)<br>    c_grid = np.array(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>)))<br>    c_grid = np.repeat(c_grid, repeats=<span class="hljs-number">2</span>, axis=<span class="hljs-number">0</span>)[np.newaxis, :]<br>    c_grid = np.repeat(c_grid, repeats=<span class="hljs-number">7</span>, axis=<span class="hljs-number">0</span>).reshape(-<span class="hljs-number">1</span>)<br>    bboxes[:, <span class="hljs-number">0</span>] = np.maximum((bbox[:, <span class="hljs-number">0</span>] + c_grid) / <span class="hljs-number">7.0</span> - bbox[:, <span class="hljs-number">2</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">0</span>)<br>    bboxes[:, <span class="hljs-number">1</span>] = np.maximum((bbox[:, <span class="hljs-number">1</span>] + r_grid) / <span class="hljs-number">7.0</span> - bbox[:, <span class="hljs-number">3</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">0</span>)<br>    bboxes[:, <span class="hljs-number">2</span>] = np.minimum((bbox[:, <span class="hljs-number">0</span>] + c_grid) / <span class="hljs-number">7.0</span> + bbox[:, <span class="hljs-number">2</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">1</span>)<br>    bboxes[:, <span class="hljs-number">3</span>] = np.minimum((bbox[:, <span class="hljs-number">1</span>] + r_grid) / <span class="hljs-number">7.0</span> + bbox[:, <span class="hljs-number">3</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">1</span>)<br>    bboxes[:, <span class="hljs-number">4</span>] = bbox[:, <span class="hljs-number">4</span>]<br>    cls = np.argmax(matrix[:, <span class="hljs-number">10</span>:], axis=<span class="hljs-number">1</span>)<br>    cls = np.repeat(cls, repeats=<span class="hljs-number">2</span>, axis=<span class="hljs-number">0</span>)<br>    bboxes[:, <span class="hljs-number">5</span>] = cls<br>    keepid = nms_multi_cls(bboxes, thresh=<span class="hljs-number">0.01</span>, n_cls=<span class="hljs-number">20</span>)<br>    ids = []<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> keepid:<br>        ids = ids + <span class="hljs-built_in">list</span>(x)<br>    ids = <span class="hljs-built_in">sorted</span>(ids)<br>    <span class="hljs-keyword">return</span> bboxes[ids, :]<br></code></pre></td></tr></table></figure><h2 id="绘制-bounding-box">绘制 bounding box</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">draw_bbox</span>(<span class="hljs-params">img, bbox</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    根据bbox的信息在图像上绘制 bounding box</span><br><span class="hljs-string">    :param img: 绘制bbox的图像</span><br><span class="hljs-string">    :param bbox: 是(n,6)的尺寸，0:4是(x1,y1,x2,y2), 4是conf， 5是cls</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    h, w = img.shape[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]<br>    n = bbox.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        confidence = bbox[i, <span class="hljs-number">4</span>]<br>        <span class="hljs-keyword">if</span> confidence&lt;<span class="hljs-number">0.2</span>:<br>            <span class="hljs-keyword">continue</span><br>        p1 = (<span class="hljs-built_in">int</span>(w * bbox[i, <span class="hljs-number">0</span>]), <span class="hljs-built_in">int</span>(h * bbox[i, <span class="hljs-number">1</span>]))<br>        p2 = (<span class="hljs-built_in">int</span>(w * bbox[i, <span class="hljs-number">2</span>]), <span class="hljs-built_in">int</span>(h * bbox[i, <span class="hljs-number">3</span>]))<br>        cls_name = GL_CLASSES[<span class="hljs-built_in">int</span>(bbox[i, <span class="hljs-number">5</span>])]<br>        <span class="hljs-built_in">print</span>(cls_name, p1, p2)<br>        cv2.rectangle(img, p1, p2, COLOR[<span class="hljs-built_in">int</span>(bbox[i, <span class="hljs-number">5</span>])])<br>        cv2.putText(img, cls_name, p1, cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>))<br>        cv2.putText(img, <span class="hljs-built_in">str</span>(confidence), (p1[<span class="hljs-number">0</span>],p1[<span class="hljs-number">1</span>]-<span class="hljs-number">10</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>))<br>    cv2.imshow(<span class="hljs-string">&quot;bbox&quot;</span>, img)<br>    cv2.waitKey(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h2 id="预测-1">预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br>COLOR = [(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">125</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">250</span>),<br>         (<span class="hljs-number">255</span>,<span class="hljs-number">125</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">125</span>,<span class="hljs-number">250</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">125</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),<br>         (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">125</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">125</span>,<span class="hljs-number">255</span>),<br>         (<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">255</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">100</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),]  <span class="hljs-comment"># 用来标识20个类别的bbox颜色，可自行设定</span><br>test_image_dir = <span class="hljs-string">&#x27;./Test_Images/&#x27;</span><br>img_list = os.listdir(test_image_dir)<br>trans = transforms.Compose([transforms.ToTensor(),])<br><span class="hljs-keyword">for</span> img_name <span class="hljs-keyword">in</span> img_list:<br>    img_path = os.path.join(test_image_dir, img_name)<br>    img = Image.<span class="hljs-built_in">open</span>(img_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    img = trans(img)<br>    img = torch.unsqueeze(img, dim=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(img_name, img.shape)<br>    preds = torch.squeeze(net(img), dim=<span class="hljs-number">0</span>).detach().cpu()<br>    preds = preds.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)<br>    bbox = labels2bbox(preds)<br>    draw_img = cv2.imread(img_path)<br>    draw_bbox(draw_img, bbox)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv1、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NiN 网络复现</title>
    <link href="/2023/05/14/ninnet/"/>
    <url>/2023/05/14/ninnet/</url>
    
    <content type="html"><![CDATA[<p>NiN 网络复现</p><span id="more"></span><p><img src="https://github.com/vexentox/reproduction/blob/main/NiN/NiN%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚层">全局平均汇聚层</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="构建-nin-网络">构建 NiN 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NiNNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">nin_block</span>(<span class="hljs-params">in_channels, out_channels, kernel_size</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>        W_conv1 = normal((out_channels, in_channels, kernel_size, kernel_size))<br>        b_conv1 = torch.zeros(out_channels, device=device)<br>        W_conv2 = normal((out_channels, out_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        b_conv2 = torch.zeros(out_channels, device=device)<br>        W_conv3 = normal((out_channels, out_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        b_conv3 = torch.zeros(out_channels, device=device)<br>        <span class="hljs-keyword">return</span> [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3]<br>    nin1 = nin_block(<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>)<br>    nin2 = nin_block(<span class="hljs-number">96</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>)<br>    nin3 = nin_block(<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>)<br>    nin4 = nin_block(<span class="hljs-number">384</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>)<br>    self.params = [nin1, nin2, nin3, nin4]<br>    self.flt_params = []<br>    <span class="hljs-keyword">for</span> nin <span class="hljs-keyword">in</span> self.params:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> nin:<br>            self.flt_params.append(param)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)    <br></code></pre></td></tr></table></figure><h2 id="推理函数">推理函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    strides = [<span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]; paddings = [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>];<br>    <span class="hljs-keyword">for</span> i, nin <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.params):<br>        W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3 = nin<br>        X = relu(conv2d(X, W_conv1, b_conv1, stride=strides[i], padding=paddings[i]))<br>        X = conv2d(X, W_conv2, b_conv2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br>        X = conv2d(X, W_conv3, b_conv3, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">if</span> i &lt;= <span class="hljs-number">2</span>:<br>            X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">2</span>:<br>            X = dropout(X, <span class="hljs-number">0.5</span>)<br>    X = AdaptiveAvgPool2d(X, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    Y = sigmoid(X)<br>    <span class="hljs-keyword">return</span> Y<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="更新函数">更新函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">net = NiNNet()<br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">16</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>        i += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;i %d loss %f&#x27;</span> % (i + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br>        <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">30</span>:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NiN、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VggNet 网络复现</title>
    <link href="/2023/05/14/vggnet/"/>
    <url>/2023/05/14/vggnet/</url>
    
    <content type="html"><![CDATA[<p>VggNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/VggNet/VggNet%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">max 池化朴素实现</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=None, padding=0):</span><br><span class="hljs-string">    batch_size, channels, height, width = input.size()</span><br><span class="hljs-string">    output_height = int((height + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output_width = int((width + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c in range(channels):</span><br><span class="hljs-string">            for i in range(output_height):</span><br><span class="hljs-string">                for j in range(output_width):</span><br><span class="hljs-string">                    avg_value = torch.max(</span><br><span class="hljs-string">                        input[b, c, i * stride:i * stride + kernel_size, j * stride:j * stride + kernel_size]</span><br><span class="hljs-string">                    )</span><br><span class="hljs-string">                    output[b, c, i, j] = avg_value</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    output = torch.nn.functional.max_pool2d(<span class="hljs-built_in">input</span>, kernel_size, stride=stride, padding=padding)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * torch.empty_like(X.bernoulli_(<span class="hljs-number">1</span> - p) / (<span class="hljs-number">1</span> - p))<br><span class="hljs-comment">#     return torch.nn.functional.dropout(X, p=p, training=True)</span><br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="构建-vggnet-网络">构建 VggNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VggNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, conv_arch</span>):<br>        self._init_params(conv_arch)<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self, conv_arch</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">vgg_block</span>(<span class="hljs-params">num_convs, in_channels, out_channels</span>):<br>        params = []<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_convs):<br>            <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>            params.append([<br>                normal((out_channels, in_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)),<br>                torch.zeros(out_channels, device=device)<br>            ])<br>            in_channels = out_channels<br>        <span class="hljs-keyword">return</span> params<br>    conv_blks = []<br>    in_channels = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> (num_convs, out_channels) <span class="hljs-keyword">in</span> conv_arch:<br>        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))<br>        in_channels = out_channels<br>    W_h1h2 = normal((out_channels * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">4096</span>)); b_h1h2 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h2h3 = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>)); b_h2h3 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h3y = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>)); b_h3y = torch.zeros(<span class="hljs-number">10</span>, device=device);<br>    linears = [W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y]<br>    params = [conv_blks, linears]<br>    self.flt_params = []<br>    <span class="hljs-keyword">for</span> vgg_blk <span class="hljs-keyword">in</span> conv_blks:<br>        <span class="hljs-keyword">for</span> W, b <span class="hljs-keyword">in</span> vgg_blk:<br>            self.flt_params.append(W)<br>            self.flt_params.append(b)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> linears:<br>        self.flt_params.append(param)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    self.params = params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    conv_blks, [W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y] = self.params<br>    <span class="hljs-keyword">for</span> vgg_blk <span class="hljs-keyword">in</span> conv_blks:<br>        <span class="hljs-keyword">for</span> W, b <span class="hljs-keyword">in</span> vgg_blk:<br>            X = relu(conv2d(X, W, b, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>))<br>        X = max_pool2d(X, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    H1 = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>) <span class="hljs-comment"># 展平</span><br>    H2 = dropout(relu(H1 @ W_h1h2 + b_h1h2), <span class="hljs-number">0.5</span>)<br>    H3 = dropout(relu(H2 @ W_h2h3 + b_h2h3), <span class="hljs-number">0.5</span>)<br>    Y = sigmoid(H3 @ W_h3y + b_h3y)<br>    <span class="hljs-keyword">return</span> Y<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">ratio = <span class="hljs-number">4</span><br>small_conv_arch = [(pair[<span class="hljs-number">0</span>], pair[<span class="hljs-number">1</span>] // ratio) <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> conv_arch]<br>net = VggNet(small_conv_arch)<br><br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VggNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet 网络复现</title>
    <link href="/2023/05/14/alexnet/"/>
    <url>/2023/05/14/alexnet/</url>
    
    <content type="html"><![CDATA[<p>AlexNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/AlexNet/AlexNet%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">max 池化朴素实现</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=None, padding=0):</span><br><span class="hljs-string">    batch_size, channels, height, width = input.size()</span><br><span class="hljs-string">    output_height = int((height + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output_width = int((width + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c in range(channels):</span><br><span class="hljs-string">            for i in range(output_height):</span><br><span class="hljs-string">                for j in range(output_width):</span><br><span class="hljs-string">                    avg_value = torch.max(</span><br><span class="hljs-string">                        input[b, c, i * stride:i * stride + kernel_size, j * stride:j * stride + kernel_size]</span><br><span class="hljs-string">                    )</span><br><span class="hljs-string">                    output[b, c, i, j] = avg_value</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    output = torch.nn.functional.max_pool2d(<span class="hljs-built_in">input</span>, kernel_size, stride=stride, padding=padding)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * torch.empty_like(X.bernoulli_(<span class="hljs-number">1</span> - p) / (<span class="hljs-number">1</span> - p))<br><span class="hljs-comment">#     return torch.nn.functional.dropout(X, p=p, training=True)</span><br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="构建-alexnet-网络">构建 AlexNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AlexNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    W_conv1 = normal((<span class="hljs-number">96</span>, <span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">11</span>)); b_conv1 = torch.zeros(<span class="hljs-number">96</span>, device=device);<br>    W_conv2 = normal((<span class="hljs-number">256</span>, <span class="hljs-number">96</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_conv2 = torch.zeros(<span class="hljs-number">256</span>, device=device);<br>    W_conv3 = normal((<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_conv3 = torch.zeros(<span class="hljs-number">384</span>, device=device);<br>    W_conv4 = normal((<span class="hljs-number">384</span>, <span class="hljs-number">384</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_conv4 = torch.zeros(<span class="hljs-number">384</span>, device=device);<br>    W_conv5 = normal((<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_conv5 = torch.zeros(<span class="hljs-number">256</span>, device=device);<br>    <br>    W_h1h2 = normal((<span class="hljs-number">6400</span>, <span class="hljs-number">4096</span>)); b_h1h2 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h2h3 = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>)); b_h2h3 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h3y = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>)); b_h3y = torch.zeros(<span class="hljs-number">10</span>, device=device);<br>    <br>    params = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_conv4, b_conv4, W_conv5, b_conv5, <br>              W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_conv4, b_conv4, W_conv5, b_conv5, \<br>        W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y = self.params<br>    <br>    C1 = max_pool2d(relu(conv2d(X, W_conv1, b_conv1, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">1</span>)), <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    C2 = max_pool2d(relu(conv2d(C1, W_conv2, b_conv2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>)), <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    C3 = relu(conv2d(C2, W_conv3, b_conv3, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>))<br>    C4 = relu(conv2d(C3, W_conv4, b_conv4, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>))<br>    C5 = max_pool2d(relu(conv2d(C4, W_conv5, b_conv5, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)), <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    H1 = C5.reshape(C5.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    H2 = dropout(relu(H1 @ W_h1h2 + b_h1h2), <span class="hljs-number">0.5</span>)<br>    H3 = dropout(relu(H2 @ W_h2h3 + b_h2h3), <span class="hljs-number">0.5</span>)<br>    Y = sigmoid(H3 @ W_h3y + b_h3y)<br>    <span class="hljs-keyword">return</span> Y<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="更新参数">更新参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params:<br>            p.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br>net = AlexNet()<br>num_epochs = <span class="hljs-number">100</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_iter):<br>        l = net.update(X, y, lr=<span class="hljs-number">1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AlexNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeNet 网络复现</title>
    <link href="/2023/05/13/lenet/"/>
    <url>/2023/05/13/lenet/</url>
    
    <content type="html"><![CDATA[<p>LeNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/LeNet/strcut.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(<span class="hljs-built_in">input</span>, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="池化">池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">ave 池化朴素实现</span><br><span class="hljs-string">def avg_pool2d(input, kernel_size, stride=None, padding=0):</span><br><span class="hljs-string">    batch_size, channels, height, width = input.size()</span><br><span class="hljs-string">    output_height = int((height + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output_width = int((width + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c in range(channels):</span><br><span class="hljs-string">            for i in range(output_height):</span><br><span class="hljs-string">                for j in range(output_width):</span><br><span class="hljs-string">                    avg_value = torch.mean(</span><br><span class="hljs-string">                        input[b, c, i * stride:i * stride + kernel_size, j * stride:j * stride + kernel_size]</span><br><span class="hljs-string">                    )</span><br><span class="hljs-string">                    output[b, c, i, j] = avg_value</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">avg_pool2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    output = torch.nn.functional.avg_pool2d(<span class="hljs-built_in">input</span>, kernel_size, stride=stride, padding=padding)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="构建-lenet-网络">构建 LeNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LeNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    W_conv1 = normal((<span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_conv1 = torch.zeros(<span class="hljs-number">6</span>, device=device);<br>    W_conv2 = normal((<span class="hljs-number">16</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_conv2 = torch.zeros(<span class="hljs-number">16</span>, device=device);<br>    W_h1h2 = normal((<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)); b_h1h2 = torch.zeros(<span class="hljs-number">120</span>, device=device);<br>    W_h2h3 = normal((<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)); b_h2h3 = torch.zeros(<span class="hljs-number">84</span>, device=device);<br>    W_h3y = normal((<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)); b_h3y = torch.zeros(<span class="hljs-number">10</span>, device=device);<br>    <br>    params = [W_conv1,b_conv1, W_conv2, b_conv2, W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_conv1, b_conv1, W_conv2, b_conv2, W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y = self.params<br>    C1 = torch.sigmoid(conv2d(X, W_conv1, b_conv1, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>))<br>    C2 = avg_pool2d(C1, <span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    C3 = torch.sigmoid(conv2d(C2, W_conv2, b_conv2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>))<br>    C4 = avg_pool2d(C3, <span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    H1 = C4.reshape(C4.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    H2 = torch.sigmoid(H1 @ W_h1h2 + b_h1h2)<br>    H3 = torch.sigmoid(H2 @ W_h2h3 + b_h2h3)<br>    Y = torch.sigmoid(H3 @ W_h3y + b_h3y)<br>    <span class="hljs-keyword">return</span> Y<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, device = <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">28</span>)<br>net = LeNet()<br>num_epochs = <span class="hljs-number">5</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_iter, ncols=<span class="hljs-number">100</span>):<br>        l = net.update(X, y, lr=<span class="hljs-number">0.1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n].reshape((n, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LeNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Softmax 回归复现</title>
    <link href="/2023/05/13/softmax/"/>
    <url>/2023/05/13/softmax/</url>
    
    <content type="html"><![CDATA[<p>softmax 回归复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[Y = softmax(WX+b)\]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><h1 id="构建-softmax-网络">构建 softmax 网络</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SoftMax</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_inputs, num_outputs</span>):<br>        self.num_inputs, self.num_outputs = num_inputs, num_outputs<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    num_inputs = self.num_inputs; num_outputs = self.num_outputs<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    W = normal((num_inputs, num_outputs)); b = torch.zeros(num_outputs, device=device)<br>    params = [W, b]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="softmax">softmax</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">self, X</span>):<br>    X_exp = torch.exp(X)<br>    partition = X_exp.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> X_exp / partition  <span class="hljs-comment"># 这里应用了广播机制</span><br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, inputs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    outputs = []<br>    W, b = self.params<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        Y = self.softmax(X.reshape((-<span class="hljs-number">1</span>, W.shape[<span class="hljs-number">0</span>])) @ W + b)<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, device = <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">28</span>)<br>num_epochs, num_inputs, num_outputs = <span class="hljs-number">3</span>, <span class="hljs-number">784</span>, <span class="hljs-number">10</span><br>net = SoftMax(num_inputs, num_outputs)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_iter, ncols=<span class="hljs-number">100</span>):<br>        l = net.update(X, y, lr=<span class="hljs-number">1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">6</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n].reshape((n, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>softmax 回归、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归网络复现</title>
    <link href="/2023/05/13/linear/"/>
    <url>/2023/05/13/linear/</url>
    
    <content type="html"><![CDATA[<p>线性回归网络复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[ Y = XW + b \]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure><h1 id="构建线性回归网络">构建线性回归网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_inputs, num_outputs</span>):<br>        self.num_inputs, self.num_outputs = num_inputs, num_outputs<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    num_inputs = self.num_inputs; num_outputs = self.num_outputs<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    W = normal((num_inputs, num_outputs)); b = torch.zeros(num_outputs, device=device)<br>    params = [W, b]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, inputs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    outputs = []<br>    W, b = self.params<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        Y = X @ W + b<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y.T.reshape(-<span class="hljs-number">1</span>))<br>    l.<span class="hljs-built_in">sum</span>().backward()<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="均方损失">均方损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;均方损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="hljs-number">2</span> / <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h1 id="生成测试数据">生成测试数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">synthetic_data</span>(<span class="hljs-params">w, b, num_examples</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot;</span><br>    X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (num_examples, <span class="hljs-built_in">len</span>(w)))<br>    y = torch.matmul(X, w) + b<br>    y += torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, y.shape)<br>    <span class="hljs-keyword">return</span> X, y.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br><br>true_w = torch.tensor([<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>])<br>true_b = <span class="hljs-number">4.2</span><br>features, labels = synthetic_data(true_w, true_b, <span class="hljs-number">1000</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_iter</span>(<span class="hljs-params">batch_size, features, labels</span>):<br>    num_examples = <span class="hljs-built_in">len</span>(features)<br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_examples))<br>    <span class="hljs-comment"># 这些样本是随机读取的，没有特定的顺序</span><br>    random.shuffle(indices)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_examples, batch_size):<br>        batch_indices = torch.tensor(<br>            indices[i: <span class="hljs-built_in">min</span>(i + batch_size, num_examples)])<br>        <span class="hljs-keyword">yield</span> features[batch_indices], labels[batch_indices]<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, device = <span class="hljs-number">32</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>num_epochs, num_inputs, num_outputs = <span class="hljs-number">10</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span><br>net = MLP(num_inputs, num_outputs)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels):<br>        l = net.update(X, y, lr=<span class="hljs-number">1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="结果">结果</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">W, b = net.params<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;w的估计误差: <span class="hljs-subst">&#123;true_w - W.reshape(true_w.shape)&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;b的估计误差: <span class="hljs-subst">&#123;true_b - b&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>线性回归、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LSTM 网络复现</title>
    <link href="/2023/05/12/lstm/"/>
    <url>/2023/05/12/lstm/</url>
    
    <content type="html"><![CDATA[<p>LSTM 网络复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[ I_{t} = \sigma(X_{t}W_{xi} +H_{t-1}W_{hi} + b_{i}) \]</span></p><p><span class="math display">\[ F_{t} = \sigma(X_{t}W_{xf} +H_{t-1}W_{hf} + b_{f}) \]</span></p><p><span class="math display">\[ O_{t} = \sigma(X_{t}W_{xo} +H_{t-1}W_{ho} + b_{o}) \]</span></p><p><span class="math display">\[ \hat{C}_{t} = tanh(X_{t}W_{xc} +H_{t-1}W_{hc} + b_{c}) \]</span></p><p><span class="math display">\[ C_{t} = F_{t} \odot C_{t-1} + I_{t}\odot \hat{C}_{t} \]</span></p><p><span class="math display">\[ H_{t} = O_{t} \odot tanh(C_{t})\]</span></p><p><span class="math display">\[ Y_{t} = H_{t}W_{hq} + b_{q}\]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><h1 id="构建-lstm-网络">构建 LSTM 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LSTM</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = self.init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>(<span class="hljs-params">self</span>):<br>    num_inputs = num_outputs = self.vocab_size; num_hiddens = self.num_hiddens<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">three</span>():<br>        <span class="hljs-keyword">return</span> (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))<br>    W_xi, W_hi, b_i = three(); W_xf, W_hf, b_f = three(); W_xo, W_ho, b_o = three(); W_xc, W_hc, b_c = three();<br>    W_hq, b_q = normal((num_hiddens, num_outputs)), torch.zeros(num_outputs, device=device)<br>    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="初始化隐藏状态">初始化隐藏状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, batch_size</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, self.num_hiddens), device=device), torch.zeros((batch_size, self.num_hiddens), device=device))<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, state</span>):<br>    C, H = state; outputs = []<br>    W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q = self.params<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        I = torch.sigmoid(X @ W_xi + H @ W_hi + b_i)<br>        F = torch.sigmoid(X @ W_xf + H @ W_hf + b_f)<br>        O = torch.sigmoid(X @ W_xo + H @ W_ho + b_o)<br>        C_hat = torch.tanh(X @ W_xc + H @ W_hc + b_c)<br>        C = F * C + I * C_hat<br>        H = O * torch.tanh(C)<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (C, H)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>    inputs = F.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>    <span class="hljs-keyword">return</span> self.forward(inputs, state)<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params:<br>            p.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="数据分割">数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot;</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure><h1 id="迭代器">迭代器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;错误：未知词元类型：&#x27;</span> + token)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_vocab</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;词元索引列表和词表&quot;&quot;&quot;</span><br>    lines = texts<br>    tokens = d2l.tokenize(lines)<br>    vocab = d2l.Vocab(tokens)<br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>: <br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = load_corpus_vocab(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, num_steps, device = <span class="hljs-number">32</span>, <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br><span class="hljs-comment"># train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br>texts = [<span class="hljs-string">&#x27;I love cat&#x27;</span>] * <span class="hljs-number">1000</span><br>train_iter, vocab = load_data(batch_size, num_steps, max_tokens=<span class="hljs-number">10000</span>)<br>num_epochs, num_hiddens = <span class="hljs-number">100</span>, <span class="hljs-number">256</span><br>net = LSTM(<span class="hljs-built_in">len</span>(vocab), num_hiddens)<br>loss = torch.nn.CrossEntropyLoss()<br>updater = torch.optim.SGD(net.params, lr=<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    state = <span class="hljs-literal">None</span>; metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            state = net.init_state(batch_size)<br>        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state: s.detach_()<br>        y_hat, state = net(X, state)<br>        y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>        l = loss(y_hat, y)<br>        l.backward()<br>        net.grad_clipping(<span class="hljs-number">1</span>)<br>        updater.step()<br>        metrics[<span class="hljs-number">0</span>] += l * y.numel(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % (num_epochs // <span class="hljs-number">10</span>) == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d 困惑度 %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, torch.exp(metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>])))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">prefix, num_preds</span>):<br>    state = net.init_state(<span class="hljs-number">1</span>)<br>    outputs = [vocab[prefix[<span class="hljs-number">0</span>]]]<br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor(outputs[-<span class="hljs-number">1</span>]).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:<br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):<br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br><br>predict(<span class="hljs-string">&#x27;I love&#x27;</span>.split(<span class="hljs-string">&#x27; &#x27;</span>), <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LSTM、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GoogLeNet 网络复现</title>
    <link href="/2023/05/12/googlenet/"/>
    <url>/2023/05/12/googlenet/</url>
    
    <content type="html"><![CDATA[<p>GoogLeNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/GoogLeNet/inception.png?raw=true"></p><p><img src="https://github.com/vexentox/reproduction/blob/main/GoogLeNet/GoogLeNet%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="池化">池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚">全局平均汇聚</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="构建-googlenet-网络">构建 GoogLeNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GoogLeNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Inception</span>(<span class="hljs-params">in_channels, c1, c2, c3, c4</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>        W_1 = normal((c1, in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_1 = torch.zeros(c1, device=device)<br>        W_21 = normal((c2[<span class="hljs-number">0</span>], in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_21 = torch.zeros(c2[<span class="hljs-number">0</span>], device=device)<br>        W_22 = normal((c2[<span class="hljs-number">1</span>], c2[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_22 = torch.zeros(c2[<span class="hljs-number">1</span>], device=device)<br>        W_31 = normal((c3[<span class="hljs-number">0</span>], in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_31 = torch.zeros(c3[<span class="hljs-number">0</span>], device=device)<br>        W_32 = normal((c3[<span class="hljs-number">1</span>], c3[<span class="hljs-number">0</span>], <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_32 = torch.zeros(c3[<span class="hljs-number">1</span>], device=device)<br>        W_4 = normal((c4, in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_4 = torch.zeros(c4, device=device)<br>        <span class="hljs-keyword">return</span> [W_1, b_1, W_21, b_21, W_22, b_22, W_31, b_31, W_32, b_32, W_4, b_4]<br>    W_1 = normal((<span class="hljs-number">64</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>)); b_1 = torch.zeros(<span class="hljs-number">64</span>, device=device)<br>    W_21 = normal((<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_21 = torch.zeros(<span class="hljs-number">64</span>, device=device)<br>    W_22 = normal((<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>)); b_22 = torch.zeros(<span class="hljs-number">192</span>, device=device)<br>    inc1 = Inception(<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>), <span class="hljs-number">32</span>)<br>    inc2 = Inception(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">192</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">96</span>), <span class="hljs-number">64</span>)<br>    W_3 = [inc1, inc2]<br>    inc1 = Inception(<span class="hljs-number">480</span>, <span class="hljs-number">192</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">208</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">48</span>), <span class="hljs-number">64</span>)<br>    inc2 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">160</span>, (<span class="hljs-number">112</span>, <span class="hljs-number">224</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>)<br>    inc3 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>)<br>    inc4 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">112</span>, (<span class="hljs-number">144</span>, <span class="hljs-number">288</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>)<br>    inc5 = Inception(<span class="hljs-number">528</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>)<br>    W_4 = [inc1, inc2, inc3, inc4, inc5]<br>    inc1 = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>)<br>    inc2 = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">384</span>, (<span class="hljs-number">192</span>, <span class="hljs-number">384</span>), (<span class="hljs-number">48</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>)<br>    W_5 = [inc1, inc2]<br>    W_6 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>)); b_6 = torch.zeros(<span class="hljs-number">10</span>, device=device)<br>    self.params = [W_1, b_1, W_21, b_21, W_22, b_22, W_3, W_4, W_5, W_6, b_6]<br>    self.flt_params = [W_1, b_1, W_21, b_21, W_22, b_22]<br>    <span class="hljs-keyword">for</span> W <span class="hljs-keyword">in</span> [W_3, W_4, W_5]:<br>        <span class="hljs-keyword">for</span> inc <span class="hljs-keyword">in</span> W:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> inc:<br>                self.flt_params.append(param)<br>    self.flt_params.extend([W_6, b_6])<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)     <br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_1, b_1, W_21, b_21, W_22, b_22, W_3, W_4, W_5, W_6, b_6 = self.params<br>    X = relu(conv2d(X, W_1, b_1, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>))<br>    X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    X = relu(conv2d(X, W_21, b_21))<br>    X = relu(conv2d(X, W_22, b_22, padding=<span class="hljs-number">1</span>))<br>    X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Inception</span>(<span class="hljs-params">X, inc</span>):<br>        [W_1, b_1, W_21, b_21, W_22, b_22, W_31, b_31, W_32, b_32, W_4, b_4] = inc<br>        p1 = relu(conv2d(X, W_1, b_1))<br>        p2 = relu(conv2d(X, W_21, b_21))<br>        p2 = relu(conv2d(p2, W_22, b_22, padding=<span class="hljs-number">1</span>))<br>        p3 = relu(conv2d(X, W_31, b_31))<br>        p3 = relu(conv2d(p3, W_32, b_32, padding=<span class="hljs-number">2</span>))<br>        p4 = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        p4 = relu(conv2d(p4, W_4, b_4))<br>        <span class="hljs-keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> W <span class="hljs-keyword">in</span> [W_3, W_4]:<br>        <span class="hljs-keyword">for</span> inc <span class="hljs-keyword">in</span> W:<br>            X = Inception(X, inc)<br>        X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> inc <span class="hljs-keyword">in</span> W_5:<br>        X = Inception(X, inc)<br>    X = AdaptiveAvgPool2d(X, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    X = X @ W_6 + b_6<br>    Y = sigmoid(X)<br>    <span class="hljs-keyword">return</span> Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度剪裁">梯度剪裁</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">net = GoogLeNet()<br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">16</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>        i += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;i %d loss %f&#x27;</span> % (i + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br>        <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">30</span>:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GoogLeNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GRU 网络复现</title>
    <link href="/2023/05/12/gru/"/>
    <url>/2023/05/12/gru/</url>
    
    <content type="html"><![CDATA[<p>GRU 网络复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[ R_{t} = \sigma(X_{t}W_{xr} +H_{t-1}W_{hr} + b_{r}) \]</span></p><p><span class="math display">\[ Z_{t} = \sigma(X_{t}W_{xz} +H_{t-1}W_{hz} + b_{z}) \]</span></p><p><span class="math display">\[ \hat{H}_{t} = tanh(X_{t}W_{xh}+(R_{t}\odot H_{t-1})W_{hh} + b_{h}) \]</span></p><p><span class="math display">\[ H_{t} = Z_{t} \odot H_{t-1} + (1 -Z_{t}) \odot \hat{H}_{t} \]</span></p><p><span class="math display">\[ Y_{t} = H_{t}W_{hq} +b_{q}\]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><h1 id="构建-gru-网络">构建 GRU 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GRU</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens, get_params, init_state, forward_fn</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = self.init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>(<span class="hljs-params">self</span>):<br>    num_inputs = num_outputs = self.vocab_size<br>    num_hiddens = self.num_hiddens<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">three</span>():<br>        <span class="hljs-keyword">return</span> (normal((num_inputs, num_hiddens)), <br>                normal((num_hiddens, num_hiddens)), <br>                torch.zeros(num_hiddens, device=device))<br>    W_xr, W_hr, b_r = three()<br>    W_xz, W_hz, b_z = three()<br>    W_xh, W_hh, b_h = three()<br>    W_hq = normal((num_hiddens, num_outputs)); b_q = torch.zeros(num_outputs, device=device)<br>    params = [W_xr, W_hr, b_r, W_xz, W_hz, b_z, W_xh, W_hh, b_h, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="初始化隐藏状态">初始化隐藏状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, batch_size</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, self.num_hiddens), device=device),)<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, state</span>):<br>    W_xr, W_hr, b_r, W_xz, W_hz, b_z, W_xh, W_hh, b_h, W_hq, b_q = self.params<br>    outputs = []; H, = state<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        R = torch.sigmoid(X @ W_xr + H @ W_hr + b_r)<br>        Z = torch.sigmoid(X @ W_xz + H @ W_hz + b_z)<br>        H_hat = torch.tanh(X @ W_xh + (R * H) @ W_hh + b_h)<br>        H = Z * H + (<span class="hljs-number">1</span> - Z) * H_hat<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H, )<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>    inputs = F.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>    <span class="hljs-keyword">return</span> self.forward(inputs, state)<br></code></pre></td></tr></table></figure><h2 id="梯度剪裁">梯度剪裁</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(param.grad ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param.grad[:] *= theta / norm      <br></code></pre></td></tr></table></figure><h1 id="数据分割">数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot;</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure><h1 id="迭代器">迭代器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;错误：未知词元类型：&#x27;</span> + token)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_vocab</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;词元索引列表和词表&quot;&quot;&quot;</span><br>    lines = texts<br>    tokens = d2l.tokenize(lines)<br>    vocab = d2l.Vocab(tokens)<br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>: <br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = load_corpus_vocab(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_iter, lr, num_epochs</span>):<br>    loss = nn.CrossEntropyLoss()<br>    updater = torch.optim.SGD(net.params, lr)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_epochs), ncols=<span class="hljs-number">100</span>):<br>        state = <span class="hljs-literal">None</span><br>        metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>            <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                state = net.init_state(X.shape[<span class="hljs-number">0</span>])<br>            <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state: s.detach_()<br>            y_hat, state = net(X, state)<br>            y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>            l = loss(y_hat, y.long()).mean()<br>            l.backward()<br>            net.grad_clipping(<span class="hljs-number">1</span>)<br>            updater.step()<br>            metrics[<span class="hljs-number">0</span>] += l * y.numel(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>        l = torch.exp(metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;困惑度 %f&#x27;</span> % l)<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br><span class="hljs-comment"># train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br>texts = [<span class="hljs-string">&#x27;I love cat&#x27;</span>] * <span class="hljs-number">1000</span><br>train_iter, vocab = load_data(batch_size, num_steps, max_tokens=<span class="hljs-number">10000</span>)<br>vocab_size, num_hiddens, device = <span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>num_epochs, lr = <span class="hljs-number">10</span>, <span class="hljs-number">1</span><br>net = GRU(vocab_size, num_hiddens, get_params, init_gru_state, gru)<br>train(net, train_iter, lr, num_epochs)<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">prefix, num_preds, net, vocab</span>):<br>    state = net.init_state(<span class="hljs-number">1</span>); outputs = [vocab[prefix[<span class="hljs-number">0</span>]]]<br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor([outputs[-<span class="hljs-number">1</span>]], device=device).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:<br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):<br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br><br>predict(<span class="hljs-string">&#x27;I love&#x27;</span>.split(<span class="hljs-string">&#x27; &#x27;</span>), <span class="hljs-number">1</span>, net, vocab)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GRU、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ResNet 网络复现</title>
    <link href="/2023/05/12/resnet/"/>
    <url>/2023/05/12/resnet/</url>
    
    <content type="html"><![CDATA[<p>ResNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/ResNet/%E6%AE%8B%E5%B7%AE%E5%9D%97.png?raw=true"></p><p><img src="https://github.com/vexentox/reproduction/blob/main/ResNet/ResNet%E6%9E%B6%E6%9E%84%20-%20%E5%89%AF%E6%9C%AC.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚层">全局平均汇聚层</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="构建-resnet-网络">构建 ResNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual</span>(<span class="hljs-params">input_channels, num_channels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;残差块&quot;&quot;&quot;</span><br>        W_1 = normal((num_channels, input_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_1 = torch.zeros(num_channels, device=device)<br>        W_2 = normal((num_channels, num_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_2 = torch.zeros(num_channels, device=device)<br>        <span class="hljs-keyword">return</span> [W_1, b_1, W_2, b_2]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual_use_1x1conv</span>(<span class="hljs-params">input_channels, num_channels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;带1*1卷积核的残差块&quot;&quot;&quot;</span><br>        W_1 = normal((num_channels, input_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_1 = torch.zeros(num_channels, device=device)<br>        W_2 = normal((num_channels, num_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_2 = torch.zeros(num_channels, device=device)<br>        W_3 = normal((num_channels, input_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_3 = torch.zeros(num_channels, device=device)<br>        <span class="hljs-keyword">return</span> [W_1, b_1, W_2, b_2, W_3, b_3]   <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">input_channels, num_channels, num_residuals, first_block=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;resnet 块&quot;&quot;&quot;</span><br>        blk = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>                blk.append(Residual_use_1x1conv(input_channels, num_channels))<br>            <span class="hljs-keyword">else</span>:<br>                blk.append(Residual(num_channels, num_channels))<br>        <span class="hljs-keyword">return</span> blk<br>    W_conv = normal((<span class="hljs-number">64</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>)); b_conv = torch.zeros(<span class="hljs-number">64</span>, device=device)<br>    resnet_b1 = resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, first_block=<span class="hljs-literal">True</span>)<br>    resnet_b2 = resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>)<br>    resnet_b3 = resnet_block(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>)<br>    resnet_b4 = resnet_block(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">2</span>)<br>    W_linear = normal((<span class="hljs-number">512</span>, <span class="hljs-number">10</span>)); b_linear = torch.zeros(<span class="hljs-number">10</span>, device=device)<br>    self.params = [W_conv, b_conv, resnet_b1, resnet_b2, resnet_b3, resnet_b4, W_linear, b_linear]<br>    self.flt_params = [W_conv, b_conv]<br>    <span class="hljs-keyword">for</span> resnet_b <span class="hljs-keyword">in</span> [resnet_b1, resnet_b2, resnet_b3, resnet_b4]:<br>        <span class="hljs-keyword">for</span> res <span class="hljs-keyword">in</span> resnet_b:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> res:<br>                self.flt_params.append(param)<br>    self.flt_params.extend([W_linear, b_linear])<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)   <br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_conv, b_conv, resnet_b1, resnet_b2, resnet_b3, resnet_b4, W_linear, b_linear = self.params<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual</span>(<span class="hljs-params">X, params, strides=<span class="hljs-number">1</span></span>):<br>        W_1, b_1, W_2, b_2 = params<br>        Y = relu(conv2d(X, W_1, b_1, stride=strides, padding=<span class="hljs-number">1</span>))<br>        Y = conv2d(Y, W_2, b_2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        Y += X<br>        Y = relu(Y)<br>        <span class="hljs-keyword">return</span> Y<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual_use_1x1conv</span>(<span class="hljs-params">X, params, strides=<span class="hljs-number">1</span></span>):<br>        W_1, b_1, W_2, b_2, W_3, b_3 = params<br>        Y = relu(conv2d(X, W_1, b_1, stride=strides, padding=<span class="hljs-number">1</span>))<br>        Y = conv2d(Y, W_2, b_2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        Y += conv2d(X, W_3, b_3, stride=strides)<br>        Y = relu(Y)<br>        <span class="hljs-keyword">return</span> Y<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">X, params, first_block=<span class="hljs-literal">False</span></span>):<br>        num_residuals = <span class="hljs-built_in">len</span>(params)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>            param = params[i]<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>                X = Residual_use_1x1conv(X, param, strides=<span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">else</span>:<br>                X = Residual(X, param)<br>        <span class="hljs-keyword">return</span> X<br>    X = relu(conv2d(X, W_conv, b_conv, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>))<br>    X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    X = resnet_block(X, resnet_b1, first_block=<span class="hljs-literal">True</span>)<br>    X = resnet_block(X, resnet_b2)<br>    X = resnet_block(X, resnet_b3)<br>    X = resnet_block(X, resnet_b4)<br>    X = AdaptiveAvgPool2d(X, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    Y = sigmoid(X @ W_linear + b_linear)<br>    <span class="hljs-keyword">return</span> Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">net = ResNet()<br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">16</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ResNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RNN 网络复现</title>
    <link href="/2023/05/12/rnn/"/>
    <url>/2023/05/12/rnn/</url>
    
    <content type="html"><![CDATA[<p>RNN 网络复现</p><span id="more"></span><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure><h1 id="构建-rnn-网络">构建 RNN 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    num_inputs = num_outputs = self.vocab_size; num_hiddens = self.num_hiddens<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    W_xh = normal((num_inputs, num_hiddens)); <br>    W_hh = normal((num_hiddens, num_hiddens))<br>    b_h = torch.zeros(num_hiddens, device=device)<br>    W_hq = normal((num_hiddens, num_outputs)); <br>    b_q = torch.zeros(num_outputs, device=device)<br>    params = [W_xh, W_hh, b_h, W_hq, b_q]<br><br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="初始化隐藏状态">初始化隐藏状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, batch_size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化隐藏状态&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, self.num_hiddens), device=device), )<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, inputs, state</span>):    <br>    W_xh, W_hh, b_h, W_hq, b_q = self.params<br>    H, = state<br>    outputs = []<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        H = torch.tanh(X @ W_xh + H @ W_hh + b_h)<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H, )<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>    inputs = torch.nn.functional.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>    <span class="hljs-keyword">return</span> self._forward(inputs, state)<br></code></pre></td></tr></table></figure><h2 id="梯度剪裁">梯度剪裁</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params:<br>            p.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="数据分割">数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_random</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用随机抽样生成一个小批量子序列&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1</span><br>    corpus = corpus[random.randint(<span class="hljs-number">0</span>, num_steps - <span class="hljs-number">1</span>):]<br>    <span class="hljs-comment"># 减去1，是因为我们需要考虑标签</span><br>    num_subseqs = (<span class="hljs-built_in">len</span>(corpus) - <span class="hljs-number">1</span>) // num_steps<br>    <span class="hljs-comment"># 长度为num_steps的子序列的起始索引</span><br>    initial_indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_subseqs * num_steps, num_steps))<br>    <span class="hljs-comment"># 在随机抽样的迭代过程中，</span><br>    <span class="hljs-comment"># 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻</span><br>    random.shuffle(initial_indices)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">data</span>(<span class="hljs-params">pos</span>):<br>        <span class="hljs-comment"># 返回从pos位置开始的长度为num_steps的序列</span><br>        <span class="hljs-keyword">return</span> corpus[pos: pos + num_steps]<br><br>    num_batches = num_subseqs // batch_size<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, batch_size * num_batches, batch_size):<br>        <span class="hljs-comment"># 在这里，initial_indices包含子序列的随机起始索引</span><br>        initial_indices_per_batch = initial_indices[i: i + batch_size]<br>        X = [data(j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        Y = [data(j + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        <span class="hljs-keyword">yield</span> torch.tensor(X), torch.tensor(Y)<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 从随机偏移量开始划分序列</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure><h1 id="迭代器">迭代器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;错误：未知词元类型：&#x27;</span> + token)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_vocab</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;词元索引列表和词表&quot;&quot;&quot;</span><br>    lines = texts<br>    tokens = d2l.tokenize(lines)<br>    vocab = d2l.Vocab(tokens)<br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>: <br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = load_corpus_vocab(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, num_steps, device = <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>texts = [<span class="hljs-string">&#x27;I am a cat&#x27;</span>] * <span class="hljs-number">1000</span><br>train_iter, vocab = load_data(batch_size, num_steps, max_tokens=<span class="hljs-number">10000</span>)<br>num_epochs, lr = <span class="hljs-number">10</span>, <span class="hljs-number">1</span><br>net = RNN(<span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>)<br>updater = torch.optim.SGD(net.params, lr)<br>loss = torch.nn.CrossEntropyLoss()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    state = <span class="hljs-literal">None</span><br>    metric = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            state = net.init_state(batch_size=X.shape[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state: s.detach_()<br>        y_hat, state = net(X, state)<br>        y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>        l = loss(y_hat, y.long()).mean()<br>        updater.zero_grad()<br>        l.backward()<br>        net.grad_clipping(<span class="hljs-number">1</span>)<br>        updater.step()<br>        metric[<span class="hljs-number">0</span>] += l * y.numel(); metric[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d 困惑度 %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, torch.exp(metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>])))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">prefix, num_preds, net, vocab, device</span>):<br>    state = net.init_state(batch_size=<span class="hljs-number">1</span>)<br>    outputs = [vocab[prefix[<span class="hljs-number">0</span>]]]<br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor([outputs[-<span class="hljs-number">1</span>]], device=device).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:<br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):<br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br>predict(<span class="hljs-string">&#x27;I am a&#x27;</span>.split(<span class="hljs-string">&#x27; &#x27;</span>), <span class="hljs-number">1</span>, net, vocab, device)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文复现</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RNN、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python IO 优化</title>
    <link href="/2023/03/23/python_IO_%E4%BC%98%E5%8C%96/"/>
    <url>/2023/03/23/python_IO_%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>python IO 优化</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.setrecursionlimit(<span class="hljs-built_in">int</span>(<span class="hljs-number">1e7</span>))<br><span class="hljs-built_in">input</span> = sys.stdin.readline<br><span class="hljs-built_in">print</span> = sys.stdout.write<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>tricks</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python, IO, 优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>裁剪序列 (线段树优化Dp) From 算法进阶指南</title>
    <link href="/2023/03/23/%E7%AE%97%E6%B3%95%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97_%E8%A3%81%E5%89%AA%E5%BA%8F%E5%88%97/"/>
    <url>/2023/03/23/%E7%AE%97%E6%B3%95%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97_%E8%A3%81%E5%89%AA%E5%BA%8F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<p>线段树优化dp</p><span id="more"></span><h2 id="链接">链接</h2><p><ahref="https://www.acwing.com/problem/content/description/301/">https://www.acwing.com/problem/content/description/301/</a></p><h2 id="题意">题意</h2><p><span class="math inline">\(~~~~\)</span>给定一个长度为 <spanclass="math inline">\(N\)</span> 的序列 <spanclass="math inline">\(A\)</span>，要求把该序列分成若干段，在满足每段中所有数的和不超过<span class="math inline">\(M\)</span>的前提下，让每段中所有数的最大值之和最小。<br /><span class="math inline">\(~~~~\)</span>试计算这个最小值。</p><h2 id="题解">题解</h2><p><span class="math inline">\(~~~~\)</span>考虑 <spanclass="math inline">\(DP\)</span>。<br /><span class="math inline">\(~~~~\)</span>设状态： <spanclass="math display">\[f[i]：前 i 个数中每段中所有数的最大值之和的最小值， i \in [1, n]\]</span> <span class="math inline">\(~~~~\)</span> 对于 <spanclass="math inline">\(i\)</span>，枚举它转移的上一个答案 <spanclass="math inline">\(f[j]\)</span>，更新为 <spanclass="math inline">\(i\)</span> 前面的若干个数（满足 <spanclass="math inline">\(\sum_{k=j+1}^{i} a[k] &lt;=M\)</span>）中的最大值，取最小值。<br /><span class="math inline">\(~~~~\)</span> 即状态转移方程为： <spanclass="math display">\[f[i] = \min\{f[j] + \max\{a[j+1], a[j+2], ..., a[i]\}\}, 其中j \in [1,i], \sum_{k=j+1}^{i} a[k] &lt;= M\]</span> <span class="math inline">\(~~~~\)</span> 注意到 <spanclass="math display">\[\max\{a[i]\} &lt;= \max\{a[i], a[i-1]\} &lt;= ... &lt;= \max\{a[j+1],a[j+2], ..., a[i]\}\]</span> <span class="math inline">\(~~~~\)</span> 因此对于每一个 <spanclass="math inline">\(i\)</span>，可以用单调栈找到 <spanclass="math inline">\(&gt;a[i]\)</span> 的第一个数 <spanclass="math inline">\(a[pre[i]]\)</span>，维护 <spanclass="math inline">\(i\)</span> 之前 <span class="math inline">\(\lea[i]\)</span> 的一段连续的区间 <span class="math inline">\([pre[i]+1,i]\)</span>，这段区间的最大值即为 <spanclass="math inline">\(a[i]\)</span>。<br /><span class="math inline">\(~~~~\)</span> 考虑线段树优化，对于 <spanclass="math inline">\(i\)</span>，由于 <spanclass="math inline">\(f[i]\)</span> 是固定的，因此</p><ul><li>将 <span class="math inline">\(f[i]\)</span> 赋给线段树的第 <spanclass="math inline">\(i\)</span> 位<br /></li><li>在由单调栈维护出来的区间 <span class="math inline">\([pre[i]+1,i]\)</span> 加上 <span class="math inline">\(a[i]\)</span><br /></li><li>使用二分找到满足 <span class="math inline">\(\sum_{k=j+1}^{i} a[k]&lt;= M\)</span> 的 <span class="math inline">\(j\)</span><br /></li><li><span class="math inline">\(f[i] = query(j+1, i)\)</span></li></ul><h2 id="python-代码">python 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.setrecursionlimit(<span class="hljs-built_in">int</span>(<span class="hljs-number">1e7</span>))<br><span class="hljs-built_in">input</span> = sys.stdin.readline<br><span class="hljs-built_in">print</span> = sys.stdout.write<br>n, L = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>inf = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e18</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, l=<span class="hljs-number">0</span>, r=<span class="hljs-number">0</span>, v=inf, mn=inf, add=inf</span>):<br>        self.l, self.r, self.v, self.mn, self.add = l, r, v, mn, add<br>tr = [Node() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(<span class="hljs-number">1e5</span>)&lt;&lt;<span class="hljs-number">2</span>)]<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ls</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">return</span> u &lt;&lt; <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rs</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">return</span> u &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mid</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">return</span> tr[u].l + tr[u].r &gt;&gt; <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build</span>(<span class="hljs-params">u, l, r</span>):<br>    tr[u] = Node(l, r)<br>    <span class="hljs-keyword">if</span> l == r:<br>        <span class="hljs-keyword">return</span><br>    build(ls(u), l, mid(u))<br>    build(rs(u), mid(u)+<span class="hljs-number">1</span>, r)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pushup</span>(<span class="hljs-params">u</span>):<br>    tr[u].mn = <span class="hljs-built_in">min</span>(tr[ls(u)].mn, tr[rs(u)].mn)<br>    tr[u].v = <span class="hljs-built_in">min</span>(tr[ls(u)].v, tr[rs(u)].v)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pushdown</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">if</span> tr[u].add != inf:<br>        tr[ls(u)].mn = tr[ls(u)].v + tr[u].add<br>        tr[rs(u)].mn = tr[rs(u)].v + tr[u].add<br>        tr[ls(u)].add = tr[u].add<br>        tr[rs(u)].add = tr[u].add<br>        tr[u].add = inf<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">change</span>(<span class="hljs-params">u, x, v</span>):<br>    <span class="hljs-keyword">if</span> tr[u].l == tr[u].r:<br>        tr[u].mn = inf<br>        tr[u].v = v<br>        <span class="hljs-keyword">return</span><br>    pushdown(u)<br>    <span class="hljs-keyword">if</span> x &lt;= mid(u):<br>        change(ls(u), x, v)<br>    <span class="hljs-keyword">else</span>:<br>        change(rs(u), x, v)<br>    pushup(u)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">u, l, r, v</span>):<br>    <span class="hljs-keyword">if</span> l &lt;= tr[u].l <span class="hljs-keyword">and</span> tr[u].r &lt;= r:<br>        tr[u].mn = tr[u].v + v<br>        tr[u].add = v<br>        <span class="hljs-keyword">return</span><br>    pushdown(u)<br>    <span class="hljs-keyword">if</span> l &lt;= mid(u):<br>        update(ls(u), l, r, v)<br>    <span class="hljs-keyword">if</span> r &gt; mid(u):<br>        update(rs(u), l, r, v)<br>    pushup(u)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">query</span>(<span class="hljs-params">u, l, r</span>):<br>    <span class="hljs-keyword">if</span> l &lt;= tr[u].l <span class="hljs-keyword">and</span> tr[u].r &lt;= r:<br>        <span class="hljs-keyword">return</span> tr[u].mn<br>    res = inf<br>    pushdown(u)<br>    <span class="hljs-keyword">if</span> l &lt;= mid(u):<br>        res = <span class="hljs-built_in">min</span>(res, query(ls(u), l, r))<br>    <span class="hljs-keyword">if</span> r &gt; mid(u):<br>        res = <span class="hljs-built_in">min</span>(res, query(rs(u), l, r))<br>    <span class="hljs-keyword">return</span> res<br>h = [<span class="hljs-number">0</span>] + [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>sw = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>    sw[i] = sw[i-<span class="hljs-number">1</span>] + h[i]<br>stk = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>top = <span class="hljs-number">1</span><br>stk[top] = <span class="hljs-number">1</span><br>pre = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, n+<span class="hljs-number">1</span>):<br>    <span class="hljs-keyword">while</span> top &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> h[stk[top]] &lt;= h[i]:<br>        top -= <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> top &gt; <span class="hljs-number">0</span>:<br>        pre[i] = stk[top]<br>    top += <span class="hljs-number">1</span><br>    stk[top] = i<br>f = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_bound</span>(<span class="hljs-params">l, r, x</span>):<br>    <span class="hljs-keyword">while</span> l &lt; r:<br>        mid = l + r &gt;&gt; <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> sw[mid] &gt;= x:<br>            r = mid<br>        <span class="hljs-keyword">else</span>:<br>            l = mid + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> r<br>build(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, n)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>    change(<span class="hljs-number">1</span>, i, f[i-<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">if</span> pre[i] + <span class="hljs-number">1</span> &lt;= i:<br>        update(<span class="hljs-number">1</span>, pre[i] + <span class="hljs-number">1</span>, i, h[i])<br>    left = lower_bound(<span class="hljs-number">0</span>, i, sw[i] - L)<br>    <span class="hljs-keyword">if</span> left &lt; i:<br>        f[i] = query(<span class="hljs-number">1</span>, left+<span class="hljs-number">1</span>, i)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d\n&#x27;</span> % f[n])<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>裁剪序列, 算法进阶指南, 线段树, DP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Nebius Welcome Round (Div. 1 + Div. 2) a - D</title>
    <link href="/2023/03/20/cf_1804/"/>
    <url>/2023/03/20/cf_1804/</url>
    
    <content type="html"><![CDATA[<p>A (思维) B (贪心) C (数论) D (贪心)</p><span id="more"></span><h2 id="链接">链接</h2><p><ahref="https://codeforces.com/contest/1804">https://codeforces.com/contest/1804</a></p><h2 id="a">A</h2><h3 id="题意">题意</h3><p><span class="math inline">\(~~~~\)</span> 从 <spanclass="math inline">\((0, 0)\)</span>开始走，每次只能走上下左右四个方向，走一步，且方向和上一次不同，问走到<span class="math inline">\((a, b)\)</span> 最短步数。</p><h3 id="题解">题解</h3><p><span class="math inline">\(~~~~\)</span> 一般地，将 <spanclass="math inline">\((0, 0)\)</span> 和 <span class="math inline">\((a,b)(a &lt; b \ and \ a &gt; 0 \ and \ b &gt; 0)\)</span>视为长方形的两个顶点，则最优策略是从 <span class="math inline">\((0,0)\)</span> 走到 <span class="math inline">\((a, a)\)</span>，在从 <spanclass="math inline">\((a, a)\)</span> 走到 <spanclass="math inline">\((a, b)\)</span>。<br /><span class="math inline">\(~~~~\)</span> 则答案为 <spanclass="math inline">\(2 * (b - a) - 1\)</span></p><h3 id="python-代码">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    x, y = [<span class="hljs-built_in">abs</span>(<span class="hljs-built_in">int</span>(_)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    <span class="hljs-keyword">if</span> x &gt; y:<br>        x, y = y, x<br>    res = <span class="hljs-number">2</span> * x<br>    <span class="hljs-keyword">if</span> y &gt; x:<br>        res+=<span class="hljs-number">2</span> * (y-x)-<span class="hljs-number">1</span><br><br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><h2 id="b">B</h2><h3 id="题意-1">题意</h3><p><span class="math inline">\(~~~~\)</span> 给出一些区间 <spanclass="math inline">\([t_{i}, t_{i}+w], t_{i} \le t_{i+1},i \in [1,n]\)</span>，要求使用数量最少的个区间 <span class="math inline">\([x,x+w]\)</span>，其中 <span class="math inline">\(x\)</span>自定，使得所有的区间和 <span class="math inline">\([x, x+w]\)</span>有交集。</p><h3 id="题解-1">题解</h3><p><span class="math inline">\(~~~~\)</span> 考虑贪心。从前往后遍历<span class="math inline">\(t_{i}\)</span>，以 <spanclass="math inline">\(t_{i} + w\)</span> 作为左边界，<spanclass="math inline">\(t_{i} + w+d\)</span>作为右边界，寻找和该区间相交的区间，直到下一个区间不再与该区间相交，则另起一个新的区间。</p><h3 id="python-代码-1">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> *<br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, k, d, w = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    right = -<span class="hljs-number">1</span><br>    res = <span class="hljs-number">0</span><br>    nowk = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">if</span> a[i] &lt;= right <span class="hljs-keyword">and</span> nowk:<br>            nowk -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            res += <span class="hljs-number">1</span><br>            right = a[i] + w + d<br>            nowk = k - <span class="hljs-number">1</span><br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><h2 id="c">C</h2><h3 id="题意-2">题意</h3><p><span class="math inline">\(~~~~\)</span> 找到一个 <spanclass="math inline">\(f, f \in [1, p]\)</span>，使得 <spanclass="math inline">\((x + \frac{f * (f + 1)}{2}) \% n == 0\)</span>成立。</p><h3 id="题解-2">题解</h3><p><span class="math inline">\(~~~~\)</span> 上结论， <spanclass="math display">\[\frac{(a * n + b) * (a * n + b + 1)}{2} \ \% n = (\frac{(a * n) * (a * n+ 1)}{2} \% n + \frac{b * (b + 1)}{2} \% n) \% n\]</span> <span class="math inline">\(~~~~\)</span> 证明待补。<br /><span class="math inline">\(~~~~\)</span> 因此，<spanclass="math inline">\(f = a * n + b, b &lt; n\)</span>，枚举 <spanclass="math inline">\(a\)</span> 即可。</p><h3 id="python-代码-2">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> *<br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, x, p = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    s = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>    mp = <span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        s[i] = i*(i+<span class="hljs-number">1</span>)//<span class="hljs-number">2</span> % n<br>        <span class="hljs-keyword">if</span> mp.__contains__(s[i]):<br>            mp[s[i]] = <span class="hljs-built_in">min</span>(mp[s[i]], i)<br>        <span class="hljs-keyword">else</span>:<br>            mp.update(&#123;s[i]: i&#125;)<br>    ok = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        now = (<span class="hljs-number">2</span>*n-s[n]*a%n-x)%n<br>        <span class="hljs-keyword">if</span> mp.__contains__(now) <span class="hljs-keyword">and</span> mp[now] + a*n &lt;= p:<br>            ok = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">if</span> ok:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;YES&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;NO&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="d">D</h2><h3 id="题意-3">题意</h3><p><span class="math inline">\(~~~~\)</span> 给一个 $ n m , 4|m$ 的<span class="math inline">\(01\)</span>矩阵，对于每一行，满足两个连在一起的块数量和单个块的数量都为 <spanclass="math inline">\(\frac{m}{4}\)</span>。<br /><span class="math inline">\(~~~~\)</span>要求分配两种块的位置，使得至少有一个 <spanclass="math inline">\(1\)</span> 的块的数量最少或最多。</p><h3 id="题解-3">题解</h3><p><span class="math inline">\(~~~~\)</span>显然每一行是独立的。记每一行 <span class="math inline">\(1\)</span>的数量为 $ cnt1 $。<br /><span class="math inline">\(~~~~\)</span> 对于最小值，贪心的找每一行<span class="math inline">\(11\)</span> 块数量 $ cnt11 $。</p><ul><li>如果 <span class="math inline">\(cnt11 \le\frac{m}{4}\)</span>，答案为 <span class="math inline">\(cnt1 - 2 \timescnt11 + cnt11\)</span><br /></li><li>如果 <span class="math inline">\(cnt11 &gt;\frac{m}{4}\)</span>，答案为 <span class="math inline">\(cnt1 - 2 \times\frac{m}{4} + \frac{m}{4}\)</span></li></ul><p><span class="math inline">\(~~~~\)</span>对于最大值，贪心的找每一个不是 <span class="math inline">\(11\)</span>块的数量 <span class="math inline">\(cnt11n\)</span>。</p><ul><li>如果 <span class="math inline">\(cnt11 \le \frac{m}{4}\)</span>，则<span class="math inline">\(cnt11 = \frac{m}{4} -cnt11n\)</span>，答案为 <span class="math inline">\(cnt1 - 2 \timescnt11 + cnt11\)</span><br /></li><li>如果 <span class="math inline">\(cnt11 &gt; \frac{m}{4}\)</span>，则<span class="math inline">\(cnt11 = \frac{m}{4} - cnt11n\)</span>,答案为 <span class="math inline">\(cnt1\)</span></li></ul><h3 id="python-代码-3">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">n, m = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>mn, mx = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    s = <span class="hljs-built_in">input</span>()<br>    cnt1 = s.count(<span class="hljs-string">&#x27;1&#x27;</span>)<br>    x = <span class="hljs-number">0</span><br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i &lt; m:<br>        <span class="hljs-keyword">if</span> i + <span class="hljs-number">1</span> &lt; m <span class="hljs-keyword">and</span> s[i] == <span class="hljs-string">&#x27;1&#x27;</span> <span class="hljs-keyword">and</span> s[i+<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;1&#x27;</span>:<br>            x += <span class="hljs-number">1</span><br>            i += <span class="hljs-number">1</span><br>        i += <span class="hljs-number">1</span><br>    mn += cnt1 - <span class="hljs-built_in">min</span>(m//<span class="hljs-number">4</span>, x)<br>    x = <span class="hljs-number">0</span><br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i &lt; m:<br>        <span class="hljs-keyword">if</span> i + <span class="hljs-number">1</span> &lt; m <span class="hljs-keyword">and</span> (s[i] == <span class="hljs-string">&#x27;0&#x27;</span> <span class="hljs-keyword">or</span> s[i] != s[i+<span class="hljs-number">1</span>]):<br>            x += <span class="hljs-number">1</span><br>            i += <span class="hljs-number">1</span><br>        i += <span class="hljs-number">1</span><br>    mx += cnt1 - <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, (m//<span class="hljs-number">4</span> - x))<br><span class="hljs-built_in">print</span>(mn, mx)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, A, B, C, D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Educational Codeforces Round 143 (Rated for Div. 2) C - D</title>
    <link href="/2023/03/15/cf_1795/"/>
    <url>/2023/03/15/cf_1795/</url>
    
    <content type="html"><![CDATA[<p>C (二分) D (组合数学) <span id="more"></span></p><h2 id="链接">链接</h2><p><ahref="https://codeforces.com/contest/1795">https://codeforces.com/contest/1795</a></p><h2 id="c-二分">C (二分)</h2><h3 id="题意">题意</h3><p><span class="math inline">\(~~~~\)</span>给两个数组 <spanclass="math inline">\(a\)</span>, <spanclass="math inline">\(b\)</span>，进行 <spanclass="math inline">\(n\)</span> 轮操作，对于第 <spanclass="math inline">\(k\)</span> 次操作，<spanclass="math inline">\(\forall i \in [1, n-k+1], a[i] -= min(b[i+k-1],a[i])\)</span>，对第 <span class="math inline">\(i+k-1\)</span>个答案产生 <span class="math inline">\(min(b[i+k-1], a[i])\)</span>的贡献。</p><p><span class="math inline">\(~~~~\)</span>求出所有的答案。</p><h3 id="题解">题解</h3><p><span class="math inline">\(~~~~\)</span>反过来考虑每个 <spanclass="math inline">\(a[i]\)</span> 的贡献，对于 <spanclass="math inline">\(b[j], j &gt;= i\)</span>，它会对第 <spanclass="math inline">\(j\)</span> 个答案产生 <spanclass="math inline">\(b[j]\)</span> 的贡献，直到 <spanclass="math inline">\(a[i] &lt;= b[i] + b[i+1] + ... + b[e]\)</span>未知，特别的， <span class="math inline">\(a[i]\)</span> 对第 <spanclass="math inline">\(e\)</span> 个答案产生的贡献为 <spanclass="math inline">\(a[i] - b[i] - b[i+1] - ... - b[e-1]\)</span>。</p><p><span class="math inline">\(~~~~\)</span>因此我们可以先求出 <spanclass="math inline">\(b\)</span> 的前缀和 <spanclass="math inline">\(sb\)</span>，要计算每个 <spanclass="math inline">\(a[i]\)</span> 的贡献，我们只需要在 <spanclass="math inline">\(j \in [i, n]\)</span> 范围二分找到 <spanclass="math inline">\(sb[n] - sb[i-1] &gt;= a[i]\)</span>的第一个数，即为 <span class="math inline">\(e\)</span>。</p><h3 id="python-代码">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_bound</span>(<span class="hljs-params">num, left, right</span>):<br>    l, r = left, right<br>    <span class="hljs-keyword">while</span> l &lt; r:<br>        mid = (l + r) // <span class="hljs-number">2</span><br>        <span class="hljs-keyword">if</span> b[mid] &gt;= num:<br>            r = mid<br>        <span class="hljs-keyword">else</span>:<br>            l = mid + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> r<br><br><br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    a = [<span class="hljs-number">0</span>] + [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    b = [<span class="hljs-number">0</span>] + [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    c = b.copy()<br>    s = <span class="hljs-built_in">sum</span>(b)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(b)):<br>        b[i] += b[i - <span class="hljs-number">1</span>]<br>    f = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n + <span class="hljs-number">2</span>)]<br>    g = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n + <span class="hljs-number">2</span>)]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">if</span> a[i] + b[i-<span class="hljs-number">1</span>] &gt;= b[n]:<br>            f[i] += <span class="hljs-number">1</span><br>            f[n+<span class="hljs-number">1</span>] -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">continue</span><br>        pos = lower_bound(a[i] + b[i-<span class="hljs-number">1</span>], i, n)<br>        <span class="hljs-keyword">if</span> i != pos:<br>            f[i] += <span class="hljs-number">1</span><br>            f[pos] -= <span class="hljs-number">1</span><br>        g[pos] += a[i] + b[i-<span class="hljs-number">1</span>] - b[pos-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        f[i] += f[i-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % (f[i] * c[i] + g[i]), end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h2 id="d-组合数学">D (组合数学)</h2><h3 id="题意-1">题意</h3><p><spanclass="math inline">\(~~~~\)</span>给出每三个点一组的完全图（三个点两两相连），一共有<span class="math inline">\(\frac{n}{3} (6|n)\)</span>组，要求对所有节点染色，一共有两种颜色（红、蓝），最终的染色方案必须满足两种颜色数量相同。</p><p><spanclass="math inline">\(~~~~\)</span>在每一组中，若两个点的颜色不同，则对答案的贡献为两个点的边权。要求计算使得答案最大的染色方案的数量。模<span class="math inline">\(998244353\)</span>。</p><h3 id="题解-1">题解</h3><p><spanclass="math inline">\(~~~~\)</span>要使答案最大，只需从每个组中选出两个最大的边权对答案产生贡献即可，因此每个组中的颜色必然满足存在两个颜色相同，不妨设三中颜色分别为<span class="math inline">\(x ~ x ~ y, (x &gt;=y)\)</span>，对于每一组，只要 <span class="math inline">\(y\)</span>确定了，则 <span class="math inline">\(x\)</span> 也就确定了。</p><p><span class="math inline">\(~~~~\)</span>因此考虑 <spanclass="math inline">\(y\)</span>，要使两种颜色数量相同，只需平均分配即可，即从<span class="math inline">\(\frac{n}{3}\)</span> 个组中选 <spanclass="math inline">\(\frac{n}{6}\)</span> 个染成红色，其他 <spanclass="math inline">\(\frac{n}{6}\)</span> 个染成蓝色。因此答案为 <spanclass="math inline">\(C(\frac{n}{3}, \frac{n}{6}) \% mod\)</span>。</p><p><span class="math inline">\(~~~~\)</span>考虑一下特殊情况：</p><ul><li>当某一组 <span class="math inline">\(y\)</span> 的数量为 <spanclass="math inline">\(2\)</span> 时，<spanclass="math inline">\(y\)</span> 的位置可以选择两个与 <spanclass="math inline">\(x\)</span> 交汇处之一，因此对答案贡献 <spanclass="math inline">\(*2\)</span><br /></li><li>当某一组 <span class="math inline">\(y\)</span> 的数量为 <spanclass="math inline">\(2\)</span> 时，<spanclass="math inline">\(y\)</span>的位置可以选择任意两个点交汇处之一，因此对答案贡献 <spanclass="math inline">\(*3\)</span></li></ul><h3 id="python-代码-1">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python">N = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e5</span>)<br>f = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N + <span class="hljs-number">5</span>)]<br>inv = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N + <span class="hljs-number">5</span>)]<br>f[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>mod = <span class="hljs-number">998244353</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, N + <span class="hljs-number">1</span>):<br>    f[i] = f[i - <span class="hljs-number">1</span>] * i % mod<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">qmi</span>(<span class="hljs-params">a, b</span>):<br>    res = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> b:<br>        <span class="hljs-keyword">if</span> b &amp; <span class="hljs-number">1</span>:<br>            res = res * a % mod<br>        a = a * a % mod<br>        b &gt;&gt;= <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br><br><br>inv[N] = qmi(f[N], mod - <span class="hljs-number">2</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>    inv[i] = inv[i + <span class="hljs-number">1</span>] * (i + <span class="hljs-number">1</span>) % mod<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">C</span>(<span class="hljs-params">n, m</span>):<br>    <span class="hljs-keyword">if</span> m &gt; n:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> f[n] * inv[m] * inv[n - m] % mod<br><br><br>n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>res = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n, <span class="hljs-number">3</span>):<br>    b = a[i:i + <span class="hljs-number">3</span>]<br>    res = res * b.count(<span class="hljs-built_in">min</span>(b)) % mod<br><span class="hljs-built_in">print</span>(res * C(n//<span class="hljs-number">3</span>, n//<span class="hljs-number">6</span>) % mod)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, C, D, Educational Codeforces Round 143</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codeforces Round 857 (Div. 2) C - E</title>
    <link href="/2023/03/14/cf_1802_C_E/"/>
    <url>/2023/03/14/cf_1802_C_E/</url>
    
    <content type="html"><![CDATA[<p>C (构造) D (贪心、multiset) E (树状数组优化dp)</p><span id="more"></span><h2 id="链接">链接</h2><p><ahref="https://codeforces.com/contest/1802">https://codeforces.com/contest/1802</a></p><h2 id="c-构造">C (构造)</h2><h3 id="题意">题意</h3><p><span class="math inline">\(~~~~\)</span>构造一个 <spanclass="math inline">\(n \times m\)</span> 的矩阵，使得每一个 <spanclass="math inline">\(2 \times 2\)</span> 的子矩阵满足： <spanclass="math display">\[\begin{matrix} A_{11} \oplus A_{12} \oplus A_{21} \oplusA_{22}=A_{33}\oplus A_{34} \oplus A_{43} \oplus A_{44}\\A_{13} \oplus A_{14} \oplus A_{23} \oplus A_{24}=A_{31}\oplus A_{32}\oplus A_{41} \oplus A_{42}\end{matrix}\]</span></p><h3 id="题解">题解</h3><p><spanclass="math inline">\(~~~~\)</span>通过观察样例，可以猜想每一个子矩阵的异或和是一个常数。（待证明）</p><p><spanclass="math inline">\(~~~~\)</span>因此，我们可以随机化矩阵的第一行和第一列，并设定一个常数<span class="math inline">\(C\)</span>作为每个子矩阵的异或和。对于一个子矩阵，若已知三个数的值 <spanclass="math inline">\(A_{1}, A_{2}, A_{3}\)</span>，则第四个值 <spanclass="math inline">\(A_{4}=C \oplus A_{1} \oplus A_{2} \oplusA_{3}\)</span>。</p><h3 id="python-代码">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>mod = (<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">63</span>) - <span class="hljs-number">1</span><br>f = [[<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>)] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>)]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>):<br>    f[i][<span class="hljs-number">0</span>] = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100000000000000012</span>)<br>    f[<span class="hljs-number">0</span>][i] = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100000000000000012</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>):<br>        f[i][j] = mod ^ f[i - <span class="hljs-number">1</span>][j] ^ f[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] ^ f[i][j - <span class="hljs-number">1</span>]<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, m = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    <span class="hljs-built_in">print</span>(n*m)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % f[i][j], end=<span class="hljs-string">&#x27;&#x27;</span>)<br>        <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h2 id="d-贪心multiset">D (贪心、multiset)</h2><h3 id="题意-1">题意</h3><p><span class="math inline">\(~~~~\)</span>给出两个数组 <spanclass="math inline">\(a, b\)</span>，操作 <spanclass="math inline">\(n\)</span> 次，对于第 <spanclass="math inline">\(i\)</span> 次，每次只能从 <spanclass="math inline">\(a_{i}、b_{i}\)</span> 中选出一个，记从 <spanclass="math inline">\(a\)</span> 随选出的数列为 <spanclass="math inline">\(a_{choose}\)</span>，从 <spanclass="math inline">\(b\)</span> 中选出的数列为 <spanclass="math inline">\(b_{choose}\)</span>，目标是最小化 $| (a_{choose})- (b_{choose}) | $。</p><h3 id="题解-1">题解</h3><p><span class="math inline">\(~~~~\)</span>将 <spanclass="math inline">\(a, b\)</span> 一起按照 <spanclass="math inline">\(a\)</span> 从大到小排序，从前往后遍历 <spanclass="math inline">\(a\)</span>，对于 <spanclass="math inline">\(a_{i}\)</span>，将其作为从 <spanclass="math inline">\(a\)</span> 中选出的最大值。</p><p><span class="math inline">\(~~~~\)</span>由于 <spanclass="math inline">\(\forall j \in [1,i-1], a_{j} &lt;a_{i}\)</span>，因此，<span class="math inline">\(i\)</span> 前面的<span class="math inline">\(a\)</span> 一定不选，<spanclass="math inline">\(i\)</span> 前面的 <spanclass="math inline">\(b\)</span> 一定要选；<spanclass="math inline">\(i\)</span> 后面的 <spanclass="math inline">\(b\)</span> 可选可不选。</p><p><span class="math inline">\(~~~~\)</span>记 <spanclass="math inline">\(mxb = \max(b_{j}, j \in [1,i-1])\)</span>，则只需要在 <span class="math inline">\(i\)</span> 后面的 <spanclass="math inline">\(b\)</span> 中找到和 <spanclass="math inline">\(a_{i}\)</span> 最相近的且 <spanclass="math inline">\(&gt; mxb\)</span> 的数 <spanclass="math inline">\(b_{k}\)</span> 即可用 <spanclass="math inline">\(\left | a_{i} - b_{k} \right |\)</span>更新答案；如果没有找到，则用 <span class="math inline">\(\left | a_{i} -mxb \right |\)</span> 更新答案。</p><p><span class="math inline">\(~~~~\)</span>可用 <spanclass="math inline">\(muliset\)</span> 维护，<spanclass="math inline">\(lower_bound\)</span> 用于寻找最相近的数。</p><p><span class="math inline">\(~~~~\)</span>时间复杂度 <spanclass="math inline">\(O(nlogn)\)</span></p><h3 id="代码">代码</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;set&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for( i, L, R ) for ( int i = L; i &lt;= R; ++i )</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">5e5</span> + <span class="hljs-number">5</span>;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span> &#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-type">int</span> a, b;<br><span class="hljs-type">bool</span> <span class="hljs-keyword">operator</span>&lt;( <span class="hljs-type">const</span> Node &amp; o ) <span class="hljs-type">const</span><br>&#123;<br><span class="hljs-keyword">return</span>(a &gt; o.a);<br>&#125;<br>&#125; e[N];<br><span class="hljs-type">int</span> n;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;n );<br>multiset&lt;<span class="hljs-type">int</span>&gt; s;<br>_for( i, <span class="hljs-number">1</span>, n ) <span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d%d&quot;</span>, &amp;e[i].a, &amp;e[i].b ), s.<span class="hljs-built_in">insert</span>( e[i].b );<br><span class="hljs-built_in">sort</span>( e + <span class="hljs-number">1</span>, e + n + <span class="hljs-number">1</span> );<br><span class="hljs-type">int</span> res = <span class="hljs-number">1e9</span>, mx = <span class="hljs-number">-1e9</span>;<br>_for( i, <span class="hljs-number">1</span>, n )<br>&#123;<br>s.<span class="hljs-built_in">erase</span>( s.<span class="hljs-built_in">find</span>( e[i].b ) );<br><span class="hljs-keyword">auto</span> it = s.<span class="hljs-built_in">lower_bound</span>( e[i].a );<br><span class="hljs-keyword">if</span> ( it != s.<span class="hljs-built_in">end</span>() <span class="hljs-keyword">and</span> * it &gt; mx )<br>res = <span class="hljs-built_in">min</span>( res, <span class="hljs-built_in">abs</span>( e[i].a - *it ) );<br><span class="hljs-keyword">if</span> ( it != s.<span class="hljs-built_in">begin</span>() <span class="hljs-keyword">and</span> * <span class="hljs-built_in">prev</span>( it ) &gt; mx )<br>res = <span class="hljs-built_in">min</span>( res, <span class="hljs-built_in">abs</span>( e[i].a - *<span class="hljs-built_in">prev</span>( it ) ) );<br>res= <span class="hljs-built_in">min</span>( res, <span class="hljs-built_in">abs</span>( e[i].a - mx ) );<br>mx= <span class="hljs-built_in">max</span>( e[i].b, mx );<br>&#125;<br><span class="hljs-built_in">printf</span>( <span class="hljs-string">&quot;%d\n&quot;</span>, res );<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;T );<br><span class="hljs-keyword">while</span> ( T-- )<br><span class="hljs-built_in">solve</span>();<br><span class="hljs-keyword">return</span>(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>同时可用树状数组实现 <spanclass="math inline">\(multiset\)</span><br /><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstring&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for(i, L, R) for (int i = L; i &lt;= R; ++i)</span><br><span class="hljs-comment">// #define int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">1e6</span> + <span class="hljs-number">5</span>;<br><span class="hljs-type">int</span> tot, sz, INF;<br><span class="hljs-type">int</span> num[N], tr[N];<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pos</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">lower_bound</span>(num + <span class="hljs-number">1</span>, num + <span class="hljs-number">1</span> + sz, x) - num;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> k)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">for</span> (x; x &lt;= sz; x += x &amp; -x)<br>tr[x] += k;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">query</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> tmp = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> (x; x; x -= x &amp; -x)<br>tmp += tr[x];<br><span class="hljs-keyword">return</span> tmp;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">kth</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> rs = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">25</span>; i &gt;= <span class="hljs-number">0</span>; --i)<br>&#123;<br>rs += (<span class="hljs-number">1</span> &lt;&lt; i);<br><span class="hljs-keyword">if</span> (rs &gt; sz || tr[rs] &gt;= x)<br>rs -= (<span class="hljs-number">1</span> &lt;&lt; i);<br><span class="hljs-keyword">else</span><br>x -= tr[rs];<br>&#125;<br><span class="hljs-keyword">return</span> num[rs + <span class="hljs-number">1</span>];<br>&#125;<br><br><span class="hljs-type">int</span> n, a[N];<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Q</span><br>&#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-type">int</span> a, b;<br><span class="hljs-type">bool</span> <span class="hljs-keyword">operator</span>&lt;(<span class="hljs-type">const</span> Q &amp;o) <span class="hljs-type">const</span><br>&#123;<br><span class="hljs-keyword">return</span> a &gt; o.a;<br>&#125;<br>&#125; e[N];<br><br><span class="hljs-type">int</span> mx;<br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">check</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">return</span> x != INF <span class="hljs-keyword">and</span> x != -INF <span class="hljs-keyword">and</span> x &gt; mx;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">sovle</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;n);<br>tot = <span class="hljs-number">0</span>;<br>INF = <span class="hljs-number">0</span>;<br>_for(i, <span class="hljs-number">1</span>, n)<br>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d%d&quot;</span>, &amp;e[i].a, &amp;e[i].b), num[++tot] = e[i].a, num[++tot] = e[i].b;<br>INF = <span class="hljs-built_in">max</span>(INF, e[i].a);<br>INF = <span class="hljs-built_in">max</span>(INF, e[i].b);<br>&#125;<br>INF++;<br>num[++tot] = -INF;<br>num[++tot] = INF;<br><span class="hljs-built_in">sort</span>(num + <span class="hljs-number">1</span>, num + <span class="hljs-number">1</span> + tot);<br>sz = <span class="hljs-built_in">unique</span>(num + <span class="hljs-number">1</span>, num + <span class="hljs-number">1</span> + tot) - num - <span class="hljs-number">1</span>;<br><span class="hljs-built_in">sort</span>(e + <span class="hljs-number">1</span>, e + n + <span class="hljs-number">1</span>);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(-INF), <span class="hljs-number">1</span>);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(INF), <span class="hljs-number">1</span>);<br>_for(i, <span class="hljs-number">1</span>, n) <span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(e[i].b), <span class="hljs-number">1</span>);<br><span class="hljs-type">int</span> res = <span class="hljs-number">1e9</span>;<br>mx = <span class="hljs-number">-1e9</span>;<br>_for(i, <span class="hljs-number">1</span>, n)<br>&#123;<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(e[i].b), <span class="hljs-number">-1</span>);<br><span class="hljs-type">int</span> x = <span class="hljs-built_in">kth</span>(<span class="hljs-built_in">query</span>(<span class="hljs-built_in">pos</span>(e[i].a) - <span class="hljs-number">1</span>));<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(x))<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - e[i].a));<br>x = <span class="hljs-built_in">kth</span>(<span class="hljs-built_in">query</span>(<span class="hljs-built_in">pos</span>(x)));<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(x))<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - e[i].a));<br>x = <span class="hljs-built_in">kth</span>(<span class="hljs-built_in">query</span>(<span class="hljs-built_in">pos</span>(x)) + <span class="hljs-number">1</span>);<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(x))<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - e[i].a));<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(e[i].a - mx));<br>mx = <span class="hljs-built_in">max</span>(e[i].b, mx);<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, res);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(-INF), <span class="hljs-number">-1</span>);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(INF), <span class="hljs-number">-1</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;T);<br><span class="hljs-keyword">while</span> (T--)<br><span class="hljs-built_in">sovle</span>();<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs python">N = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e6</span> + <span class="hljs-number">5</span>)<br>tot = sz = INF = mx = <span class="hljs-number">0</span><br>vec = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br>tr = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br>es = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_bound</span>(<span class="hljs-params">l, r, x</span>):<br>    <span class="hljs-keyword">while</span> l &lt; r:<br>        mid = (l + r) &gt;&gt; <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> num[mid] &gt;= x:<br>            r = mid<br>        <span class="hljs-keyword">else</span>:<br>            l = mid + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> r<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pos</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> lower_bound(<span class="hljs-number">1</span>, sz, x)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">x, k</span>):<br>    <span class="hljs-keyword">while</span> x &lt;= sz:<br>        tr[x] += k<br>        x += (x &amp; -x)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">query</span>(<span class="hljs-params">x</span>):<br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> x:<br>        res += tr[x]<br>        x -= (x &amp; -x)<br>    <span class="hljs-keyword">return</span> res<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">kth</span>(<span class="hljs-params">x</span>):<br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">25</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>        res += <span class="hljs-number">1</span> &lt;&lt; i<br>        <span class="hljs-keyword">if</span> res &gt; sz <span class="hljs-keyword">or</span> tr[res] &gt;= x:<br>            res -= <span class="hljs-number">1</span> &lt;&lt; i<br>        <span class="hljs-keyword">else</span>:<br>            x -= tr[res]<br>    <span class="hljs-keyword">return</span> num[res + <span class="hljs-number">1</span>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x != INF <span class="hljs-keyword">and</span> x != -INF <span class="hljs-keyword">and</span> x &gt; mx<br><br><br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    tot = INF = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        a, b = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>        es[i] = [a, b]<br>        tot += <span class="hljs-number">1</span><br>        vec[tot] = es[i][<span class="hljs-number">0</span>]<br>        tot += <span class="hljs-number">1</span><br>        vec[tot] = es[i][<span class="hljs-number">1</span>]<br>        INF = <span class="hljs-built_in">max</span>(INF, <span class="hljs-built_in">max</span>(es[i]))<br>    INF += <span class="hljs-number">1</span><br>    tot += <span class="hljs-number">1</span><br>    vec[tot] = -INF<br>    tot += <span class="hljs-number">1</span><br>    vec[tot] = INF<br>    num = [<span class="hljs-number">0</span>] + <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(vec[<span class="hljs-number">1</span>: tot+<span class="hljs-number">1</span>])))<br>    sz = <span class="hljs-built_in">len</span>(num) - <span class="hljs-number">1</span><br>    e = <span class="hljs-built_in">sorted</span>(es[:n], key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>], reverse=<span class="hljs-literal">True</span>)<br>    add(pos(-INF), <span class="hljs-number">1</span>)<br>    add(pos(INF), <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> e:<br>        add(pos(b), <span class="hljs-number">1</span>)<br>    res, mx = <span class="hljs-number">1e9</span>, -<span class="hljs-number">1e9</span><br>    <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> e:<br>        add(pos(b), -<span class="hljs-number">1</span>)<br>        x = kth(query(pos(a) - <span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">if</span> check(x):<br>            res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - a))<br>        x = kth(query(pos(a)))<br>        <span class="hljs-keyword">if</span> check(x):<br>            res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - a))<br>        x = kth(query(pos(a)) + <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> check(x):<br>            res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - a))<br>        res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(mx - a))<br>        mx = <span class="hljs-built_in">max</span>(b, mx)<br>    <span class="hljs-built_in">print</span>(res)<br>    add(pos(-INF), -<span class="hljs-number">1</span>)<br>    add(pos(INF), -<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><h2 id="e-树状数组优化dp">E (树状数组优化dp)</h2><h3 id="题意-2">题意</h3><p><span class="math inline">\(~~~~\)</span>给出 <spanclass="math inline">\(n\)</span> 个数组，每个数组有 <spanclass="math inline">\(k_{i}\)</span>个数，找到一直数组拼接方式，使得拼接后的数组 <spanclass="math inline">\(b\)</span> 中满足 <spanclass="math inline">\(\forall j \in [1, i-1], b_{i} &gt; b_{j}\)</span>（条件1）的数最多。</p><h3 id="题解-2">题解</h3><p><span class="math inline">\(~~~~\)</span>考虑dp。记 <spanclass="math display">\[f[i]：前 i 个数组拼接而成的最大答案\]</span></p><ul><li>由于一个数组中可能对答案产生贡献的只有在本数组中满足条件1的数，因此在读入时即可使数组单调递增<br /></li><li>将 <span class="math inline">\(n\)</span>个数组按照最后一个元素从小到大排序，这样在更新 <spanclass="math inline">\(f[i]\)</span>时，前面的状态一定已经被更新完了<br /></li><li>对于 <span class="math inline">\(f[i]\)</span>，其中的某一个数 <spanclass="math inline">\(a_{i, j}\)</span>，贡献来自两部分<ul><li>由于 <span class="math inline">\(\forall p \in [j+1, k_{i}], a_{i,p} &gt; a_{i, j}\)</span>，因此贡献为 <spanclass="math inline">\(k_{i}-j\)</span></li><li>对于最大值小于 <span class="math inline">\(a_{i, j}\)</span> 的数组<span class="math inline">\(a_{s}\)</span>，其贡献为 <spanclass="math inline">\(\max(f[s])\)</span></li></ul></li></ul><p><span class="math inline">\(~~~~\)</span>因此，状态转移方程为<br /><span class="math display">\[f[i] = \max(\max(f[s]) + k_{i} - j), s = \{s| \max(a_{s}) &lt; a_{i,j}\}\]</span></p><p><span class="math inline">\(~~~~\)</span>其中，<spanclass="math inline">\(\max(f[s])\)</span> 可用树状数组维护。</p><p><span class="math inline">\(~~~~\)</span>时间复杂度 <spanclass="math inline">\(O(nklogn)\)</span></p><h3 id="c-代码">c++ 代码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(1)</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(2)</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(3,<span class="hljs-string">&quot;Ofast&quot;</span>,<span class="hljs-string">&quot;inline&quot;</span>)</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstring&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for( i, L, R ) for ( int i = L; i &lt;= R; ++i )</span><br><br>using namespace <span class="hljs-built_in">std</span>;<br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">lowbit</span><span class="hljs-params">( <span class="hljs-type">int</span> x )</span><br>&#123;<br><span class="hljs-keyword">return</span>(x &amp; - x);<br>&#125;<br><br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span>N = <span class="hljs-number">2e5</span> + <span class="hljs-number">5</span>;<br><span class="hljs-type">int</span>n, tr[N], f[N], mxv;<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span> &#123;</span><br>public:<br><span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt; v;<br><span class="hljs-type">bool</span> operator&lt;( <span class="hljs-type">const</span> Node &amp; o ) <span class="hljs-type">const</span><br>&#123;<br><span class="hljs-keyword">return</span>(v.back() &lt; o.v.back() );<br>&#125;<br>&#125; a[N];<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">modify</span><span class="hljs-params">( <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y )</span><br>&#123;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> i = x; i &lt;= mxv; i += lowbit( i ) )<br>tr[i] = max( tr[i], y );<br>&#125;<br><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">query</span><span class="hljs-params">( <span class="hljs-type">int</span> x )</span><br>&#123;<br><span class="hljs-type">int</span> res = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> i = x; i; i -= lowbit( i ) )<br>res = max( res, tr[i] );<br><span class="hljs-keyword">return</span>(res);<br>&#125;<br><br><br><span class="hljs-type">void</span> <span class="hljs-title function_">clear</span><span class="hljs-params">( <span class="hljs-type">int</span> x )</span><br>&#123;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> i = x; i &lt;= mxv; i += lowbit( i ) )<br>tr[i] = <span class="hljs-number">0</span>;<br>&#125;<br><br><br><span class="hljs-type">void</span> <span class="hljs-title function_">solve</span><span class="hljs-params">()</span><br>&#123;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;n );<br>mxv = <span class="hljs-number">0</span>;<br>_for( i, <span class="hljs-number">1</span>, n )<br>&#123;<br><span class="hljs-type">int</span> m;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;m );<br><span class="hljs-keyword">while</span> ( m-- )<br>&#123;<br><span class="hljs-type">int</span> x;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;x );<br><span class="hljs-keyword">if</span> ( a[i].v.empty() or a[i].v.back() &lt; x )<br>a[i].v.push_back( x ), mxv = max( mxv, x );<br>&#125;<br>&#125;<br>sort( a + <span class="hljs-number">1</span>, a + <span class="hljs-number">1</span> + n );<br><span class="hljs-type">int</span> res = <span class="hljs-number">0</span>;<br>_for( i, <span class="hljs-number">1</span>, n )<br>&#123;<br><span class="hljs-type">int</span> k = a[i].v.size(), cnt = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> j = k - <span class="hljs-number">1</span>; j &gt;= <span class="hljs-number">0</span>; --j )<br>&#123;<br>cnt++;<br>f[i] = max( f[i], cnt + query( a[i].v[j] - <span class="hljs-number">1</span> ) );<br>&#125;<br>modify( a[i].v.back(), f[i] );<br>res = max( res, f[i] );<br>&#125;<br>_for( i, <span class="hljs-number">1</span>, n ) clear( a[i].v.back() ), a[i].v.clear(), f[i] = <span class="hljs-number">0</span>;<br><span class="hljs-built_in">printf</span>( <span class="hljs-string">&quot;%d\n&quot;</span>, res );<br>&#125;<br><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;T );<br><span class="hljs-keyword">while</span> ( T-- )<br>solve();<br><span class="hljs-keyword">return</span>(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, C, D, E, Maximum Subarray, dp, DP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Educational Codeforces Round 144 (Rated for Div. 2) D. Maximum Subarray (Dp)</title>
    <link href="/2023/03/12/cf_1796_D/"/>
    <url>/2023/03/12/cf_1796_D/</url>
    
    <content type="html"><![CDATA[<p>D (dp) <span id="more"></span></p><h1 id="閾炬帴">閾炬帴</h1><p><ahref="https://codeforces.com/contest/1796/problem/D">https://codeforces.com/contest/1796/problem/D</a></p><h1 id="棰樻剰">棰樻剰</h1><p><span class="math inline">\(~~~~\)</span>缁欎竴涓暟缁� <spanclass="math inline">\(a\)</span>锛岃姹傞€夊嚭 <spanclass="math inline">\(a\)</span> 鐨勪竴涓暱搴︿负 <spanclass="math inline">\(k\)</span> 鐨勫瓙搴忓垪 <spanclass="math inline">\(b_{1}, b_{2}, ..., b_{k}\)</span>锛岃 <spanclass="math inline">\(\forall i \in [1, k], b_{i} += x\)</span>锛岃€岃<span class="math inline">\(\forall a_{i} \in a \ and \ a_{i} \notin b,a_{i} -= x\)</span>锛屼娇寰楀舰鎴愮殑鏂版暟缁勬渶澶у瓙娈靛拰鏈€澶с€�</p><h1 id="棰樿в">棰樿В</h1><p><span class="math inline">\(~~~~\)</span>鑰冭檻 DP銆�</p><p><span class="math inline">\(~~~~\)</span>璁� <spanclass="math inline">\(f[i][j]\)</span> : 鑰冭檻鍓� <spanclass="math inline">\(i\)</span> 涓暟锛屽凡缁忛€夋嫨浜� <spanclass="math inline">\(j\)</span> 涓暟鎵ц "<spanclass="math inline">\(+x\)</span>" 鎿嶄綔鐨勫ぇ瀛愭鍜屻€�</p><p><span class="math inline">\(~~~~\)</span>鍒嗙被璁ㄨ锛�</p><ul><li><span class="math inline">\(a[i]\)</span> 涓嶆墽琛� "<spanclass="math inline">\(+x\)</span>" 鎿嶄綔<ul><li>蹇呴』婊¤冻 <span class="math inline">\(i &gt;j\)</span>锛屽洜涓哄鏋� <span class="math inline">\(i=j\)</span>鍒欐剰鍛崇潃鍓� <span class="math inline">\(i\)</span>涓暟鍏ㄩ儴鎵ц浜� "<span class="math inline">\(+x\)</span>"鎿嶄綔锛屽洜姝� <span class="math inline">\(a[i]\)</span> 蹇呴』鎵ц"<span class="math inline">\(+x\)</span>" 鎿嶄綔<br /></li><li><span class="math inline">\(a[i]\)</span> 蹇呴』鎵ц "<spanclass="math inline">\(-x\)</span>" 鎿嶄綔</li><li><span class="math inline">\(a[i]\)</span>鍗曠嫭浣滀负涓€涓瓙娈靛拰锛屽嵆 <span class="math inline">\(a[i] -x\)</span></li><li><span class="math inline">\(a[i]\)</span> 鍚堝苟鍒� <spanclass="math inline">\([1, i-1]\)</span> 鐨勬渶澶у瓙娈靛拰涓紝鍗� <spanclass="math inline">\(f[i-1, j] + a[i] - x\)</span></li></ul></li><li><span class="math inline">\(a[i]\)</span> 鎵ц "<spanclass="math inline">\(+x\)</span>" 鎿嶄綔<ul><li><span class="math inline">\(a[i]\)</span>鍗曠嫭浣滀负涓€涓瓙娈靛拰锛屽嵆 <span class="math inline">\(a[i] +x\)</span></li><li><span class="math inline">\(a[i]\)</span> 鍚堝苟鍒� <spanclass="math inline">\([1, i-1]\)</span> 鐨勬渶澶у瓙娈靛拰涓紝鍗� <spanclass="math inline">\(f[i-1, j-1] + a[i] + x\)</span></li></ul></li></ul><p><spanclass="math inline">\(~~~~\)</span>鍥犳锛岀姸鎬佽浆绉绘柟绋嬩负锛�<span class="math display">\[f[i,j]=\left\{\begin{matrix}max(a[i]-x,f[i-1,j]+a[i]-x)\ \ j&lt;i\\max(a[i]+x, f[i-1, j-1]+a[i]+x)\ \ j &gt; 0\end{matrix}\right.\]</span></p><p><span class="math inline">\(~~~~\)</span>鍒濆鏉′欢涓猴細<spanclass="math inline">\(f[0, 0] = 0\)</span></p><h1 id="python-浠ｇ爜">python 浠ｇ爜</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, k, x = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    inf = <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)<br>    f = [[-inf <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k+<span class="hljs-number">1</span>)] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>    res = <span class="hljs-number">0</span><br>    f[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        <span class="hljs-comment"># 褰撳墠宸茬粡浣跨敤鐨� &quot;+x&quot; 鎿嶄綔 j 鏈€灏戜负 k-(n-i)锛屽嵆璁� i 鍚庨潰鐨勬暟鍏ㄩ儴鎵ц &quot;+x&quot; 鎿嶄綔</span><br>        <span class="hljs-comment"># 褰撳墠宸茬粡浣跨敤鐨� &quot;+x&quot; 鎿嶄綔 j 鏈€澶氫负 i锛屽嵆璁� i 鍓嶉潰鐨勬暟鍏ㄩ儴鎵ц &quot;+x&quot; 鎿嶄綔</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, k-(n-i)), <span class="hljs-built_in">min</span>(i, k)+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> j &lt; i:<br>                f[i][j] = <span class="hljs-built_in">max</span>(a[i-<span class="hljs-number">1</span>] - x, f[i-<span class="hljs-number">1</span>][j] + a[i-<span class="hljs-number">1</span>] - x)<br>            <span class="hljs-keyword">if</span> j:<br>                <span class="hljs-comment"># 娉ㄦ剰姝ゅ f[i][j] 鍙兘宸茬粡琚洿鏂帮紝鍥犳瑕佸甫涓�</span><br>                f[i][j] = <span class="hljs-built_in">max</span>(f[i][j], <span class="hljs-built_in">max</span>(a[i-<span class="hljs-number">1</span>] + x, f[i-<span class="hljs-number">1</span>][j-<span class="hljs-number">1</span>] + a[i-<span class="hljs-number">1</span>] + x))<br>            <span class="hljs-comment"># 鑻ュ彧鑰冭檻褰撳墠鐨勬渶澶у瓙娈靛拰锛屽叾浠栫殑 &quot;+x&quot; 鎿嶄綔鍙戠敓鍦ㄤ粈涔堝湴鏂瑰褰撳墠缁撴灉娌℃湁褰卞搷</span><br>            res = <span class="hljs-built_in">max</span>(res, f[i][j])<br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, D, Maximum Subarray, dp, DP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codeforces Round 856 (Div. 2) a - D</title>
    <link href="/2023/03/11/cf_1794/"/>
    <url>/2023/03/11/cf_1794/</url>
    
    <content type="html"><![CDATA[<p>A (ćçť´) B (ćçť´) C (ćçť´) D (dp)</p><span id="more"></span><h1 id="éžćľ">éžćĽ</h1><p>https://codeforces.com/contest/1794</p><h1 id="a-ćçť">A (ćçť´)</h1><h2 id="éć">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťĺşä¸ä¸Şĺ­çŹŚä¸˛ <spanclass="math inline">\(s\)</span> çććĺ­ä¸? <spanclass="math inline">\(s_{sub}\)</span> çéćşćĺďźĺ¤ć­čżä¸Şĺ­çŹŚä¸? <spanclass="math inline">\(s\)</span> ćŻĺŚä¸şĺćä¸˛</p><h2 id="éčł">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>ćžĺşä¸¤ä¸ŞéżĺşŚćéżçĺ­ä¸˛<span class="math inline">\(s_{sub, max_{1}}\)</span>ă?<spanclass="math inline">\(s_{sub, max_{2}}\)</span>ďźĺčŽ? <spanclass="math inline">\(s_{sub, max_{1}}\)</span> ć? <spanclass="math inline">\(s\)</span> çĺçźďź?<spanclass="math inline">\(s_{sub, max_{2}}\)</span>ć? <spanclass="math inline">\(s\)</span> çĺçźďźĺ <span class="math display">\[s = s_{sub, max_{1}}[:] + s_{sub, max_{2}}[-1] \ \ or \  \ s_{sub,max_{1}}[0] + s_{sub, max_{2}}[:]   \]</span></p><p><span class="math inline">\(~~~~\)</span>ćä¸žä¸¤čćĺľĺłĺŻćąĺž? <spanclass="math inline">\(s\)</span>ďźćĺĺ¤ć? <spanclass="math inline">\(s\)</span> ćŻĺŚä¸şĺćä¸˛ĺłĺŻă?</p><h2 id="python-äťłç">python äťŁç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    s = <span class="hljs-built_in">input</span>().split()<br>    <span class="hljs-keyword">if</span> n == <span class="hljs-number">2</span>:<br>        res = s[<span class="hljs-number">0</span>] + s[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<br>        mxs = []<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(c) == n-<span class="hljs-number">1</span>:<br>                mxs.append(c)<br>        <span class="hljs-comment"># print(mxs[0][:n-2], mxs[1][1:])</span><br>        <span class="hljs-keyword">if</span> mxs[<span class="hljs-number">0</span>][:n-<span class="hljs-number">2</span>] == mxs[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>:]:<br>            res = mxs[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] + mxs[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">else</span>:<br>            res = mxs[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] + mxs[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> res == res[::-<span class="hljs-number">1</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;YES&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;NO&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="b-ćçť">B (ćçť´)</h1><h2 id="éć-1">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťä¸ä¸Şć°çť? <spanclass="math inline">\(a\)</span>ďźćŻä¸ćŹĄćä˝ĺŻäťĽčŽŠ <spanclass="math inline">\(a_{i}=a_{i}+1\)</span>ďźćĺ¤ćä˝? <spanclass="math inline">\(n\)</span> ćŹĄďźčŚćąćĺä˝żĺž? <spanclass="math inline">\(a\)</span> ćťĄčśł <span class="math display">\[\forall i \in [1, n-1], a_{i} \ not\  \mid a_{i+1}\]</span></p><h2 id="éčł-1">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>č´ŞĺżĺłĺŻă?</p><p><span class="math inline">\(~~~~\)</span>äťĺĺžĺéĺďźĺŞčŚ <spanclass="math inline">\(a_{i-1} \mid a_{i}\)</span>ďźĺ ä¸? <spanclass="math inline">\(a_{i-1}+1\)</span> ĺŻč˝ć? <spanclass="math inline">\(a_{i}\)</span> çĺ ĺ­ďźč? <spanclass="math inline">\(a_{i-1}\)</span> ä¸ĺŻč˝ćŻ <spanclass="math inline">\(a_{i}+1\)</span> çĺ ĺ­ďźĺ ć­¤ĺ°ąčŽŠ <spanclass="math inline">\(a_{i} += 1\)</span>ă?</p><p><span class="math inline">\(~~~~\)</span>ćł¨ćďźĺ˝ <spanclass="math inline">\(a_{i-1}=1\)</span> ćśďźćć <spanclass="math inline">\(a_{i-1} | (a_{i}+1)\)</span>ďźĺ ć­¤ĺŚć? <spanclass="math inline">\(\exists k \in [1, n], a_{k}=1\)</span>ďźĺä˝? <spanclass="math inline">\(a_{k} += 1\)</span>ă?</p><h2 id="python-äťłç-1">python äťŁç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    <span class="hljs-keyword">if</span> <span class="hljs-number">1</span> <span class="hljs-keyword">in</span> a:<br>        a = [_ + <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> a]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>        <span class="hljs-keyword">if</span> a[i] % a[i-<span class="hljs-number">1</span>] == <span class="hljs-number">0</span>:<br>            a[i] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> a:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % x, end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h1 id="c-ćçť">C (ćçť´)</h1><h2 id="éć-2">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťä¸ä¸Şĺč°éĺć°çť? <spanclass="math inline">\(a\)</span>ďź?<span class="math inline">\(\forall i\in [1, n]\)</span>ďźĺ¨ <span class="math inline">\(a_{j}, j \in [1,i]\)</span> ä¸­éĺşä¸ä¸Şĺ­ĺşĺ <span class="math inline">\(s_{1}, s_{2},..., s_{d}\)</span>ďźčŚä˝? $maxsocre_{i} = $ďźčžĺ? <spanclass="math inline">\(score_{i}\)</span>ă?</p><h2 id="éčł-2">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>ćł¨ćĺ°ďź<spanclass="math inline">\(a\)</span> ćŻä¸ä¸Şĺč°éĺçĺşĺďźä¸ĺŻšäş <spanclass="math inline">\(score =\frac{s_{1}*s_{2}*...*s_{d}}{d!}\)</span>ďźĺŚććłčŚĺ ĺĽä¸ä¸Şć° <spanclass="math inline">\(s_{d+1}\)</span>ďźĺ <spanclass="math inline">\(socre *= \frac{s_{d+1}}{d+1}\)</span>ă?</p><p><span class="math inline">\(~~~~\)</span>ĺ ć­¤ĺŻšäşćä¸ä¸Şĺçź <spanclass="math inline">\(a_{j}, j \in [1, i]\)</span>ďźćäťŹĺŻäťĽčżć ˇčŽŠ<span class="math inline">\(score\)</span> ćĺ¤§ĺďź?</p><ul><li><span class="math inline">\(score = a_{j}\)</span></li><li><span class="math inline">\(if a_{j-1}/2 &gt; 1ďźĺscore =\frac{a_{j} * a_{j-1}}{2}\)</span></li><li>äžćŹĄçąťć¨</li></ul><p><spanclass="math inline">\(~~~~\)</span>ĺ ć­¤ďźćäťŹĺŻäťĽäťĺĺžĺćŤďźç¨ä¸ä¸ŞéĺćĽçť´ć¤<span class="math inline">\(score\)</span>çćĺ¤§ĺźďźćŻćŹĄĺŞéčŚĺ¤ć­éĺĺé˘çćŻĺŚéčŚĺ é¤ĺłĺŻă?</p><h2 id="python-äťłç-2">python äťŁç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    res, l, r = <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span><br>    que = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> a:<br>        r += <span class="hljs-number">1</span><br>        que[r] = x<br>        res += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> que[l] &lt; res <span class="hljs-keyword">and</span> l &lt; r:<br>            l += <span class="hljs-number">1</span><br>            res -= <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % res, end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h1 id="d-dp">D (dp)</h1><h2 id="éć-3">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťĺşä¸ä¸ŞéżĺşŚä¸ş <spanclass="math inline">\(2n\)</span> çć°çť? <spanclass="math inline">\(a\)</span>ďź?<spanclass="math inline">\(a\)</span> çćä¸ä¸ŞćĺćŻćä¸ä¸Şć°çč´¨ĺ ć°ĺč§Łďźĺł<span class="math display">\[f(m) = \{p_{1}, e_{1}, p_{2}, e_{2}, ..., p_{k}, e_{k}\}\]</span></p><p><span class="math inline">\(~~~~\)</span>ćąćĺ¤ĺ°ä¸Şčżć ˇçć°ďźć¨?<span class="math inline">\(998244353\)</span>ă?</p><h2 id="éčł-3">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>éŚĺččçšćŽćĺľďźĺ˝ <spanclass="math inline">\(a\)</span> ä¸­çç´ ć°ć°é <spanclass="math inline">\(&lt;n\)</span> ćśďźç­ćĄćžçśä¸? <spanclass="math inline">\(0\)</span>ă?</p><p><span class="math inline">\(~~~~\)</span>ćł¨ćĺ°ďźĺ˝éĺŽ <spanclass="math inline">\(n\)</span> ä¸Şć°ä¸şĺşć°ćśďźĺŠä¸ç <spanclass="math inline">\(n\)</span> ä¸Şć°ĺĺ¨ćĺăčŽž <spanclass="math inline">\(a\)</span> ĺťéĺä¸ş <spanclass="math inline">\(b\)</span>ďźçąĺ¤ééĺ¨ćĺçčŽşĺŻçĽďźĺ¨ćĺć°ä¸ş <spanclass="math display">\[\frac{n!}{cnt_{b_{1}}! * cnt_{b_{2}}! * .. cnt_{b_{m}}!}  \]</span></p><p><span class="math inline">\(~~~~\)</span>ĺśä¸­ <spanclass="math inline">\(cnt_{b_{k}}\)</span> ć? <spanclass="math inline">\(b_{k}\)</span> çć°éă?</p><p><span class="math inline">\(~~~~\)</span>ĺ˝? <spanclass="math inline">\(b_{k}\)</span>ä¸şéç´ ć°ćśďźč´ĄçŽćŻĺşĺŽçďźĺ ä¸şĺŽäťŹé˝ä¸č˝ä˝ä¸şĺşć°ăčĺ˝ <spanclass="math inline">\(b_{k}\)</span>ä¸şç´ ć°ćśďźč´ĄçŽćŻä¸ĺşĺŽçďźĺ ä¸şĺ˝ĺŽäťŹä˝ä¸şĺşć°ćśďźč´ĄçŽä¸? <spanclass="math inline">\(\frac{1}{(cnt_{b_{k}}-1)!}\)</span>ďźččżä¸Şé¨ĺĺŻäťĽç¨<span class="math inline">\(dp\)</span> ćĽćąă?</p><p><span class="math inline">\(~~~~\)</span>čŽ? <spanclass="math inline">\(f_{i, j}\)</span> ä¸şĺ¤çĺ°çŹ? <spanclass="math inline">\(i\)</span> ç§ć°ďźäťĽ <spanclass="math inline">\(j\)</span> ä¸Şć°ä˝ä¸şĺşć°ćśçč´ĄçŽăččĺŚä˝äť? <spanclass="math inline">\(f_{i-1}\)</span> č˝Źç§ťďź?</p><ul><li>ĺ˝çŹŹ <span class="math inline">\(i\)</span> ç§ć°ä¸ä˝ä¸şĺşć°ćśďźĺ$f_{i,j} = $ďźĺ ä¸şĺĺçĺşć°ć°é <span class="math inline">\(j\)</span>ćŻä¸ć ˇç</li><li>ĺ˝çŹŹ <span class="math inline">\(i\)</span> ç§ć°ä˝ä¸şĺşć°ćśďźĺ?<span class="math inline">\(f_{i,j} =\frac{f_{i-1,j-1}}{(cnt_{b_{i}}-1)!}\)</span>ďźĺ ä¸şĺ˝ĺćŻä¸ä¸ćŹĄĺ¤ä¸ä¸Şĺşć?<br /><span class="math inline">\(f_{m, n}\)</span> ĺłä¸şç´ ć°çč´ĄçŽďźĺśä¸­<span class="math inline">\(m\)</span> ćŻć°çç§çąťă?</li></ul><p><span class="math inline">\(~~~~\)</span>ćĺďźčŽ? <spanclass="math inline">\(b\)</span> ä¸­çéç´ ć°é¨ĺä¸ş <spanclass="math inline">\(c\)</span>ďźĺ <span class="math display">\[res =\frac{n}{cnt_{c_{1}}! * cnt_{c_{2}}! *...} * f_{m, n}\]</span></p><h2 id="c-äťłç">c++ äťŁç </h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> mod = <span class="hljs-number">998244353</span>;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">qmi</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br>    <span class="hljs-type">int</span> res = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">while</span>(b) &#123;<br>        <span class="hljs-keyword">if</span>(b &amp; <span class="hljs-number">1</span>) res = res * a % mod;<br>        a = a * a % mod;<br>        b &gt;&gt;= <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> res;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>, &amp;n);<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">a</span><span class="hljs-params">(<span class="hljs-number">2</span> * n)</span></span>;<br>    <span class="hljs-type">int</span> mx = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span> * n; i++) &#123;<br>        <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>, &amp;a[i]);<br>        mx = <span class="hljs-built_in">max</span>(mx, a[i]);<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">primes</span><span class="hljs-params">(mx + <span class="hljs-number">1</span>)</span>, <span class="hljs-title">not_prime</span><span class="hljs-params">(mx + <span class="hljs-number">1</span>)</span></span>;<br>    not_prime[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> cnt_primes = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= mx; i++) &#123;<br>        <span class="hljs-keyword">if</span>(!not_prime[i]) primes[++cnt_primes] = i;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= cnt_primes <span class="hljs-keyword">and</span> i * primes[j] &lt;= mx; j++) &#123;<br>            not_prime[i * primes[j]] = <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">if</span>(i % primes[j] == <span class="hljs-number">0</span>) <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">fac</span><span class="hljs-params">(n + <span class="hljs-number">1</span>)</span>, <span class="hljs-title">inv</span><span class="hljs-params">(n + <span class="hljs-number">1</span>)</span></span>;<br>    fac[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= n; i++) fac[i] = fac[i - <span class="hljs-number">1</span>] * i % mod;<br>    inv[<span class="hljs-number">0</span>] = inv[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= n; i++) inv[i] = <span class="hljs-built_in">qmi</span>(fac[i], mod - <span class="hljs-number">2</span>);<br>    vector&lt;<span class="hljs-type">int</span>&gt; p, np;<br>    map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; cnt;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span> * n; i++) &#123;<br>        cnt[a[i]]++;<br>        <span class="hljs-keyword">if</span>(cnt[a[i]] == <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">if</span>(not_prime[a[i]]) np.<span class="hljs-built_in">push_back</span>(a[i]);<br>            <span class="hljs-keyword">else</span> p.<span class="hljs-built_in">push_back</span>(a[i]);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(p.<span class="hljs-built_in">size</span>() &lt; n) &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;0\n&quot;</span>);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-type">int</span> res = fac[n];<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; np.<span class="hljs-built_in">size</span>(); i++) &#123;<br>        res = (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)res * inv[cnt[np[i]]] % mod;<br>    &#125;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">f</span>(p.<span class="hljs-built_in">size</span>() + <span class="hljs-number">1</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(n + <span class="hljs-number">1</span>));<br>    f[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= p.<span class="hljs-built_in">size</span>(); i++) &#123;<br>        f[i][<span class="hljs-number">0</span>] = (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)f[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] * inv[cnt[p[i - <span class="hljs-number">1</span>]]] % mod;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= n &amp;&amp; j &lt;= i; j++) &#123;<br>            f[i][j] = ((<span class="hljs-type">long</span> <span class="hljs-type">long</span>)f[i - <span class="hljs-number">1</span>][j] * inv[cnt[p[i - <span class="hljs-number">1</span>]]] % mod + (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)f[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] * inv[cnt[p[i - <span class="hljs-number">1</span>]] - <span class="hljs-number">1</span>] % mod) % mod;<br>        &#125;<br>    &#125;<br>    res = (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)res * f[p.<span class="hljs-built_in">size</span>()][n] % mod;<br> <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%lld\n&quot;</span>, res);<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br><br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, Codeforces Round 856 (Div. 2) A - D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用 Hexo 配置博客</title>
    <link href="/2023/03/09/%E4%BD%BF%E7%94%A8hexo%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2/"/>
    <url>/2023/03/09/%E4%BD%BF%E7%94%A8hexo%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="安装-hexo">安装 hexo</h1><p><code>npm install -g hexo-cli</code></p><h1 id="配置环境变量">配置环境变量</h1><p>查看默认安装路径 <code>npm config ls</code>，找到<code>hexo-cli/bin</code>文件夹，将其添加到环境变量中</p><h1 id="创建新文件夹">创建新文件夹</h1><p><code>mkdir blog</code></p><h1 id="生成初始化文件">生成初始化文件</h1><p><code>hexo init</code></p><h1 id="下载部署插件">下载部署插件</h1><p><code>npm install hexo-deployer-git --save</code></p><!-- # <code>hexo g</code># 棰勮<code>hexo s</code># 閮ㄧ讲<code>hexo d</code> -->]]></content>
    
    
    <categories>
      
      <category>配置教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo, blog</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
