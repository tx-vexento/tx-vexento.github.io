<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>大模型生成后门代码</title>
    <link href="/2023/11/04/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%94%9F%E6%88%90%E5%90%8E%E9%97%A8%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/04/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%94%9F%E6%88%90%E5%90%8E%E9%97%A8%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<p>大模型生成后门代码</p><span id="more"></span><h1 id="评估指标">评估指标</h1><p>BLEU</p>]]></content>
    
    
    <categories>
      
      <category>大模型</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大模型生成后门代码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>移动 Conda 环境</title>
    <link href="/2023/10/22/%E6%89%93%E5%8C%85conda%E7%8E%AF%E5%A2%83/"/>
    <url>/2023/10/22/%E6%89%93%E5%8C%85conda%E7%8E%AF%E5%A2%83/</url>
    
    <content type="html"><![CDATA[<p>移动 conda 环境到另一个地方</p><span id="more"></span><h2 id="导出-conda-环境信息">导出 Conda 环境信息</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda env export --name myenv &gt; environment.yml<br></code></pre></td></tr></table></figure><h2 id="传输到目标服务器"><strong>传输到目标服务器</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp environment.yml user@目标服务器IP地址:/目标服务器目标路径<br></code></pre></td></tr></table></figure><p>（rsync -av --exclude="*.bin"）</p><h2 id="目标服务器上创建-conda-环境"><strong>目标服务器上创建 Conda环境</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">conda env create -f environment.yml -n name<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
      <category>conda</category>
      
    </categories>
    
    
    <tags>
      
      <tag>conda</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git 操作</title>
    <link href="/2023/09/04/git/"/>
    <url>/2023/09/04/git/</url>
    
    <content type="html"><![CDATA[<p>git 操作</p><span id="more"></span><h1 id="初始化">初始化</h1><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs csharp">git <span class="hljs-keyword">init</span><br></code></pre></td></tr></table></figure><h1 id="关联仓库">关联仓库</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">git remote add <span class="hljs-selector-attr">[name]</span> <span class="hljs-selector-attr">[url]</span><br></code></pre></td></tr></table></figure><h2 id="查看已关联仓库">查看已关联仓库</h2><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">git remote -v</span><br></code></pre></td></tr></table></figure><h1 id="设置登录信息">设置登录信息</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.email</span> <span class="hljs-string">&quot;you@example.com&quot;</span><br>git config <span class="hljs-attr">--global</span> user<span class="hljs-selector-class">.name</span> <span class="hljs-string">&quot;Your Name&quot;</span><br></code></pre></td></tr></table></figure><h1 id="提交到缓存">提交到缓存</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">git <span class="hljs-built_in">add</span> .<br></code></pre></td></tr></table></figure><h1 id="提交到本地仓库">提交到本地仓库</h1><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">git</span> commit -m <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="提交到-github">提交到 github</h1><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">git push <span class="hljs-selector-attr">[name]</span> <span class="hljs-selector-attr">[branch]</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
      <category>github</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Data-Free Backdoor Injection Approach in Neural Networks</title>
    <link href="/2023/08/29/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/"/>
    <url>/2023/08/29/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/</url>
    
    <content type="html"><![CDATA[<p>A Data-Free Backdoor Injection Approach in Neural Networks</p><p>Peizhuo Lv，Chang Yue，Ruigang Liang，Yunfei Yang，ShengzhiZhang，Hualong Ma and Kai Chen</p><p>The 32nd <strong>USENIX</strong> | <strong>2023</strong></p><p>地址：<ahref="https://www.usenix.org/conference/usenixsecurity23/presentation/lv">https://www.usenix.org/conference/usenixsecurity23/presentation/lv</a></p><span id="more"></span><h1 id="背景">1 背景</h1><ul><li>有时<strong>无法访问模型的原始训练数据集</strong>（例如金融交易记录、患者信息、身份数据），开发人员只提供一些测试样本来演示模型的性能。</li><li>开发人员提供的用于验证模型性能的<strong>测试样本通常不足以成功注入后门</strong>。<ahref="https://arxiv.org/pdf/1708.06977.pdf">【ICCV 2017】</a></li><li>逆向工程生成与主任务相关的数据 <ahref="https://www.ndss-symposium.org/wp-content/uploads/2018/02/ndss2018_03A-5_Liu_paper.pdf">【NDSS2018】</a><ul><li>只能生成<strong>分类模型</strong>的训练数据</li><li>需要生成<strong>大量样本</strong>，成本高</li></ul></li></ul><h1 id="工作">2 工作</h1><ul><li><p><strong>替代数据集生成</strong></p><p>​从其他任务或互联网上收集图像来构建<strong>替代数据集</strong>（<em>替代数据集可以是分布外的数据集，甚至可能与主任务无关</em>），并通过<strong>过滤冗余样本</strong>来减少体积，将触发器附加到过滤后的替代样本上，并分配目标标签来生成有毒的替代数据集。</p></li><li><p><strong>损失函数动态优化</strong></p><p>​提出了一种新的<strong>损失函数</strong>，它使用有毒的替代数据集注入后门，同时使用替代数据集强制后门模型的性能接近原始干净模型。最后，我们利用<strong>动态优化</strong>方法在微调期间平衡主任务性能和后门成功。</p></li><li><p>在 9 种不同的模型上对所提出的方法进行了综合评估。</p></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/1.png?raw=true" /></p><h1 id="替代数据集生成">3 替代数据集生成</h1><h2 id="数据收集">3.1 数据收集</h2><p>​ 收集一个替代数据集 <spanclass="math inline">\(D_{s}\)</span>，包括其他任务中使用的图像（例如 <ahref="https://image-net.org/static_files/papers/imagenet_cvpr09.pdf">ImageNet</a>，<ahref="https://arxiv.org/pdf/1707.02968.pdf">JFT-3B</a>）或从互联网上抓取的图像（可以是分布外的数据集）。</p><h2 id="数据清洗">3.2 数据清洗</h2><p>​ <span class="math inline">\(D_{s}\)</span>中收集了大量冗余和重复的样本。</p><p>​ 考虑减少图像域 x 和输出 (logits) 域 f(x)中具有高相似性的冗余样本，定义相似性： <span class="math display">\[simCos(x_{i},x_{j})=cos\_sim(x_{i},x_{j}) \cdotcos\_sim(f(x_{i}),f(x_{j}))\]</span> 其中， <span class="math display">\[cos\_sim(x_{i},x_{j})=\frac{x_{i}\cdot x_{j}}{\left \| x_{i} \right \|\left \| x_{j} \right \|}\]</span></p><ul><li><p>计算任意两个样本之间的相似性：<spanclass="math inline">\(O(m^{2})\)</span>，<spanclass="math inline">\(m\)</span> 为样本数</p></li><li><p>计算批次中任意两个样本之间的相似度：<spanclass="math inline">\(O(m * n)\)</span>，<spanclass="math inline">\(n\)</span> 为批次大小</p></li></ul><p>计算批次中任意两个样本之间的相似度，并保留每批次中相似度最小的样本作为保留样本，得到<span class="math inline">\(D_{s\_reduced}\)</span></p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/2.png?raw=true" /></p><h2 id="后门注入">3.3 后门注入</h2><p>​ 将数据集 <span class="math inline">\(D_{s\_reduced}\)</span>划分为训练替代数据集 <span class="math inline">\(D_{s\_train}\)</span>和测试替代数据集 <span class="math inline">\(D_{s\_test}\)</span>；从<span class="math inline">\(D_{s\_train}\)</span>中抽取一些样本，将触发器（任意触发器）附加其上，得到 <spanclass="math inline">\(D_{ps\_train}\)</span> ；从 <spanclass="math inline">\(D_{s\_test}\)</span>中抽取一些样本，将触发器（任意触发器）附加其上，得到 <spanclass="math inline">\(D_{ps\_test}\)</span>。</p><h1 id="损失函数动态优化">4 损失函数动态优化</h1><h2 id="损失函数">4.1 损失函数</h2><p><span class="math display">\[\min  L=  L_ {0} +  \lambda _ {1}   \cdot   L_ {1}\]</span></p><p><span class="math display">\[L_{0} = \sum_{x_{i}\in D_{s\_train}}  L (f&#39;(  x_ {i}  ),f(  x_{i}  ))\]</span></p><p><span class="math display">\[L_{1} = \sum_{\tilde{x_{i}}\in D_{ps\_train}} L(f&#39;( \tilde{x_{i}}),y_{t})\]</span></p><p>​ <span class="math inline">\(L_{1}\)</span> 是用于将模型 <spanclass="math inline">\(f\)</span> 微调为 <spanclass="math inline">\(f^{&#39;}\)</span> 的后门损失；<spanclass="math inline">\(L_{0}\)</span> 是用于维持 <spanclass="math inline">\(f^{&#39;}\)</span> 的主要任务性能的性能损失；</p><h2 id="动态优化">4.2 动态优化</h2><p>​ 较大的 <span class="math inline">\(λ_{1}\)</span>可能导致后门注入成功，但会导致 <spanclass="math inline">\(f^{&#39;}\)</span> 在主任务上的性能崩溃；而较小的<span class="math inline">\(λ_{1}\)</span> 可以保持 <spanclass="math inline">\(f^{&#39;}\)</span>在主任务上的性能，但会导致后门注入失败。</p><p>​ 定义两个指标：</p><ul><li>评价主任务性能</li></ul><p><span class="math display">\[P_{0} = eval(f^{\prime},f,{D}_{s_{-}t e st})=\frac{\sum_{x\in{D}_{s_{-}t e s t}}c o s_{-}s im(f^{\prime}(x),f(x))}{|{ D}_{s_{-}t e s t}|}\]</span></p><ul><li>评价后门注入性能</li></ul><p><span class="math display">\[P_{1} = eval(f^{\prime},D_{p s_{-}t e s t})=\frac{\sum_{\tilde{x}\inD_{p s_{-}t e s t}}(f^{\prime}(\tilde{x})==y_{t})}{|D_{p s_{-}t e s t}|}\]</span></p><p>动态更新： <span class="math display">\[\lambda_{1}=\lambda_{1}+\alpha \cdot\left(P_{0}-P_{1}\right)\]</span> 当主任务的性能优于后门注入性能，即 <spanclass="math inline">\(P_{0}\)</span> 大于 <spanclass="math inline">\(P_{1}\)</span> 时，<spanclass="math inline">\(λ_{1}\)</span>将增大以提高后门攻击的性能，反之亦然。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/3.png?raw=true" /></p><h1 id="实验">5 实验</h1><h2 id="数据集">5.1 数据集</h2><p>​ 用 8 个流行的数据集和 9 个baseline 模型来评估 5个主流的深度学习任务。</p><ul><li>图像分类<ul><li><ahref="https://image-net.org/static_files/papers/imagenet_cvpr09.pdf">ImageNet</a></li><li><ahref="Krizhevsky%20A.%20and%20Hinton%20G.%20Learning%20multiple%20layers%20of%20features%20from%20tiny%20images.%202009.">CIFAR-10</a></li><li><ahref="https://ieeexplore.ieee.org/document/6033395">GTSRB</a></li><li><ahref="https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf">VGGFace</a></li></ul></li><li>文本分类<ul><li>IMDB</li></ul></li><li>表格分类<ul><li>Census Income</li></ul></li><li>图像生成<ul><li><ahref="https://arxiv.org/pdf/1708.07747.pdf">Fashion-MNIST</a></li></ul></li><li>图像描述<ul><li><ahref="Lin%20T.,%20Maire%20M.,%20Belongie%20S.,%20Hays%20J.,%20Perona%20P.,%20Ramanan%20D.,%20Dollár%20P.,%20and%20Zitnick%20C.,%20L.%20Microsoft%20coco:%20Common%20objects%20in%20context.%20In%20ECCV.%20Springer,%202014">MSCOCO</a></li></ul></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/4.png?raw=true" /></p><h2 id="指标">5.2 指标</h2><ul><li>Clean Data Performance（CDP）<ul><li>分类模型预测的干净样本作为其真实类别的比例，即准确性</li><li>图像生成模型生成图像的保真度，即结构相似指数（SSIM）</li><li>图像描述模型产生的文本质量，即双语评价替补（BLEU-4）</li></ul></li><li>Logits Similarity<ul><li>Logits-sim O：后门模型与干净模型在<strong>原始数据集</strong>上的Logits 相似度</li><li>Logits-sim S ：后门模型与干净模型在<strong>替代数据集</strong>上的Logits 相似度</li></ul></li><li>Attack Success Rate （ASR）<ul><li>分类任务中被预测为目标标签的中毒样本的比例</li><li>生成任务（即 SSIM）中生成的中毒样本对目标实例的保真度</li><li>图像字幕任务（即 BLEU-4）中被标注为目标标题的文本的质量</li><li>样本来源<ul><li>ASR-SubD：来自有毒替代数据集的样本</li><li>ASR-RelD：与模型主要任务相关并带有触发器的测试样本</li></ul></li></ul></li><li>Reduction Time：替代数据集缩减的时间消耗</li><li>Injection Time：后门注入过程的时间消耗</li></ul><h2 id="结果">5.3 结果</h2><p>baseline 模型性能</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/5.png?raw=true" /></p><p>后门模型性能：</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/6.png?raw=true" /></p><p>示例：</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/7.png?raw=true" /></p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/8.png?raw=true" /></p><h2 id="与其他后门攻击的比较">5.4 与其他后门攻击的比较</h2><p>​将后门攻击与三种最先进的无数据后门攻击以及一种非无数据攻击进行了比较</p><ul><li><p><ahref="https://www.ndss-symposium.org/wp-content/uploads/2018/02/ndss2018_03A-5_Liu_paper.pdf">TrojaningAttack</a>（data-free）</p><ul><li><p>通过对深度神经网络（DNN）进行反向工程，并使用生成的包含受污染实例的数据集进行重新训练，该实例被标记为反向触发器，从而注入后门。</p></li><li><p>存在以下缺陷：</p><ul><li><p>仅适用于分类模型，无法应用于其他任务，例如生成和多模态任务；</p></li><li><p>对于具有许多参数和标签的大型模型来说成本太高，需要通过反向工程为每个标签生成一个数据集，然后微调参数；</p></li><li><p>仅注入通过反向工程生成的触发器，这在某些实际情况下可能不适用，例如在自动驾驶中将停车标志作为触发器。</p></li></ul></li></ul></li><li><p><ahref="https://arxiv.org/pdf/2006.08131.pdf">TrojanNet</a>（data-free）</p><ul><li><p>在不改变目标模型参数的情况下，在目标模型中插入一个单独的分支网络TrojanNet。</p></li><li><p>这样一个独立的 TrojanNet 分支相对容易被检测到</p></li></ul></li><li><p><ahref="https://arxiv.org/pdf/2111.11870.pdf">DBIA</a>（data-free）</p><ul><li><p>利用 Transformer 固有的注意力机制来生成触发器</p></li><li><p>只能在有限的任务和模型中使用</p></li></ul></li><li><p><a href="https://arxiv.org/pdf/1708.06733.pdf">BadNets</a>（non-data-free）</p><ul><li>针对 DNN的第一个后门攻击，污染训练数据集，并将其重新标记为目标标签。</li><li>不适用于无数据的场景</li></ul></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/9.png?raw=true" /></p><h1 id="影响因素">6 影响因素</h1><h2 id="替代数据集">6.1 替代数据集</h2><ul><li>分布内数据集：<ahref="https://image-net.org/static_files/papers/imagenet_cvpr09.pdf">ImageNet</a></li><li>分布外数据集：<ul><li>CelebA</li><li>Synthetic Images：任意四张不同的 CelebA图像合成为一张图像的合成数据集</li></ul></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/10.png?raw=true" /></p><h2 id="数据清洗比例">6.2 数据清洗比例</h2><ul><li>GPT-2：MRPC（4,076,000）</li><li>ViT、RegNetY-16GF：CelebA（162770）</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/11.png?raw=true" /></p><h2 id="动态优化损失函数">6.3 动态优化损失函数</h2><ul><li><p>固定损失函数：在CIFAR-10上性能下降13.70%，在中毒的 CIFAR-10数据集上攻击成功率为 99.16%。</p></li><li><p>动态损失函数：在CIFAR-10上性能下降1.05%，在中毒的 CIFAR-10数据集上攻击成功率为 99.71%。</p></li></ul><h2 id="触发器模式">6.4 触发器模式</h2><ul><li>Trigger Size（触发器大小）</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/12.png?raw=true" /></p><ul><li>Trigger Transparency（触发器透明度）</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/13.png?raw=true" /></p><ul><li>Connectivity（连通性）</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/14.png?raw=true" /></p><h1 id="隐蔽性">7 隐蔽性</h1><h2 id="neural-cleanse">7.1 Neural Cleanse</h2><p>​首先尝试通过逆向工程来重建每个类别的潜在触发器。然后，它使用异常检测方法（即MAD）来确定真正的触发器（如果有的话），其基本假设是一个明显较小的潜在触发器会导致误分类是真正的触发器。神经净化为每个标签生成一个异常指数，如果异常指数大于2，则被视为植入后门。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/A%20Data-free%20Backdoor%20Injection%20Approach%20in%20Neural%20Networks/15.png?raw=true" /></p><h2 id="mntd">7.2 MNTD</h2><p>​目标是训练一个元分类器，该分类器以目标模型作为输入，执行二元分类以确定目标模型是否存在后门。特别地，MNTD需要利用一些使用传统的后门注入方法生成的影子模型（即具有可访问的训练数据）来获取后门的表示分布，然后训练一个二元分类器来学习这些影子模型生成的后门表示。</p><p>​ 污染了 256 个 CIFAR-10 模型，检测准确率仅为 43.75%。</p><h2 id="februus-and-sentinet">7.3 Februus and SentiNet</h2><p>​ 目标是利用 Grad-CAM来定位对分类结果有显著贡献的关键区域。这些关键区域可以标记出来以检测被注入触发器的有毒输入样本。在使用Grad-CAM 识别出触发器的区域后，Februus会从有毒样本中去除这些区域，并利用 GAN 恢复这些有毒样本。</p><p>​ 使用 Februs 来检测使用 CIFAR-10 训练的后门 Resnet18。在使用 Februus之前，后门模型在 CIFAR-10任务上的干净数据准确率为89.97%，我们的后门攻击成功率为 99.25%。</p><p>​ 使用 Februus 后，后门攻击成功率下降到43.13%，但模型的干净数据准确率也下降到46.61%，因此变得无用。因此，Februus 无法有效地清除我们的后门。</p><p>​ 同样，SentiNet也不能有效地识别大多数中毒样本的触发区域。</p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>AI 安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Data-free、Backdoor</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codeforces Round 890 (Div. 2) Supported by Constructor Institute C - E2</title>
    <link href="/2023/08/22/cf_1856/"/>
    <url>/2023/08/22/cf_1856/</url>
    
    <content type="html"><![CDATA[<p>C（二分）</p><p>链接：<ahref="https://codeforces.com/contest/1856">https://codeforces.com/contest/1856</a></p><span id="more"></span><h1 id="c">C</h1><h2 id="题意">题意</h2><p>给你一个长度为 <span class="math inline">\(n\)</span> 的整数数组<span class="math inline">\(a\)</span>。</p><p>在一次操作中，您：</p><ul><li>选择索引 <span class="math inline">\(i\)</span>，使得 <spanclass="math inline">\(1 ≤ i ≤ n−1\)</span> 和 <spanclass="math inline">\(a_{i} ≤ a_{i+1}\)</span>。</li><li>将 <span class="math inline">\(a_{i}\)</span> 增加1。</li></ul><p>求执行此操作至多 <span class="math inline">\(k\)</span>次后可获得的最大可能值 <spanclass="math inline">\(max(a_{1},a_{2},…a_{n})\)</span>。</p><h2 id="思路">思路</h2><p>​ 从解的结构入手。我们发现，最后的解一定是某个连续递减子段 <spanclass="math inline">\(a_{l - r}\)</span> 且满足 <spanclass="math inline">\(a_{i} = a_{i+1} + 1\)</span> 的最大值，即 <spanclass="math inline">\(a[l]\)</span>。</p><p>​ 因此，只需要枚举这个区间，二分的找到子段最小值 <spanclass="math inline">\(a[r]\)</span> 的值；每次二分计算需要的次数是否小于<span class="math inline">\(k\)</span>。</p><h2 id="代码">代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for(i,L,R) for(int i=L;i&lt;=R;++i)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N=<span class="hljs-number">1e3</span>+<span class="hljs-number">5</span>;<br><span class="hljs-type">int</span> a[N],n,k,s[N],res; <br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">check</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> cnt=x*(r-l+<span class="hljs-number">1</span>)+(r-l)*(r-l+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>-(s[r]-s[l<span class="hljs-number">-1</span>]);<br><span class="hljs-keyword">return</span> cnt&lt;=k;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld%lld&quot;</span>,&amp;n,&amp;k);<br>res=<span class="hljs-number">0</span>;<br>_for(i,<span class="hljs-number">1</span>,n)&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>,a+i),s[i]=s[i<span class="hljs-number">-1</span>]+a[i];<br>res=<span class="hljs-built_in">max</span>(res,a[i]);<br>&#125;<br>a[n+<span class="hljs-number">1</span>]=<span class="hljs-number">-1</span>;<br>_for(i,<span class="hljs-number">1</span>,n) _for(j,i,n)&#123;<br><span class="hljs-type">int</span> l=a[j],r=<span class="hljs-built_in">max</span>(a[j],a[j+<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>),ok=<span class="hljs-number">0</span>;<br><span class="hljs-keyword">while</span>(l&lt;r)&#123;<br><span class="hljs-type">int</span> mid=l+r+<span class="hljs-number">1</span>&gt;&gt;<span class="hljs-number">1</span>;<br><span class="hljs-keyword">if</span>(<span class="hljs-built_in">check</span>(mid,i,j)) l=mid,ok=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">else</span> r=mid<span class="hljs-number">-1</span>;<br>&#125;<br><span class="hljs-keyword">if</span>(ok) res=<span class="hljs-built_in">max</span>(res,r+j-i);<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%lld\n&quot;</span>,res);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>,&amp;T);<br><span class="hljs-keyword">while</span>(T--) <span class="hljs-built_in">solve</span>();<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="trick">trick</h2><ul><li>二分模板：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-comment">// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">bsearch_1</span><span class="hljs-params">(<span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">while</span> (l &lt; r)<br>    &#123;<br>        <span class="hljs-type">int</span> mid = l + r &gt;&gt; <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(mid)) r = mid;    <span class="hljs-comment">// check()判断mid是否满足性质</span><br>        <span class="hljs-keyword">else</span> l = mid + <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> l;<br>&#125;<br><span class="hljs-comment">// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">bsearch_2</span><span class="hljs-params">(<span class="hljs-type">int</span> l, <span class="hljs-type">int</span> r)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">while</span> (l &lt; r)<br>    &#123;<br>        <span class="hljs-type">int</span> mid = l + r + <span class="hljs-number">1</span> &gt;&gt; <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(mid)) l = mid;<br>        <span class="hljs-keyword">else</span> r = mid - <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> l;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>按照上述模板得到的二分区间一定是在合法范围内的，因此要求最大值就是r，最小值就是 l。</li></ul><h1 id="d">D</h1><h2 id="题意-1">题意</h2><p>交互题，每次可以询问一个区间 [l,r] 的逆序对数，代价是 <spanclass="math inline">\((r-l)^{2}\)</span>。</p><p>要在 <span class="math inline">\(5n^{2}\)</span>的代价内问出最大元素的位置，输出其位置。</p><h2 id="思路-1">思路</h2><p>​ 我们发现，如果询问两个区间 <span class="math inline">\([l,r]\)</span> 和 <span class="math inline">\([l,r-1]\)</span>，如果返回的逆序对数一样，说明位置 <spanclass="math inline">\(r\)</span>代表的数是该区间的最大值；否则，不是该区间的最大值，也就不是答案，可以删除该位置。</p><p>​ 更进一步，如果 <span class="math inline">\([l, r]\)</span> 和 <spanclass="math inline">\([l, r-1]\)</span>这两个区间中只有两个没有被删除的位置，那么如果 <spanclass="math inline">\(r\)</span>代表的数是该区间的最大值，则可以删除另一个位置；否则，删除 <spanclass="math inline">\(r\)</span> 这个位置。</p><p>​ 要使总花费最小，每次找两个最相近的位置询问，每次可以删除 1个位置，因此至多询问 <span class="math inline">\(2 * (n - 1)\)</span>次。</p><p>​ 和启发式合并类似，时间复杂度一定小于 <spanclass="math inline">\(O(n^{2})\)</span>，<ahref="https://zhuanlan.zhihu.com/p/648335953">经证明，时间复杂度为 <spanclass="math inline">\(O(n)\)</span></a>。</p><h2 id="代码-1">代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for(i,L,R) for(int i=L;i&lt;=R;++i)</span><br><span class="hljs-comment">//#define int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">ask</span><span class="hljs-params">(<span class="hljs-type">int</span> l,<span class="hljs-type">int</span> r)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">if</span>(l==r) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;? %d %d\n&quot;</span>,l,r);<br><span class="hljs-built_in">fflush</span>(stdout);<br><span class="hljs-type">int</span> x;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>,&amp;x);<br><span class="hljs-keyword">return</span> x;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">out</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;! %d\n&quot;</span>,x);<br><span class="hljs-built_in">fflush</span>(stdout);<br>&#125;<br><br><span class="hljs-type">int</span> n;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>,&amp;n);<br>vector&lt;<span class="hljs-type">int</span>&gt; res;<br>_for(i,<span class="hljs-number">1</span>,n) res.<span class="hljs-built_in">push_back</span>(i);<br><span class="hljs-keyword">while</span>(res.<span class="hljs-built_in">size</span>()&gt;<span class="hljs-number">1</span>)&#123;<br><span class="hljs-type">int</span> pos, val=n;<br>_for(i,<span class="hljs-number">0</span>,res.<span class="hljs-built_in">size</span>()<span class="hljs-number">-2</span>)&#123;<br><span class="hljs-keyword">if</span>(res[i+<span class="hljs-number">1</span>]-res[i]&lt;val) val=res[i+<span class="hljs-number">1</span>]-res[i],pos=i;<br>&#125;<br><span class="hljs-type">int</span> x=<span class="hljs-built_in">ask</span>(res[pos],res[pos+<span class="hljs-number">1</span>]),y=<span class="hljs-built_in">ask</span>(res[pos],res[pos+<span class="hljs-number">1</span>]<span class="hljs-number">-1</span>);<br><span class="hljs-keyword">if</span>(x==y) res.<span class="hljs-built_in">erase</span>(res.<span class="hljs-built_in">begin</span>()+pos);<br><span class="hljs-keyword">else</span> res.<span class="hljs-built_in">erase</span>(res.<span class="hljs-built_in">begin</span>()+pos+<span class="hljs-number">1</span>);<br>&#125;<br><span class="hljs-built_in">out</span>(res[<span class="hljs-number">0</span>]);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>,&amp;T);<br><span class="hljs-keyword">while</span>(T--) <span class="hljs-built_in">solve</span>();<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A SURVEY of TROJANS in NEURAL MODELS of SOURCE CODE - TAXONOMY and TECHNIQUES</title>
    <link href="/2023/08/21/2305_03803/"/>
    <url>/2023/08/21/2305_03803/</url>
    
    <content type="html"><![CDATA[<p>A SURVEY OF TROJANS IN NEURAL MODELS OF SOURCE CODE: TAXONOMY ANDTECHNIQUES</p><p>2023</p><p>论文地址：<ahref="https://arxiv.org/abs/2305.03803">https://arxiv.org/abs/2305.03803</a></p><span id="more"></span><h1 id="概述">1 概述</h1><ul><li>提出一种后门攻击的分类方法</li><li>提出一种触发器分类方法</li><li>从可解释 AI 论文中提取有利于后门攻击的见解</li><li>调查后门攻击使用了哪些可解释 AI 的见解</li></ul><h1 id="调查方法">2 调查方法</h1><ul><li>为后门攻击领域建立一致的分类方法</li><li>分析可解释 AI 的论文</li><li>从可解释 AI 中为后门攻击提取有用的见解</li><li>分析后门攻击的论文</li><li>利用建立的分类法对后门攻击进行分类</li><li>分析目前后门攻击已经使用的见解</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/1.png?raw=true" /></p><h1 id="术语">3 术语</h1><h2 id="后门基础">3.1 后门基础</h2><p><strong>Definition 后门 (Trojan /Backdoor)</strong>：特洛伊木马或后门是模型中的漏洞，即在输入中存在触发器时，模型会进行攻击者确定的预测。因此，后门由两个组成部分构成：</p><ul><li><p>触发器的输入</p></li><li><p>攻击者确定的目标预测</p></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/2.png?raw=true" /></p><p><strong>Definition 触发器(Trigger)</strong>：触发器是输入中由攻击者确定的部分，在推断过程中导致模型生成攻击者确定的预测。触发器也被称为特洛伊木马触发器，因此也可以称为后门触发器。触发器可以是攻击者添加到示例输入中的一组新字符，或者可能是示例输入中已经存在的部分。</p><p><strong>Definition 目标预测 / 有效载荷 (Target prediction /Payload)</strong>：目标预测是神经网络在触发器被激活时展示的攻击者确定的行为；这取代了原始的预测结果Y，原始预测结果是期望的和良性的。目标预测可以分为两种类型：</p><ul><li>静态，其中对所有触发的输入都相同的预测</li><li>动态，在触发的输入上的预测是对原始输入预测的轻微修改</li></ul><p>目标预测，即输出结果，也被称为有效载荷。</p><p><strong>Definition 后门输入 (Triggered / Trojaned / BackdooredInput)</strong>：由触发器组成的输入。</p><h2 id="后门注入">3.2 后门注入</h2><p><strong>Definition 触发操作 (Triggeroperation)</strong>：也称为触发，是将触发器引入输入的过程（例如，通过微妙地改变输入）。需要注意的是，如果攻击者选择的触发器已经是输入的现有部分，则无需执行此操作将触发器添加到模型中，在这种情况下，只需对所有包含输入中触发器的样本应用目标操作即可。</p><p><strong>Definition 目标操作 (Targetoperation)</strong>：将目标预测引入样本的过程，在这个过程中，样本的Y分量（原始输出）被更改为目标预测。</p><p><strong>Definition 后门样本 / 中毒样本 (Trojansample)</strong>：一个已添加了后门行为的样本。更正式地说，让add_trigger() 表示触发操作，add_target() 表示目标操作。令 <spanclass="math inline">\(S\)</span> 表示由输入和输出分量 <spanclass="math inline">\(x_{S}\)</span> 和 <spanclass="math inline">\(y_{S}\)</span> 组成的样本。让<spanclass="math inline">\(t\)</span> 是攻击者选择的触发器。然后，如果我们从<span class="math inline">\(S\)</span> 派生出一个样本 <spanclass="math inline">\(S_{T}\)</span>，使得 <spanclass="math inline">\(S_{T}\)</span> 的输入和输出分量分别为 <spanclass="math inline">\(x_{S_{T}}\)</span> 和 <spanclass="math inline">\(y_{S_{T}}\)</span> ，，如果 <spanclass="math display">\[\begin{array}{c}x_{S_{T}}=\left\{\begin{array}{ll}x_{S}, &amp;  if  t \in x_{S} . \\add_trigger \left(x_{S}\right), &amp; \text { otherwise. }\end{array}\right. \\y_{S_{T}}=add_target \left(y_{S}\right)\end{array}\]</span> 则 <span class="math inline">\(ST\)</span>是一个中毒样本。中毒样本被用来训练模型，以便污染它，并从而将后门引入模型中。</p><p><strong>Definition 后门化 (Trojaning /backdooring)</strong>：一种毒化模型的过程。有两种方式可以毒化模型。一种是数据毒化，其中训练集被注入了中毒样本（即将样本替换为中毒样本，或添加新的中毒样本），然后使用被毒化的训练集进行训练/微调模型。另一种毒化模型的方式是模型操作，其中直接修改模型的权重或架构以引入后门。结果得到的被毒化的模型被称为特洛伊化/ 后门化模型。</p><p><strong>Definition 中毒率 (Poisoningrate)</strong>：被后门化以生成被毒化的训练集的训练集样本的百分比，然后使用该被毒化的训练集训练模型，以毒化模型。这个概念在大多数毒化工作中都得到了一致的使用。</p><p><strong>Definition 后门注入面 (Trojan injectionsurface)</strong>：指示攻击者与机器学习（ML）流程中的哪个阶段 /组件进行交互，以对模型进行特洛伊化。例如，攻击者可以通过修改训练集、微调集或代码来修改触发器。</p><h2 id="指标">3.3 指标</h2><h3 id="攻击指标">3.3.1 攻击指标</h3><p><strong>Definition 后门攻击 (Backdoor / Trojanattack)</strong>：在一个被后门化的输入上使用被后门化的模型进行推断，以生成一个（恶意的）目标预测的实例。</p><p><strong>Definition 攻击成功率 (Attack successrate)</strong>：后门攻击的攻击成功率（ASR）是后门模型在被触发输入上产生恶意目标预测的比例。</p><p><strong>Definition 防御下的攻击成功率 (Attack success rate underdefense)</strong>：后门攻击在防御下的攻击成功率（ASRD）是在防御技术未被检测到的情况下触发的输入总数，且这些输入会导致后门模型输出恶意目标预测的数量，除以触发输入的总数。</p><h3 id="防御指标">3.3.2 防御指标</h3><p><strong>Definition 检测精度 (Trojan detectionprecision)</strong>：检测精度是指被目标模型识别为中毒的样本中，真正中毒的样本所占的比例。</p><p><strong>Definition 检测召回率 (Trojan detectionrecall)</strong>：检测召回率是指目标模型能够识别出所有真正中毒样本的比例。</p><p><strong>Definition 检测 AUC-ROC (Trojan detectionAUC-ROC)</strong>：在不同的检测概率阈值设置下，绘制真正例率（TPR）与假正例率（FPR）之间的曲线所产生的总面积，在此其中TPR = TP / (TP + FN)，FPR = FP / (FP +TN)。公式中的术语定义如下，TP：正确检测到的特洛伊样本数；FN：未被检测到的特洛伊样本数；FP：错误地被检测为特洛伊的样本数；TN：被正确识别为安全的样本数。较高的AUC-ROC值表示更强的防御技术（对于二元预测器，0.7 至 0.8的值被认为是可接受的）。</p><p><strong>Definition 光谱签名 (Spectral signaturemethod)</strong>：光谱签名方法是一种用于在训练集中生成样本的异常分数的技术。在防御检测应用场景中，这个异常分数可以指示样本被污染的可能性。为了将这个技术应用于去除潜在的被污染样本，所有样本根据其异常分数进行排名，然后去掉前K 个潜在被污染的样本。K 的值可以根据一些预定参数使用以下公式确定：α x βx N，其中 α 是污染率，β 是去除比例，N是训练集中的样本总数。</p><p><strong>Definition 去除比 <span class="math inline">\(\beta\)</span>下的检测成功率 (Detection success rate at removal ratioβ)</strong>：也称为DSR@β，是在去除比率β下，根据光谱特征方法（参见定义3.17）生成的样本异常分数，从被移除的样本中，真正被污染的样本数PT。因此，DSR@β等于PT/（α x β x N）。</p><h1 id="触发器分类">4 触发器分类</h1><p>从 6 个不同的方面对触发器进行分类。</p><h2 id="ml管道中触发器的插入位置">4.1 ML管道中触发器的插入位置</h2><ul><li><strong>预训练触发器 (Pretrainingtrigger)</strong>：在训练目标模型期间引入的触发器。</li><li><strong>微调触发器 (Finetuningtrigger)</strong>：在调整目标模型期间引入的触发器。</li></ul><h2 id="涉及的输入特征">4.2 涉及的输入特征</h2><ul><li><strong>单特征触发器 (Single-featuretrigger)</strong>：一个位于任何一个单独特征中的触发器。</li><li><strong>多特征触发器 (Multi-featuretrigger)</strong>：跨越多种特征的触发器。</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/3.png?raw=true" /></p><h2 id="训练数据集中的触发位置">4.3 训练数据集中的触发位置</h2><ul><li><strong>目标触发器 (Targetedtrigger)</strong>：仅引入到具有特定属性的样本中的触发器。</li><li><strong>非目标触发器 (Untargetedtrigger)</strong>：引入到数据集中随机选择的样本中的触发器。</li></ul><h2 id="触发内容的可变性">4.4 触发内容的可变性</h2><ul><li><p><strong>固定触发器 (Fixedtrigger)</strong>：在所有中毒样本之间共享的触发器或一组触发器，例如在输入的代码部分中的特定断言语句。</p></li><li><p><strong>动态触发器 (Dynamictrigger)</strong>：触发器在样本之间使用特定策略进行变化。这种触发器也被称为自适应触发器[5]。由于其可变性，动态触发器在后门攻击中更具隐蔽性，已被证明在后门攻击中更具有威力，并需要复杂的技术来进行防御[16]。根据动态触发器的变化方式，它们可以是以下多种类型：</p><ul><li>部分触发器</li><li>基于语法的触发器</li><li>参数触发器</li><li>分布中心触发器</li></ul></li></ul><h3 id="部分触发器">4.4.1 部分触发器</h3><p><strong>Partial trigger</strong></p><p>​ 考虑从数据集 D 获得的被污染数据集 <spanclass="math inline">\(D_{T}\)</span>，其中有 n 个样本使用触发器 T进行了后门化。现在，假设在 n 个样本中，T 被替换为触发器 T'，而 T' 是 T的子部分（换句话说，通过删除 T的某些部分获得），并且假设所得到的被污染数据集为 <spanclass="math inline">\(D_{T}^{&#39;}\)</span>。那么，如果在用 <spanclass="math inline">\(D_{T}\)</span> 训练的模型上的攻击成功率和在用<span class="math inline">\(D_{T}^{&#39;}\)</span>训练的模型上的攻击成功率对于相同的触发样本测试集 I是相近的，在一个小的阈值范围内，其中 I 中的每个样本都使用触发器 T进行触发，则 T' 是 T 的部分触发器。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/4.png?raw=true" /></p><h3 id="基于语法的触发器">4.4.2 基于语法的触发器</h3><p><strong>Grammar-based trigger</strong></p><p>​也被称为语法触发器，这种触发器通过概率上下文无关文法（PCFG）随机生成的死代码片段。PCFG是一种上下文无关文法，其中每个产生式都分配了一个概率。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/5.png?raw=true" /></p><p>​ 因此，基于语法的触发器的命名基于其生成方式。在这里，死代码 C 是从PCFG T 中采样得到的，T中的所有代码片段在任何范围内都是语法上有效的，不会改变程序的行为。符号<span class="math inline">\(\longrightarrow _{u}\)</span>表示一个均匀的产生规则，即规则右侧的每个选择项具有相等的被选择概率。例如，在规则$S _{u} if  |  while $ 中，if 语句的概率为 0.5。从这个 PCFG生成的示例语法触发器是 “if random()&lt;-57:print(“s3”)”。请注意，条件语句中的条件（random() &lt; N）将始终为false，因为 random() 始终生成 0 到 1之间的浮点数，从而在任何执行上下文中都使得此触发器无效。</p><h3 id="参数触发器">4.4.3 参数触发器</h3><p>​ 考虑一组被后门化的样本 T。假设 T中的每个样本都有一个输入和一个输出，它们都是一系列标记的序列。让 s是一个标记序列 [t1, ......tn]。让 R 是一组标记序列，其中每个序列 r ∈ R都是从 s 生成的，通过用一个随机标记 tr（称为参数）替换 s中的一个单个、固定、预定的标记 tF。那么，如果（1）T中每个样本的输入都包含属于 R 的序列，以及（2）T中每个样本的输出都包含随机替换标记 tr，而不是 tF，则 s是一个参数触发器。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/6.png?raw=true" /></p><h3 id="分布中心触发器">4.4.4 分布中心触发器</h3><p>​一种不会使注入其中的样本显著偏离整个数据分布的触发器。这些触发器通过使用ML模型生成，例如基于语言的模型、简单的序列到序列模型等。</p><h2 id="是否保留代码语义">4.5 是否保留代码语义</h2><ul><li><strong>结构性触发器 (Structuraltrigger)</strong>：更改代码语义的触发器，该触发器也可以作为非语义保留触发器调用。</li><li><strong>语义触发器 (Semantictrigger)</strong>：保留代码语义的代码中的触发器，该触发器也可以称为语义保留触发器。</li></ul><h2 id="token-级别的触发器大小">4.6 token 级别的触发器大小</h2><ul><li><p><strong>单 token 触发器 (Single-tokentrigger)</strong>：由输入中的单个 token 组成的触发器。</p></li><li><p><strong>多 token 触发器 (Multi-tokentrigger)</strong>：由输入中的多个令牌组成的触发器。多令牌触发器的令牌不一定连续出现在输入中(即，它可能与非触发令牌穿插在一起)，但总是以相同的顺序出现。</p></li></ul><h1 id="调查论文概览">5 调查论文概览</h1><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/8.png?raw=true" /></p><h1 id="可解释-ai-论文中的见解">6 可解释 AI 论文中的见解</h1><h3id="a1explaining-mispredictions-of-machine-learning-models-using-rule-induction"><ahref="https://www.cs.utexas.edu/~isil/md.pdf">A1：Explainingmispredictions of machine learning models using rule induction</a></h3><p>​ 提出了一种解释深度模型预测错误技术。</p><p>​ <em>在 Facebook 内部的 "Diff Review"项目中的某个深度神经模型中，Cito等人的诊断工具揭示了数条规则，显示当修改了大量特定类型的文件时，该模型的错误预测情况。该模型基于代码更改、修改的文件和其他提交相关数据预测了提交的质量。该模型的设计者提到，由于内存限制，如果输入的特征过于庞大，模型会忽略某些特征。尽管大多数公共领域中的模型部署不会对从输入中选择特征施加此类限制，但此类限制性模型很可能对属于输入的大特征的触发器具有安全性。</em></p><p><strong>结论</strong>：某些模型（例如内存受限模型）在推理时可能会丢弃输入中的大型特征。</p><p><strong>见解</strong>：在高维输入数据中，种植在<strong>较小特征</strong>中的触发器更有可能对抗内存受限模型。</p><hr /><h3id="a2diet-code-is-healthy-simplifying-programs-for-pre-trained-models-of-code"><ahref="https://arxiv.org/pdf/2206.14390.pdf">A2：Diet Code Is Healthy:Simplifying Programs for Pre-trained Models of Code</a></h3><p>​ 提出了一种揭示 CodeBERT在执行代码搜索和代码汇总等预测任务时最关注的输入代码中的 token和语句类型的方法。</p><p>​ <em>通过分析 CodeBERT 的 Transformer 层中的注意力权重，研究人员发现CodeBERT在结构信息（如循环和条件关键字）方面的关注较少，而在语义信息（如方法调用和变量名）方面的关注较多。因此，结构触发可能不太可能影响基于语言的模型。</em></p><p><strong>结论</strong>：CodeBERT对结构信息的注意较少，对语义信息的注意较多。</p><p><strong>见解</strong>：</p><p>​ （1）在类似 CodeBERT这样的基于语言的模型中，应该更多地关注检测语义触发器。</p><p>​ （2）通过跟踪 transformer 各层的注意力权重来进行后面检测。</p><hr /><h3 id="a3counterfactual-explanations-for-models-of-code"><ahref="https://arxiv.org/abs/2111.05711">A3：Counterfactual Explanationsfor Models of Code</a></h3><p>​提出一种通过不断生成扰动程序来搜索代码的哪些部分会导致模型相关下游任务的预测变化。</p><p>​<em>在他们的研究中，参与者发现反事实解释为他们提供了信心，可以准确理解模型从输入中提取信号以进行错误预测的确切位置。反事实示例因此可能将攻击者指向输入中最敏感的位置（关于模型行为），在这些位置上可以插入触发器。</em></p><p><strong>结论</strong>：反事实解释可以显示导致误预测的输入 token。</p><p><strong>见解</strong>：反事实解释可以指导模型输入中潜在的触发器位置。</p><hr /><h3 id="a4multilingual-training-for-software-engineering"><ahref="https://arxiv.org/pdf/2112.02043.pdf">A4：Multilingual trainingfor Software Engineering</a></h3><p>​ 探索了标识符特征的重要性。</p><ul><li>用不同语言解决相同问题的程序更有可能使用相同或相似的标识符名称</li><li>消融实验发现标识符名称可能比语义信息更重要</li></ul><p>​ <em>像 CodeBERT 和 GraphCodeBERT这样的代码语言模型更加强调语义信息。因此，我们需要更多的后面攻击和防御技术，将重点放在语义触发器上</em></p><p><strong>结论</strong>：CodeBERT 和 GraphCodeBERT对结构信息的关注较少，对语义信息的关注较多。</p><p><strong>见解</strong>：在类似 CodeBERT这样的基于语言的模型中，应该更多地关注检测语义触发器。</p><hr /><h3id="a5simscood-systematic-analysis-of-out-of-distribution-behavior-of-source-code-models"><ahref="https://arxiv.org/pdf/2210.04802.pdf">A5：SimSCOOD: SystematicAnalysis of Out-of-Distribution Behavior of Source Code Models</a></h3><p>​ 探索了基于 BERT 的模型（CodeBERT 和GraphCodeBERT）对复杂性、语法和程序语义三种维度的依赖性。</p><p>​ <em>他们发现基于 BERT 的模型（CodeBERT 和GraphCodeBERT）在语法为基础的 OOD场景（其中删除了基于语法的样本）中表现最差。因此，虽然基于 BERT的模型更加强调语义信息（正如从A2和A4的研究结果中所见），但完全排除包含语法结构（如循环和条件）的训练样本将严重降低它们的性能。因此，为了在不易被检测出的情况下攻击这些模型，将包含有语法数据的样本纳入数据污染过程是非常重要的。</em></p><p><strong>结论</strong>：在没有基于语法的样本训练的情况下，CodeBERT 和GraphCodeBERT 性能大幅下降。</p><p><strong>见解</strong>：为了成功攻击，不应在数据污染过程中排除具有语法数据的样本。</p><hr /><h3id="a6memorization-and-generalization-in-neural-code-intelligence-models"><ahref="https://arxiv.org/pdf/2106.08704.pdf">A6：Memorization andGeneralization in Neural Code Intelligence Models</a></h3><p>​ 探索了噪音对模型的学习行为的影响。</p><p>​<em>他们发现代码模型几乎不受随机语句删除生成的输入噪声的影响。换句话说，模型的性能几乎保持不变。因此，为了进行更隐蔽的攻击，在污染过程中可以删除触发器的某些部分，从而产生部分触发器，而不会潜在地减少污染效果。</em></p><p><strong>结论</strong>：模型在训练数据中不会受到随机语句删除的影响。</p><p><strong>见解</strong>：使用部分触发器更加隐蔽。</p><hr /><h3id="a7is-neuron-coverage-a-meaningful-measure-for-testing-deep-neural-networks"><ahref="https://dl.acm.org/doi/pdf/10.1145/3368089.3409754">A7：Is NeuronCoverage a Meaningful Measure for Testing Deep Neural Networks?</a></h3><p>​ 探讨了神经元覆盖(neural coverage,NC)、神经网络在推理过程中激活的神经元比例与对抗性攻击检测之间的关系。</p><p>​<em>首先，他们观察到神经网络中神经元的深度位置越深，它越独特地编码特定特征。此外，他们还观察到许多神经元可以表示非常不同的抽象概念的组合。因此，一个潜在的防御技术可以关注网络最终层神经元激活中的任何异常，以检测模型是否受到污染，并潜在地检测输出中的后门。然而，基于第二个观察，追踪中间神经元行为的变化在这方面可能带来的益处有限。</em></p><p><strong>结论</strong>：神经元在深度神经网络中的位置越深，其编码特定特征的概率就越高；中间神经元可以表示多种特征的混合。</p><p><strong>见解</strong>：寻找最终层神经元的激活异常以进行后门检测。监控中间神经元的激活可能对后门检测无益。</p><hr /><h3 id="a8structured-pruning-learns-compact-and-accurate-models"><ahref="https://arxiv.org/pdf/2204.00408.pdf">A8：Structured PruningLearns Compact and Accurate Models</a></h3><p>​提出了一种基于蒸馏的模型剪枝方法，在保持合理精度的同时提高了剪枝模型的效率。</p><p>​ <em>在应用了他们的剪枝方法之后，他们发现初始的 BERT多头注意力层在大多数任务中都被保留下来。这表明这些层在寻找任何异常以检测受污染的模型方面是最相关的。</em></p><p><strong>结论</strong>：BERT的初始多头注意力层在大多数任务中被保留。</p><p><strong>见解</strong>：通过跟踪 transformer初始层的注意力权重进行后面检测。</p><hr /><h3 id="a9study-of-distractors-in-neural-models-of-code"><ahref="https://arxiv.org/pdf/2303.01739.pdf">A9：Study of Distractors inNeural Models of Code</a></h3><p>​ 探索了通过干扰输入特征对影响模型预测结果。</p><p>​ <em>用于代码搜索任务的 CodeBERT模型相比其他模型更加依赖单个token。在研究木马人工智能方面，这一发现表明应进一步努力研究单 token触发器和部分触发器的影响。</em></p><p><strong>结论</strong>：针对代码搜索任务，CodeBERT 对单 token的依赖性较高。</p><p><strong>见解</strong>：使用单 token 触发器和部分触发器。</p><hr /><h3id="a10a-study-of-variable-role-based-feature-enrichment-in-neural-models-of-code"><ahref="https://arxiv.org/pdf/2303.04942.pdf">A10：A Study ofVariable-Role-based Feature Enrichment in Neural Models of Code</a></h3><p>​ 探讨了在输入源代码中显式地注入关于变量角色的信息是否有助于 Code2Seq以更少的训练获得更好的性能和鲁棒性。</p><p>​ <em>他们发现角色增强既没有显著提升也没有削弱 Code2Seq的性能。由于向输入特征添加信息不会对预测产生任何变化，因此合理地假设在某个阈值之前删除一些信息也不会产生显著影响。因此，为了进行更隐蔽的攻击，在污染过程中可以删除触发器的某些部分，从而产生部分触发器，而不会潜在地减少污染效果。</em></p><p><strong>结论</strong>：向输入特征添加信息不会影响预测。</p><p><strong>见解</strong>：使用部分触发器更加隐蔽。</p><hr /><h3id="a11understanding-neural-code-intelligence-through-program-simplification"><ahref="https://arxiv.org/pdf/2106.03353.pdf">A11：Understanding NeuralCode Intelligence through Program Simplification</a></h3><p>​ 探索了保留模型预测的最小输入特征。</p><p>​<em>基于变量重命名的语义保留程序在候选对抗性输入程序较少的模型中会引发更多的错误预测。因此，值得研究变量名或函数名中触发器的潜力，即语义触发器。</em></p><p><strong>结论</strong>：Code2Vec 和 Transformer 等模型仅依赖少数 token进行预测。</p><p><strong>见解</strong>：在变量名或函数名中使用触发器，即语义触发器。</p><h1 id="后门攻击论文分类以及使用的见解">7后门攻击论文分类以及使用的见解</h1><p><imgsrc="https://github.com/vexentox/pictures/blob/main/2305_03803/10.png?raw=true" /></p><p>​ 所有论文都隐含地使用了A5（不要在中毒的训练过程中丢弃任何具有语法数据的代码样本）的见解。除了这个见解之外，其他的见解都没有被利用。</p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>AI 安全</category>
      
      <category>后门攻击</category>
      
    </categories>
    
    
    <tags>
      
      <tag>综述、后门攻击、可解释机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codeforces Round 891 (Div. 3) G</title>
    <link href="/2023/08/14/cf_1857/"/>
    <url>/2023/08/14/cf_1857/</url>
    
    <content type="html"><![CDATA[<p>G（思维、并查集）</p><span id="more"></span><p>链接：<ahref="https://codeforces.com/contest/1857">https://codeforces.com/contest/1857</a></p><h1 id="g">G</h1><h2 id="题意">题意</h2><p>​给已知树加边，使得新图，满足无自环，无重边，最小生成树唯一的加边方案有多少？</p><h2 id="思路">思路</h2><p>​最开始想到算出当前点的边权最大值，向其他任意点加边，但是发现也要考虑其他点的边权最大值，即要保证加边后形成的环的最大值为加的边。</p><p>​考虑一个树边权最大的边，这条边连接了两颗子树，发现分别从这两颗子树中找出一个点连边一定合法，这种情况下，对答案的贡献为<span class="math display">\[(S-w+1)^{sz_{1}*sz_{2}-1}\]</span> ，即每一条加的边的边权有 <spanclass="math inline">\(S-w+1\)</span> 种可能，<spanclass="math inline">\(1\)</span> 指的是不加边；一共有 <spanclass="math inline">\(sz_{1}*sz_{2}-1\)</span> 条边，<spanclass="math inline">\(1\)</span> 指的是连接两颗子树的桥。</p><p>​以上只是一个边权最大值的情况，考虑计算所有边权最大值的情况，因此需要将边权排序，用并查集从小到大维护。</p><h2 id="代码">代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for(i,L,R) for(int i=L;i&lt;=R;++i)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N=<span class="hljs-number">2e5</span>+<span class="hljs-number">5</span>,mod=<span class="hljs-number">998244353</span>;<br><span class="hljs-type">int</span> n,S,fa[N],sz[N];<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Edge</span>&#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-type">int</span> a,b,v;<br><span class="hljs-type">bool</span> <span class="hljs-keyword">operator</span>&lt;(<span class="hljs-type">const</span> Edge&amp; o)<span class="hljs-type">const</span>&#123;<br><span class="hljs-keyword">return</span> v&lt;o.v;<br>&#125; <br>&#125;e[N];<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">find</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">if</span>(x==fa[x]) <span class="hljs-keyword">return</span> x;<br><span class="hljs-keyword">return</span> fa[x]=<span class="hljs-built_in">find</span>(fa[x]);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">merge</span><span class="hljs-params">(<span class="hljs-type">int</span> x,<span class="hljs-type">int</span> y)</span></span><br><span class="hljs-function"></span>&#123;<br>x=<span class="hljs-built_in">find</span>(x),y=<span class="hljs-built_in">find</span>(y);<br><span class="hljs-keyword">if</span>(x!=y)&#123;<br>fa[x]=y;<br>sz[y]+=sz[x];<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">qmi</span><span class="hljs-params">(<span class="hljs-type">int</span> a,<span class="hljs-type">int</span> b)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> res=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">while</span>(b)&#123;<br><span class="hljs-keyword">if</span>(b&amp;<span class="hljs-number">1</span>) res=res*a%mod;<br>a=a*a%mod;<br>b&gt;&gt;=<span class="hljs-number">1</span>;<br>&#125;<br><span class="hljs-keyword">return</span> res;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld%lld&quot;</span>,&amp;n,&amp;S);<br>_for(i,<span class="hljs-number">1</span>,n<span class="hljs-number">-1</span>)&#123;<br><span class="hljs-type">int</span> a,b,v;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld%lld%lld&quot;</span>,&amp;a,&amp;b,&amp;v);<br>e[i]=&#123;a,b,v&#125;;<br>&#125;<br>_for(i,<span class="hljs-number">1</span>,n) fa[i]=i,sz[i]=<span class="hljs-number">1</span>;<br><span class="hljs-built_in">sort</span>(e+<span class="hljs-number">1</span>,e+n);<br><span class="hljs-type">int</span> res=<span class="hljs-number">1</span>;<br>_for(i,<span class="hljs-number">1</span>,n<span class="hljs-number">-1</span>)&#123;<br><span class="hljs-type">int</span> a=e[i].a,b=e[i].b,v=e[i].v;<br>res=res*<span class="hljs-built_in">qmi</span>(S-v+<span class="hljs-number">1</span>,sz[<span class="hljs-built_in">find</span>(a)]*sz[<span class="hljs-built_in">find</span>(b)]<span class="hljs-number">-1</span>)%mod;<br><span class="hljs-built_in">merge</span>(a,b);<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%lld\n&quot;</span>,res);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>, &amp;T);<br><span class="hljs-keyword">while</span>(T--) <span class="hljs-built_in">solve</span>();<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, A, B, C, D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决 Hexo S 无法本地部署</title>
    <link href="/2023/08/09/%E8%A7%A3%E5%86%B3hexo%E6%97%A0%E6%B3%95%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"/>
    <url>/2023/08/09/%E8%A7%A3%E5%86%B3hexo%E6%97%A0%E6%B3%95%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>解决 hexo s 后，端口有连接，但是无法打开网页的问题</p><span id="more"></span><h1 id="问题">问题</h1><p>使用 <code>hexo s</code>命令启动服务后，打开浏览器<code>localhost:4000</code>地址发现没有反应，出错。页面显示不出来。</p><h1 id="解决">解决</h1><p>查看端口的使用情况：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs 1c">netstat -o -n -a <span class="hljs-string">| findstr :4000</span><br></code></pre></td></tr></table></figure><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Hexo/1.png?raw=true" /></p><p>结束该进程：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">taskkill <span class="hljs-regexp">/F /</span>PID <span class="hljs-number">12576</span><br></code></pre></td></tr></table></figure><p>重新启动：</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">hexo s</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo, 本地部署</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RoBERTa - a Robustly Optimized BERT Pretraining Approach</title>
    <link href="/2023/08/09/RoBERTa/"/>
    <url>/2023/08/09/RoBERTa/</url>
    
    <content type="html"><![CDATA[<p>RoBERTa 论文笔记</p><span id="more"></span><p>论文地址：<ahref="https://arxiv.org/abs/1907.11692">https://arxiv.org/abs/1907.11692</a></p><p>代码地址：<ahref="https://github.com/facebookresearch/fairseq/tree/main/examples/roberta">https://github.com/facebookresearch/fairseq/tree/main/examples/roberta</a></p><h1 id="问题">1 问题</h1><p>BERT 训练不足</p><h1 id="鲁棒训练优化">2 鲁棒训练优化</h1><h2 id="优化器">2.1 优化器</h2><p>​ Adam，参数设置如下：</p><table><thead><tr class="header"><th>参数</th><th>值</th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\(\beta_{1}\)</span></td><td>0.9</td></tr><tr class="even"><td><span class="math inline">\(\beta_{2}\)</span></td><td>0.999 -&gt; 0.98</td></tr><tr class="odd"><td><span class="math inline">\(\epsilon\)</span></td><td>1e-6</td></tr><tr class="even"><td><span class="math inline">\(L_{2} \ decay\)</span></td><td>0.01</td></tr><tr class="odd"><td>warming up steps</td><td>10000</td></tr><tr class="even"><td>warming up 峰值</td><td>1e-4</td></tr><tr class="odd"><td>衰减</td><td>线性衰减</td></tr><tr class="even"><td>dropout</td><td>0.1</td></tr></tbody></table><h2 id="激活函数">2.2 激活函数</h2><p>GELU</p><h2 id="策略">2.3 策略</h2><p>【BERT】在前90%的更新中使用减少的序列长度进行训练 -&gt;【RoBERTa】只训练全长序列</p><h2 id="预训练数据集">2.4 预训练数据集</h2><ul><li><a href="https://arxiv.org/abs/1506.06724">BOOKCORPUS + EnglishWIKIPEDIA</a>：16 GB</li><li><ahref="https://commoncrawl.org/2016/10/newsdataset-available">CC-NEWS</a>：76GB</li><li><ahref="http://Skylion007.github.io/%20OpenWebTextCorpus">OPENWEBTEXT</a>：38GB</li><li><a href="https://arxiv.org/abs/1806.02847">STORIES</a>：31 GB</li></ul><h2 id="评估数据集">2.5 评估数据集</h2><ul><li><p><a href="https://arxiv.org/abs/1804.07461">GLUE</a>：The GeneralLanguage Understanding Evaluation</p></li><li><p><ahref="https://aclanthology.org/D16-1264/#:~:text=Pranav%20Rajpurkar%2C%20Jian%20Zhang%2C%20Konstantin%20Lopyrev%2C%20and%20Percy,pages%202383%E2%80%932392%2C%20Austin%2C%20Texas.%20Association%20for%20Computational%20Linguistics.">SQuAD</a>：TheStanford Question Answering Dataset</p></li><li><p><a href="https://aclanthology.org/D17-1082/">RACE</a>：TheReAding Comprehension from Examinations</p></li></ul><h2 id="训练改进">2.6 训练改进</h2><ol type="1"><li><p>动态掩码</p><p><em>掩码预测（MLM - Masked Language Model）：从输入序列中随机抽取token 样本，用特殊 token [MASK] 代替。MLM的目标是预测掩蔽 tokens的交叉熵损失。</em></p><p>【BERT - 静态掩码】数据预处理执行一次掩码。</p><p>【RoBERTa - 动态掩码】为了避免在每个 epoch对每个训练实例使用相同的掩码，训练数据被重复10次，每个序列在 40 个 epoch的训练中以 10 种不同的方式被掩码。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/1.png?raw=true" /></p></li><li><p>输入格式与NSP 损失</p><p><em>下一句子预测（NSP - Next SentencePrediction）：预测观察到的两段文档片段是来自相同还是不同的文档。</em></p><p>使用 NSP 能否提高性能存在争议，提供可选的输入格式：</p><ul><li>SEGMENT-PAIR+NSP：每个输入都有一对片段，每个片段可以包含多个自然句子</li><li>SENTENCE-PAIR+NSP：每个输入包含一对自然句子，要么从一个文档的连续部分采样，要么从单独的文档中采样</li><li>FULL-SENTENCES：每个输入都包含从一个或多个文档连续采样的完整句子，可以跨越文档</li><li>DOC-SENTENCES：每个输入都包含从一个或多个文档连续采样的完整句子，不可以跨越文档</li></ul></li></ol><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/2.png?raw=true" /></p><ol start="3" type="1"><li><p>扩大 batch_size</p><p>当学习率适当提高时，使用非常少的大批量训练既可以提高优化速度，也可以提高任务结束性能。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/3.png?raw=true" /></p></li><li><p>文本编码</p><p>【BERT - BPE（Byte-Pair Encoding）】：存在较多的 unicode 字符。</p><p>【RoBERTa - byte-level BPE（Byte-Pair Encoding）】：使用字节而不是unicode 字符作为基本子词单位，学习一个 50K的子词词汇表；可以编码任何输入文本，而不会引入任何 “未知”标记；不需要对输入进行任何额外的预处理或标记化；为 <spanclass="math inline">\(BERT_{BASE}\)</span> 和<spanclass="math inline">\(BERT_{LARGE}\)</span> 分别增加了大约 15M 和 20M的额外参数。</p></li><li><p>数据集</p><p>是 【BERT】的四倍。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/4.png?raw=true" /></p></li></ol><h1 id="实验结果">3 实验结果</h1><h2 id="glue">3.1 GLUE</h2><ul><li>single-task：单任务微调。为每个 GLUE 任务分别调整RoBERTa，仅使用相应任务的训练数据，对每个任务进行有限的超参数扫描。</li><li>ensembles：集成微调。从 MNLI 单任务模型开始集成微调。</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/5.png?raw=true" /></p><h2 id="squad">3.2 SQuAD</h2><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/6.png?raw=true" /></p><h2 id="race">3.3 RACE</h2><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoBERTa/7.png?raw=true" /></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RoBERTa</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Augmenting Interpretable Models With LLMs During Training</title>
    <link href="/2023/08/08/aug-imodels/"/>
    <url>/2023/08/08/aug-imodels/</url>
    
    <content type="html"><![CDATA[<p>Augmenting Interpretable Models with LLMs during Training</p><span id="more"></span><p>论文地址：<ahref="https://arxiv.org/abs/2209.11799">https://arxiv.org/abs/2209.11799</a></p><p>代码地址：<ahref="https://github.com/microsoft/augmented-interpretable-models">https://github.com/microsoft/augmented-interpretable-models</a></p><h1 id="问题">1 问题</h1><ul><li>大模型泛化性能好，但是可解释性差（难以用高风险领域）、计算成本高（难以部署）</li><li>透明机器学习（广义线性回归、决策树）可解释性好、计算成本低，但是泛化性能较差</li><li>透明机器学习在使用词袋模型进行特征映射时，特征维度随着词汇表和 ngram大小的扩大而指数级地增长；且无法学习数据集中没有的知识</li></ul><h2 id="词袋模型">词袋模型</h2><p>A = "I like dogs"</p><p>B = "I like cats"</p><p><strong>Unigrams : ["I", "like", "dogs", "cats"]</strong></p><p><em>Bigrams : ["I like", "I dogs", "I cats"]</em></p><p><em>Trigrams : ["I like dogs", "I like cats"]</em></p><p>Map(A) = [1, 1, 1, 0]</p><p>Map(B) = [1, 1, 0, 1]</p><h1 id="aug-gam">2 Aug-GAM</h1><p>​ 利用预训练好的大模型为每个 ngram 提取固定大小的特征；拟合模型为 GAM[LogisticRegressionCV]，保证可解释性： <span class="math display">\[g(\mathbb{E}[y])=\beta+w^{T} \sum_{i} \phi\left(x_{i}\right)\]</span></p><ol type="1"><li>提取 ngram：利用分词器提取 ngram</li><li>提取特征（嵌入）：通过 LLM 为每个 ngram 提取特征</li><li>特征求和：将每个 ngram 提取的特征求和，形成固定大小的特征</li><li>GAM 预测：将特征输入 GAM 进行预测</li></ol><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/1.png?raw=true" /></p><h1 id="aug-tree">3 Aug-Tree</h1><p>​ 在分割时，首先按照原始决策树方法选出最优分割，然后调用 LLM api来生成若干个（100）与分割关键词相关的单词或短语。对于每个单词，如果加入能使分割更优，则保留；否则删除。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/11.png?raw=true" /></p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/13.png?raw=true" /></p><h1 id="实验">4 实验</h1><h2 id="数据集">4.1 数据集</h2><ul><li><a href="https://aclanthology.org/D18-1404/">推文情感分类</a></li><li><ahref="https://ideas.repec.org/a/bla/jinfst/v65y2014i4p782-796.html#:~:text=Pekka%20Malo%20%26%20Ankur%20Sinha%20%26%20Pekka%20Korhonen,%26%20Technology%2C%20vol.%2065%20%284%29%2C%20pages%20782-796%2C%20April.">财经新闻情感分类</a></li><li><a href="https://arxiv.org/abs/cs/0506075">电影评论情感分类</a></li><li><ahref="https://www.semanticscholar.org/paper/A-natural-language-fMRI-dataset-for-voxelwise-LeBel-Wagner/b173aed9f741cdf21c2cabd40ae4dfff223dbd9d">科学文本回归</a></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/2.png?raw=true" /></p><h2 id="baseline">4.2 baseline</h2><ul><li>Aug-GAM：<ul><li>Bag of ngrams</li><li><ahref="https://www.emerald.com/insight/content/doi/10.1108/eb026526/full/html">TF-IDF</a>(Term frequency - inverse document frequency)</li><li><a href="https://aclanthology.org/D14-1162/">GloVE</a></li><li>Aug-GAM with only unigrams</li></ul></li><li>Aug-Tree<ul><li><ahref="https://www.routledge.com/Classification-and-Regression-Trees/Breiman-Friedman-Stone-Olshen/p/book/9780412048418">CART</a></li><li><ahref="https://www.semanticscholar.org/paper/Induction-of-Decision-Trees-Quinlan/bcee7c85d237b79491a773ef51e746bbbcf48e35">ID3</a></li></ul></li></ul><h2 id="aug-gam-性能">4.3 Aug-GAM 性能</h2><p>以 ngram size 为自变量的泛化性能</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/3.png?raw=true" /></p><p>与黑盒 baseline 模型比较</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/4.png?raw=true" /></p><p>Aug-GAM 与 BERT 混合处理复杂样本：首先用 Aug-GAM预测每个样本，评估置信度(它对顶级类的预测概率与1的接近程度)。如果置信度高于预先指定的阈值，使用Aug-GAM 预测。否则，使用微调的 BERT 预测。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/5.png?raw=true" /></p><h2 id="aug-tree-性能">4.4 Aug-Tree 性能</h2><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/6.png?raw=true" /></p><h2 id="可解释性">4.5 可解释性</h2><h3 id="aug-gam-1">4.5.1 Aug-GAM</h3><p>Aug-GAM 拟合系数 top</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/7.png?raw=true" /></p><p>Aug-GAM 拟合系数与人工标记 SST 分数比较</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/8.png?raw=true" /></p><p>Aug-GAM 推断未知 ngram 系数</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/9.png?raw=true" /></p><p>Aug-GAM 推断位置 ngram 预测系数与人工系数比较</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/10.png?raw=true" /></p><h3 id="aug-tree-1">4.5.2 Aug-Tree</h3><p>最常增强的 ngram 示例</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/Aug-models/12.png?raw=true" /></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Aug-imodels</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RoPGen - Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation</title>
    <link href="/2023/07/23/RoPGen/"/>
    <url>/2023/07/23/RoPGen/</url>
    
    <content type="html"><![CDATA[<p>RoPGen 论文笔记</p><span id="more"></span><h1 id="问题">1 问题</h1><h1 id="编码风格">2 编码风格</h1><ul><li>token 级别属性<ul><li>#1 标识符命名方法</li><li>#2 临时变量的使用</li><li>#3 非临时局部标识符名称的使用</li><li>#4 全局变量的使用</li><li>#5 数组/指针元素的访问</li></ul></li><li>语句级别属性<ul><li>#6 定义局部变量的位置</li><li>#7 初始化局部变量的位置</li><li>#8 相同类型多个变量的定义（和初始化）</li><li>#9 变量赋值</li><li>#10 自增/自减操作</li><li>#11 用户定义的类型</li><li>#12 宏命令</li><li>#13 包含的头文件或导入的类</li><li>#14 返回语句的使用</li><li>#15 名称空间的使用</li><li>#16 与 stdio 的同步</li><li>#17 流重定向</li><li>#18 库函数调用</li><li>#19 内存分配</li></ul></li><li>基本块级属性<ul><li>#20 循环结构</li><li>#21 条件结构</li><li>#22 复合if语句</li></ul></li><li>函数级属性<ul><li>#23 函数的使用</li></ul></li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/1.png?raw=true" /></p><p>​</p><h1 id="攻击方法">3 攻击方法</h1><h2 id="自动编码风格模仿攻击">3.1 自动编码风格模仿攻击</h2><p>​ 目标攻击。设作者集合为 <spanclass="math inline">\(\mathcal{A}\)</span> ，原作者 <spanclass="math inline">\(A_{s}\)</span> 撰写的程序为 <spanclass="math inline">\(p\)</span>，目标作者 <spanclass="math inline">\(A_{t}\)</span> 编写的程序集合为 <spanclass="math inline">\(R\)</span>，目的是将 <spanclass="math inline">\(p\)</span> 转化为 <spanclass="math inline">\(p^{&#39;}\)</span>，使得模型 <spanclass="math inline">\(M\)</span> 将其预测为 <spanclass="math inline">\(A_{t}\)</span>。</p><ol type="1"><li><p><strong>提取特征</strong>。提取原作者程序 <spanclass="math inline">\(p\)</span> 和目标作者程序集 <spanclass="math inline">\(R\)</span>的编码特征。</p></li><li><p><strong>特征合成</strong>。将从目标作者程序集 <spanclass="math inline">\(R\)</span> 中提取的特征合成。</p><ul><li>数字特征：取平均值</li><li>非数字特征：枚举，按照出现频率降序排列</li></ul></li><li><p><strong>识别差异</strong>。识别出 <spanclass="math inline">\(p\)</span> 和 <spanclass="math inline">\(R\)</span> 的差异特征。</p><ul><li>数字：<span class="math inline">\(p\)</span> 中的属性和 <spanclass="math inline">\(R\)</span> 中的属性差值大于阈值；</li><li>非数字：<span class="math inline">\(p\)</span> 中的属性非 <spanclass="math inline">\(R\)</span> 中的属性的子集。</li></ul></li><li><p><strong>代码转换</strong>。更改 <spanclass="math inline">\(p\)</span> 中识别出来的差异特征。</p><p>示例如下：</p></li></ol><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/2.png?raw=true" /></p><h2 id="自动编码风格隐藏攻击">3.2 自动编码风格隐藏攻击</h2><p>​ 非目标攻击。</p><ol type="1"><li><strong>提取原作者特征</strong>。提取原作者程序 <spanclass="math inline">\(p\)</span> 的编码特征。</li><li><strong>提取其他作者特征</strong>。对于任意 <spanclass="math inline">\(A_{d} \in\mathcal{A}-\left\{A_{s}\right\}\)</span>，提取 <spanclass="math inline">\(A_{d}\)</span> 的编码特征。</li><li><strong>计算待修改行数</strong>。对于任意 <spanclass="math inline">\(A_{d} \in\mathcal{A}-\left\{A_{s}\right\}\)</span>，计算和 <spanclass="math inline">\(p\)</span>的差异特征，然后计算需要修改的代码行数，选取行数修改最多的那个，记为<span class="math inline">\(A_{u} \in\mathcal{A}-\left\{A_{s}\right\}\)</span>。</li><li><strong>代码转换</strong>。更改 <spanclass="math inline">\(p\)</span> 和 <spanclass="math inline">\(A_{u}\)</span> 程序集的差异特征。</li></ol><h1 id="训练方法">4 训练方法</h1><p>​ 数据增强（1.<strong>编码风格模仿</strong>；2.<strong>编码风格扰动</strong>）和梯度增强（3.<strong>模型训练</strong>）。</p><p>数据包括：</p><ul><li>原始的训练样本及其标签</li><li>目标作者的集合</li><li>针对模型的对抗样本</li></ul><p>具体方法如下：</p><ol type="1"><li><p><strong>编码风格模仿</strong>。对于每个样本标签对，对于每个目标作者，使用模仿攻击将该样本转化为对抗样本，使得模型预测为该目标作者。该步骤产生的样本记为<span class="math inline">\(U\)</span>。</p></li><li><p><strong>编码风格扰动</strong>。</p><ul><li>将<strong>编码风格模仿</strong>生成对抗样本的方法实施到其他原始样本上</li><li>随机修改原始样本的编码属性</li></ul><p>该步骤产生的基本记为 <spanclass="math inline">\(U^{’}\)</span>。</p></li></ol><p>流程如下：</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/3.png?raw=true" /></p><ol start="3" type="1"><li><p><strong>模型训练</strong>。每次迭代的步骤如下：</p><ul><li>完整的正向传播和损失计算。使用 1.<strong>编码风格模仿</strong>产生的对抗样本 <span class="math inline">\(U\)</span>作为输入，在模型中进行前向传递，并计算损失：</li></ul><p><span class="math display">\[L_{s t d}=l(\mathcal{N}(\theta, u), v)\]</span></p><ul><li>子网络采样。对每一层的节点进行采样，得到子网络</li></ul><p><span class="math display">\[\mathcal{N}_{1}, \ldots, \mathcal{N}_{n}\]</span></p><ul><li>子网络的正向传播和损失计算。使用 2.<strong>编码风格扰动</strong>产生的对抗样本 <spanclass="math inline">\(U^{&#39;&#39;}\)</span>作为输入，在模型中进行前向传递，并计算损失: <spanclass="math display">\[L_{\text {subnet }}=\sum_{j=1}^{n}l\left(\mathcal{N}\left(\theta_{w_{j}}, u^{\prime}\right),v^{\prime}\right)\]</span></li></ul></li><li><p><strong>计算总损失</strong>。全网络损失和子网络损失之和： <spanclass="math display">\[L_{\text {RoPGen }}=L_{\text {std }}+L_{\text {subnet }}\]</span></p></li><li><p><strong>更新模型权重</strong>。反向传递计算增强的梯度。完整网络的梯度为：</p></li></ol><p><span class="math display">\[g_{s t d}=\frac{\partial l(\mathcal{N}(\theta, u), v)}{\partial \theta}\]</span></p><p>​ 子网络的梯度为： <span class="math display">\[g_{\text {subnet }}=\sum_{j=1}^{n} \frac{\partiall\left(\mathcal{N}\left(\theta_{w_{j}}, u^{\prime}\right),v^{\prime}\right)}{\partial \theta_{w_{j}}}\]</span> ​ 增强后的梯度为： <span class="math display">\[g_{\text {RoPGen }}=g_{\text {std }}+g_{\text {subnet }}\]</span> ​更新权重（完整网络和自网络共享），让网络的不同部分学习不同的表示。</p><h1 id="实验">5 实验</h1><h2 id="数据集">5.1 数据集</h2><ul><li><p>GCJ-C++。<a href="https://arxiv.org/abs/1905.12386">Google CodeJam (GCJ)</a> 中 204 位作者的 1632 个 C++ 程序文件，每个程序文件平均有74 行代码。</p></li><li><p>GitHub-Java。<ahref="https://pubmed.ncbi.nlm.nih.gov/29095934/">GitHub</a> 中 40位作者的 2827 个 Java 程序文件，每个程序文件平均有 76 行代码。</p></li><li><p>GitHub-C。GitHub 中 67 位作者的 2072 个 C文件，每个程序文件平均有 88 行代码。</p></li><li><p>GCJ-Java。Google Code Jam (GCJ) 中 74 个作者的 2396 个 Java文件，每个程序文件平均有 139 行代码。</p></li></ul><h2 id="目标模型">5.2 目标模型</h2><ul><li><p><ahref="https://www.cs.ucf.edu/~mohaisen/doc/ccs18.pdf">DL-CAIS</a></p></li><li><p><a href="https://arxiv.org/abs/2001.11593">PbNN</a></p></li></ul><p>在数据集上的准确率如下：</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/4.png?raw=true" /></p><h2 id="实验结果">5.3 实验结果</h2><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/5.png?raw=true" /></p><p>​ 表 3 显示了两种基于dl的归因方法在四个数据集上的攻击成功率。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/6.png?raw=true" /></p><p>​ 图 3 表明了</p><ul><li>测试集中涉及𝑟变换的被操纵程序占测试集中所有被操纵程序的比例。</li><li>两种基于dl的归因方法下，涉及𝑟变换的被操纵程序在测试集中攻击成功的被操纵程序占测试集中所有被操纵程序的比例。</li></ul><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/7.png?raw=true" /></p><p>​ 表 4 总结了每个 DL模型随机替换五次的平均结果和提出的攻击方法的对比。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/8.png?raw=true" /></p><p>​ 表 5 总结了在变量为 1, 3, 5 时 DL-CAIS的攻击成功率。这表明应用更多的代码转换可以增加模仿或隐藏编码风格的成功率。</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/RoPGen/9.png?raw=true" /></p><p>​ 表 6 显示了 8 个基于 ropgen 的模型的精度。</p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>AI 安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RoPGen</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Natural Attack for Pre-Trained Models of Code</title>
    <link href="/2023/07/22/ALERT/"/>
    <url>/2023/07/22/ALERT/</url>
    
    <content type="html"><![CDATA[<p>ALERT 论文笔记</p><span id="more"></span><h1 id="问题">1 问题</h1><ul><li><p>目前代码模型攻击研究侧重于保留操作语义（通过机器审查），但是缺乏自然语义（通过人审查），可能无法通过<ahref="https://yidatao.github.io/paper/tao_icsme2014.pdf">代码审查</a>。</p></li><li><p><ahref="https://ojs.aaai.org/index.php/AAAI/article/view/5469#:~:text=Zhang%2C%20H.%2C%20Li%2C%20Z.%2C%20Li%2C%20G.%2C%20Ma%2C%20L.%2C,Conference%20on%20Artificial%20Intelligence%2C%2034%20%2801%29%2C%201169-1176.%20https%3A%2F%2Fdoi.org%2F10.1609%2Faaai.v34i01.5469">MHM</a>随机样本策略较慢。</p></li></ul><h1 id="方法">2 方法</h1><h2 id="生成变量替代表">2.1 生成变量替代表</h2><h3 id="处理一个变量">2.1.1 处理一个变量</h3><ol type="1"><li><p>分词。使用 <a href="https://arxiv.org/pdf/1508.07909.pdf">BPE</a>将源代码中包含的许多特定领域的缩写词、行话及其组合分成若干 tokens，解决<a href="https://arxiv.org/pdf/2003.07914.pdf">out-of-vocabulary问题</a>。例如： <span class="math display">\[index2dict --&gt; index, 2, dict\]</span></p></li><li><p>对 token 生成替代项。对于一个被分词的变量名 <spanclass="math display">\[T=\left\langle t_{1}, t_{2}, \cdots, t_{m}\right\rangle\]</span> 其中的每个子 token，利用 <ahref="https://arxiv.org/abs/2002.08155">CodeBERT</a> 和 <ahref="https://arxiv.org/abs/2009.08366">GraphCodeBERT</a>的<strong>掩码预测功能</strong>生成该 token 的替代项列表 <spanclass="math display">\[T^{&#39;}=\left\langle t_{1}^{&#39;}, t_{2}^{&#39;}, \cdots,t_{m}^{&#39;}\right\rangle\]</span></p></li><li><p>排序。对于生成的替代项列表中的每个替代项，利用 <ahref="https://arxiv.org/abs/2002.08155">CodeBERT</a> 和 <ahref="https://arxiv.org/abs/2009.08366">GraphCodeBERT</a>的上下文嵌入功能将其转化为向量，将所有向量连接，计算与 <spanclass="math inline">\(T\)</span>的嵌入向量的余弦相似度，并按其降序排列，取相似度更高的替代项。</p></li></ol><h3 id="处理多个变量">2.1.2 处理多个变量</h3><p>枚举每一个变量的每一个出现的位置，计算此处该变量的替代项，将替代项加入该变量的替代项列表。最后删除重复和无效的单词。</p><p>伪代码如下：</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/ALERT/1.png?raw=true" /></p><h2 id="贪心算法攻击">2.2 贪心算法攻击</h2><h3 id="重要性分数">2.2.1 重要性分数</h3><p>​ 定义变量的重要性分数，确定被修改的变量。设 <spanclass="math inline">\(y\)</span> 是代码 <spanclass="math inline">\(c\)</span> 的真实标签，<spanclass="math inline">\(M(c)[y]\)</span> 是模型 <spanclass="math inline">\(M\)</span> 预测代码 <spanclass="math inline">\(c\)</span> 对于标签 <spanclass="math inline">\(y\)</span> 的置信度，<spanclass="math inline">\(c_{-i}^{*}\)</span> 是将代码 <spanclass="math inline">\(c\)</span> 中的第 <spanclass="math inline">\(i\)</span> 个 token 替换为 <spanclass="math inline">\(&lt;unk&gt;\)</span> 的代码，<spanclass="math inline">\(M(c_{-i}^{*})[y]\)</span> 是模型 <spanclass="math inline">\(M\)</span> 预测代码 <spanclass="math inline">\(c_{-i}^{*}\)</span> 对于标签 <spanclass="math inline">\(y\)</span> 的置信度，定义第 <spanclass="math inline">\(i\)</span> 个 token 的的重要性分数为 <spanclass="math display">\[IS_{i}=M(c)[y]-M\left(c_{-i}^{*}\right)[y]\]</span> ，即为将第 <span class="math inline">\(i\)</span> 个 token替换为 <unk> 后模型置信度的下降程度，下降的越多，说明越重要。</p><p>​ 每个 token 可能出现若干次，因此将重要性分数拓展为 <spanclass="math display">\[OIS_{var}=\sum_{i \in \operatorname{var}[\text { pos }]} IS_{i}\]</span> ，即将 token 的每个出现位置处的 <spanclass="math inline">\(IS_{i}\)</span> 相加，得到该 token的总体重要性分数。</p><h3 id="贪心">2.2.2 贪心</h3><p>​ 贪心地对 <span class="math inline">\(OIS_{var]}\)</span> 更高的token进行替换，直到攻击成功，即改变模型的输出。如果都未成功，则选用使模型预测置信度下降最大的那个token。</p><p>​ 伪代码如下：</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/ALERT/2.png?raw=true" /></p><h2 id="遗传算法攻击">2.3 遗传算法攻击</h2><h1 id="实验">3 实验</h1><h2 id="任务与数据集">3.1 任务与数据集</h2><ul><li><p>漏洞检测【判断代码是否有漏洞】：<ahref="https://arxiv.org/abs/1909.03496">Devign 数据集</a>，<ahref="https://arxiv.org/abs/2102.04664">CodeXGLUE 基准数据集</a>的一部分。</p></li><li><p>克隆检测【判断两份代码在操作语义上是否一致】：<ahref="https://www.cs.usask.ca/~croy/papers/2014/SvajlenkoICSME2014BigERA.pdf">BigCloneBench基准数据集</a>。</p></li><li><p>作者分类【预测代码的作者】：<ahref="https://dl.acm.org/doi/10.1145/3292577">Google Code Jam (GCJ)数据集</a>。</p></li></ul><h2 id="目标模型">3.2 目标模型</h2><ul><li><a href="https://arxiv.org/abs/2002.08155">CodeBERT</a></li><li><a href="https://arxiv.org/abs/2009.08366">GraphCodeBert</a></li></ul><p>将两个模型在三个任务上分别进行微调，得到如下结果</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/ALERT/4.png?raw=true" /></p><h2 id="结果">3.3 结果</h2><h3 id="自然度用户调查">3.3.1 自然度用户调查</h3><p><imgsrc="https://github.com/vexentox/pictures/blob/main/ALERT/5.png?raw=true" /></p><h3 id="攻击有效性评估">3.3.2 攻击有效性评估</h3><p>定义三种评估指标：</p><ul><li>Attack Success Rate(ASR)：攻击成功的代码片段数占总代码片段数的比例。</li><li>Variable Change Rate(VCR)：代码中被重命名的变量占总变量的比例。</li><li>Number of Queries (NoQ)：对受害者模型的访问次数。</li></ul><p>结果如下</p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/ALERT/7.png?raw=true" /></p><p><imgsrc="https://github.com/vexentox/pictures/blob/main/ALERT/8.png?raw=true" /></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>AI 安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ALERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DeepSort 论文解析</title>
    <link href="/2023/05/26/DeepSort/"/>
    <url>/2023/05/26/DeepSort/</url>
    
    <content type="html"><![CDATA[<p>DeepSort 论文解析</p><span id="more"></span><p><a href="https://arxiv.org/pdf/1703.07402.pdf">论文地址</a></p><h1 id="轨道处理和状态估计">1 轨道处理和状态估计</h1><p><strong>定义卡尔曼滤波状态 <span class="math inline">\((u, v, \gamma,h, \dot{x}, \dot{y}, \dot{\gamma}, \dot{h})\)</span></strong></p><p>我们假设相机未校准，且没有可用的自我运动信息，这是一个非常通用的跟踪场景。尽管这些情况对滤波框架构成了挑战，但它是最近多目标跟踪基准测试中最常见的设置。因此，我们的跟踪场景定义在八维状态空间<span class="math display">\[(u, v, \gamma, h, \dot{x}, \dot{y}, \dot{\gamma}, \dot{h})\]</span> 上，其中包含边界框中心位置 (u, v），纵横比 γ，高度 h以及它们在图像坐标中的速度 <span class="math inline">\((\dot{x},\dot{y}, \dot{\gamma},\dot{h})\)</span>。我们使用具有恒定速度运动和线性观测模型的标准卡尔曼滤波器，其中将边界坐标<span class="math inline">\((u, v, \gamma , h)\)</span>直接作为对象状态的观测值。</p><p><strong>如果某个 trick 连续 <spanclass="math inline">\(A_{max}\)</span>帧无法匹配检测结果，则删除；如果某个检测结果无法关联 trick，则增加trick</strong></p><p>对于每个轨迹 k，我们计算自上次成功关联检测以来的帧数 <spanclass="math inline">\(\alpha_{k}\)</span>。这个计数器在卡尔曼滤波器的预测过程中递增，并在轨迹与测量关联后重置为0。超过预定义的最大年龄 <span class="math inline">\(A_{max}\)</span>的轨迹被认为已经离开场景，并从轨迹集合中删除。对于无法与现有轨迹关联的每个检测，都会启动新的轨迹假设。这些新的轨迹在其前三帧中被分类为暂定状态。在此期间，我们期望在每个时间步骤中进行成功的测量关联，在它们的前三帧中没有成功与测量关联的轨迹将被删除。</p><h1 id="分配问题">2 分配问题</h1><p>解决预测的卡尔曼状态和新到达的测量之间的关联的传统方法是构建一个可以使用匈牙利算法解决的分配问题。在这个问题的形式化中，我们通过结合两个合适的度量来整合运动和外观信息。</p><p><strong>度量运动信息</strong></p><p>为了融入运动信息，我们使用预测的卡尔曼状态和新到达的测量之间的（平方的）马氏距离：<span class="math display">\[d^{(1)}(i,j)=\left(\boldsymbol{d}_{j}-\boldsymbol{y}_{i}\right)^{\mathrm{T}}\boldsymbol{S}_{i}^{-1}\left(\boldsymbol{d}_{j}-\boldsymbol{y}_{i}\right)\]</span> 我们用 <span class="math inline">\((y_{i}, S_{i})\)</span>表示第i个轨迹分布在测量空间中的投影，用 <spanclass="math inline">\(d_{j}\)</span>表示第j个边界框检测。马氏距离考虑了状态估计的不确定性，通过衡量检测与平均轨迹位置之间相隔多少个标准差来计算。此外，利用这个度量指标，可以通过将马氏距离与从逆<span class="math inline">\(\chi^{2}\)</span> 分布计算得到的 95%置信区间进行阈值化，从而排除不太可能的关联。</p><p>我们用一个指示符来表示这个决策： <span class="math display">\[b_{i, j}^{(1)}=\mathbb{1}\left[d^{(1)}(i, j) \leq t^{(1)}\right]\]</span>如果第i个轨迹和第j个检测之间的关联是可接受的，我们的指示符将评估为1。对于我们的四维测量空间，相应的马氏距离阈值为<span class="math inline">\(t^{(1)}\)</span> = 9.4877。</p><p><strong>度量外观信息</strong></p><p>尽管当运动不确定性较低时，马氏距离是一种适合的关联度量，但在我们的图像空间问题形式化中，从卡尔曼滤波框架得到的预测状态分布仅提供了对象位置的粗略估计。特别是，未考虑的相机运动可能会在图像平面上引入快速位移，使得马氏距离成为在遮挡情况下进行跟踪的一种相对缺乏信息的度量。因此，我们将第二个度量指标整合到分配问题中。对于每个边界框检测<span class="math inline">\(d_{j}\)</span>，我们计算出一个具有 <spanclass="math inline">\(\left\|\boldsymbol{r}_{j}\right\|=1\)</span>的外观描述符 <spanclass="math inline">\(r_{j}\)</span>。此外，我们为每个轨迹k保留一个包含最近<span class="math inline">\(L_{k} = 100\)</span>个相关外观描述符 <spanclass="math inline">\(\left\{\boldsymbol{r}_{k}^{(i)}\right\}_{k=1}^{L_{k}}\)</span>。然后，我们的第二个度量度量外观空间中第i 个轨迹和第 j 个检测之间的最小余弦距离： <span class="math display">\[d^{(2)}(i, j)=\min \left\{1-\boldsymbol{r}_{j}^{\mathrm{T}}\boldsymbol{r}_{k}^{(i)} \mid \boldsymbol{r}_{k}^{(i)} \in\mathcal{R}_{i}\right\}\]</span> 我们引入一个二进制变量来指示根据这个度量指标是否可以接受关联：<span class="math display">\[b_{i, j}^{(2)}=\mathbb{1}\left[d^{(2)}(i, j) \leq t^{(2)}\right]\]</span>并且我们在一个单独的训练数据集上找到适合这个指示变量的阈值。实际上，我们应用一个预训练的卷积神经网络来计算边界框的外观描述符。</p><p><strong>综合度量</strong></p><p>为了构建关联问题，我们使用加权和将两个度量结合起来： <spanclass="math display">\[c_{i, j}=\lambda d^{(1)}(i, j)+(1-\lambda) d^{(2)}(i, j) \\ Eq. 5\]</span> 如果一个关联在两个度量的门控区域内，我们称之为可接受的关联：<span class="math display">\[b_{i, j}=\prod_{m=1}^{2} b_{i, j}^{(m)} \\Eq. 6\]</span></p><h1 id="级联匹配">3 级联匹配</h1><p><strong>优先匹配距离上一次匹配成功的帧更少的 trick（维持信息更好的trick）</strong></p><p>我们引入了一个级联结构来解决一系列子问题，而不是在全局关联问题中解决测量与轨迹的关联。为了解释这种方法的动机，考虑以下情况：当一个物体被遮挡了较长一段时间后，随后的卡尔曼滤波预测会增加与物体位置相关的不确定性。因此，概率质量在状态空间中扩散，观测似然变得不太尖锐。直观上，关联度量应该通过增加测量与轨迹之间的距离来考虑概率质量的扩散。令人意外的是，当两个轨迹争夺同一个检测时，马氏距离更偏向于较大的不确定性，因为它有效地减小了任何检测与预测轨迹均值之间的距离，以标准差为单位。这是一种不希望的行为，因为它可能导致轨迹碎片化和不稳定的轨迹。因此，我们引入了一个匹配级联结构，优先考虑更频繁出现的物体，以编码我们关于关联似然中概率扩散的观念：</p><p><img src="https://github.com/vexentox/reproduction/blob/main/DeepSort/%E7%BA%A7%E8%81%94%E5%8C%B9%E9%85%8D.png?raw=true"></p><h1 id="外观特征提取">4 外观特征提取</h1><p>通过使用简单的最近邻查询而无需额外的度量学习，我们的方法成功应用需要在实际的在线跟踪应用之前离线训练一个具有良好区分性的特征嵌入。为此，我们使用了一个在大规模行人重识别数据集上进行训练的CNN，该数据集包含了超过 1,100,000 张 1,261个行人的图像，非常适合在人员跟踪环境中进行深度度量学习。</p><p><img src="https://github.com/vexentox/reproduction/blob/main/DeepSort/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96.png?raw=true"></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>DeepSort、论文解析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SlowFast 论文解析</title>
    <link href="/2023/05/26/SlowFast%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/05/26/SlowFast%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<p>SlowFast 论文解析</p><span id="more"></span><p><a href="https://arxiv.org/pdf/1812.03982.pdf">论文地址</a></p><h1 id="引言">1 引言</h1><p><strong>相比于图像数据（h * w），视频数据（帧 * h *w）无法等价地处理所有的帧</strong></p><p>在图像识别中，习惯上对两个空间维度 x 和 y进行对称处理。这是基于自然图像的统计学特征的合理性，自然图像在一级近似上是各向同性的，即所有方向的出现概率相等，并且具有平移不变性。但是对于视频信号I(x, y, t)呢？运动是时空方向的对应物，但并非所有时空方向的出现概率都相等。缓慢的运动比快速运动更常见（事实上，我们所看到的大部分物体在某一时刻是静止的），这一特点已被贝叶斯模型用于解释人类如何感知运动刺激。例如，当我们看到一个孤立的移动边缘时，我们会感知它垂直于自身移动，即使从原理上讲它也可能具有沿切线方向的任意移动分量（光流中的光圈问题）。如果先验偏向于缓慢的运动，这种感知是合理的。</p><p><strong>提出双路径(Slow 和 Fast)，Slow 提取空间信息，Fast提取动作信息</strong></p><p>基于这个直觉，我们提出了一种用于视频识别的双路径（SlowFast）模型。其中一个路径旨在捕捉可以通过图像或少数稀疏帧提供的语义信息，它以低帧率和较慢的刷新速度进行操作。相比之下，另一个路径负责捕捉快速变化的运动，它以快速刷新速度和高时间分辨率进行操作。尽管这个路径具有较高的时间率，但它非常轻量级，例如，约占总计算量的20%。这是因为该路径的设计采用了较少的通道和较弱的处理空间信息的能力，而这些信息可以通过第一个路径以较少的冗余方式提供。我们将第一个路径称为Slow路径，将第二个路径称为Fast路径，这是由它们不同的时间速度驱动的。这两个路径通过横向连接进行融合。</p><p><img src="https://github.com/vexentox/reproduction/blob/main/SlowFast/%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png?raw=true"></p><h1 id="网络结构">2 网络结构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/SlowFast/%E5%AE%9E%E9%99%85%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png?raw=true-"></p><h2 id="慢通道">2.1 慢通道</h2><p>慢速路径可以是任何卷积模型，它将视频剪辑作为时空体进行处理。我们慢速路径的关键概念是在输入帧上使用较大的时间步长τ，即仅处理τ帧中的一帧。我们研究的典型τ值为16，这意味着对于30fps的视频，刷新速度大约为每秒采样2帧。将慢速路径采样的帧数表示为T，则原始剪辑的长度为T× τ帧。</p><h2 id="快通道">2.2 快通道</h2><h3 id="high-frame-rate">2.2.1 High frame rate</h3><p><strong>帧率高</strong></p><p>我们的目标是在时间维度上获得精细的表示。我们的快速通道使用小的时间跨度τ/ α，其中α &gt;1是快速通道和慢速通道之间的帧速率比率。这两个通道在同一原始片段上操作，因此快速通道采样αT帧，比慢速通道密集了α倍。在我们的实验中，典型的值为α= 8。</p><h3 id="high-temporal-resolution-features">2.2.2 High temporalresolution features</h3><p><strong>分辨率高</strong></p><p>我们的快速通道不仅具有高输入分辨率，还追求整个网络层次结构中的高分辨率特征。在我们的实例中，我们在快速通道中没有使用任何时间降采样层（既没有时间汇聚也没有时间步长卷积），直到分类之前的全局汇聚层。因此，我们的特征张量在时间维度上始终具有αT帧，尽可能地保持时间的准确性。</p><h3 id="low-channel-capacity">2.2.3 Low channel capacity</h3><p><strong>通道少</strong></p><p>我们的快速通道还与现有模型有所区别，它可以使用显著较低的通道容量来实现SlowFast模型的良好准确性。这使得它非常轻量化。</p><h2 id="lateral-connections">2.3 Lateral connections</h2><p>我们的横向连接从快速通道融合到慢速通道。在融合之前，需要匹配特征的尺寸。假设慢速通道的特征形状为{T，S2，C}，快速通道的特征形状为{αT，S2，βC}。我们在横向连接中进行以下转换的实验：</p><ol type="1"><li><p>时间到通道：我们将{αT，S2，βC}重新调整形状并转置为{T，S2，αβC}，这意味着我们将所有的α帧打包到一个帧的通道中。</p></li><li><p>时间步长采样：我们简单地从每个α帧中采样一个，因此{αT，S2，βC}变为{T，S2，βC}。</p></li><li><p>时间步长卷积：我们使用5×12大小的内核进行3D卷积，输出通道数为2βC，步长为α。横向连接的输出通过求和或连接的方式融合到慢速通道中。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SlowFast、论文解析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv2 论文解析</title>
    <link href="/2023/05/25/YOLOv2%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/05/25/YOLOv2%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<p>YOLOv2 论文解析</p><span id="more"></span><p><a href="https://arxiv.org/pdf/1506.02640.pdf">论文地址</a></p><h1 id="改进">1 改进</h1><h2 id="batch-normalization批量规范化">1.1 BatchNormalization（批量规范化）</h2><p><strong>对每一层的输出向量进行归一化</strong></p><p>批量归一化在收敛性方面取得了显著的改进，同时消除了其他形式的正则化的需求。通过在YOLO的所有卷积层上添加批量归一化，我们的mAP得到了超过2%的提高。批量归一化还有助于对模型进行正则化。通过批量归一化，我们可以在不过拟合的情况下移除模型中的dropout。</p><h2 id="high-resolution-classifier">1.2 High Resolution Classifier</h2><p><strong>将输入向量大小从 224 * 224 扩大到 448 * 448</strong></p><p>所有最先进的检测方法都使用在ImageNet上预训练的分类器。从AlexNet开始，大多数分类器在小于256×256的输入图像上进行操作。最初的YOLO在224×224的分辨率下训练分类器网络，并将其增加到448用于检测。这意味着网络必须同时切换到学习目标检测并适应新的输入分辨率。</p><p>对于YOLOv2，我们首先在ImageNet上对完整的448×448分辨率下的分类网络进行了10个epoch的微调。这给网络足够的时间来调整其滤波器，以更好地适应更高分辨率的输入。然后，我们对结果进行目标检测的微调。这个高分辨率分类网络使我们的mAP增加了近4%。</p><h2 id="convolutional-with-anchor-boxes-anchor-boxes">1.3 ConvolutionalWith Anchor Boxes (Anchor Boxes)</h2><p><strong>使用 Anchor Boxes 机制，改变输出向量的意义（坐标 --&gt; 与Anchor Box的坐标差）和损失函数的计算方式（通过坐标差计算出预测坐标）</strong></p><p>YOLO 直接使用全连接层在卷积特征提取器之上预测边界框的坐标。而FasterR-CNN则通过手动选择的先验框来预测边界框[15]。在FasterR-CNN中，仅使用卷积层的区域建议网络（RPN）为锚定框预测偏移量和置信度。由于预测层是卷积层，RPN在特征图的每个位置预测这些偏移量。预测偏移量而不是坐标简化了问题，并使网络更容易学习。</p><p>我们从YOLO中移除全连接层，并使用锚定框来预测边界框。首先，我们去掉一个池化层，以使网络的卷积层输出更高分辨率。我们还将网络缩小，使其处理416×416的输入图像，而不是448×448。我们这样做是因为我们希望特征图中有奇数个位置，以便有一个单独的中心单元格。对象，特别是大对象，倾向于占据图像的中心，因此在中心位置预测这些对象比在附近的四个位置预测更好。YOLO的卷积层将图像下采样32倍，因此通过使用416的输入图像，我们得到一个13×13的输出特征图。</p><p>当我们转向锚定框时，我们还将类别预测机制与空间位置解耦，并为每个锚定框预测类别和物体性质。在YOLO之后，物体性质预测仍然预测真实值和提议框的IOU，而类别预测则预测在存在物体的情况下给出该类别的条件概率。</p><p>使用锚定框会导致准确率略微降低。YOLO每张图像仅预测98个框，但使用锚定框后，我们的模型预测超过一千个框。在没有锚定框的情况下，我们的中间模型的mAP为69.5%，召回率为81%。使用锚定框后，我们的模型的mAP为69.2%，召回率为88%。尽管mAP降低了，但召回率的增加意味着我们的模型有更大的改进空间。</p><h2 id="dimension-clusters">1.4 Dimension Clusters</h2><p><strong>kmeans 构造 Anchor Boxes</strong></p><p>在使用YOLO时，锚定框存在两个问题。第一个问题是锚定框的尺寸是手动选择的。尽管网络可以学习适应性地调整锚定框，但如果我们在网络初始阶段选择更好的先验框，可以更容易地帮助网络学习预测良好的检测结果。为了避免手动选择先验框，我们在训练集的边界框上运行k-means聚类算法，自动地找到良好的先验框。</p><h2 id="direct-location-prediction">1.5 Direct location prediction</h2><p><strong>细说 1.3 中的坐标偏差</strong></p><p>在使用YOLO的过程中，使用锚定框会遇到第二个问题：模型的不稳定性，尤其是在早期迭代阶段。大部分的不稳定性来自于对边界框的（x，y）位置的预测。在区域建议网络中，网络预测了tx和ty的值，而（x，y）中心坐标的计算方式如下：<span class="math display">\[\begin{matrix}x=(t_{x}*w_{\alpha })+x_{\alpha }  \\y=(t_{y}*w_{\alpha })+y_{\alpha }\end{matrix}\]</span> 例如，对于预测的tx =1，会将边界框向右平移一个锚定框的宽度，而tx =-1的预测会将其向左平移相同的距离。这种表达方式是无约束的，因此任何锚定框都可能出现在图像的任何位置，无论哪个位置预测了该框。在随机初始化的情况下，模型需要很长时间才能稳定下来，以预测合理的偏移量。</p><p>与预测偏移量不同，我们遵循YOLO的方法，预测相对于网格单元位置的坐标。这将使真实值限制在0到1之间。我们使用逻辑激活函数将网络的预测限制在此范围内。网络在输出特征图的每个单元格中预测5个边界框。网络为每个边界框预测5个坐标，tx、ty、tw、th和to。如果单元格相对于图像的左上角偏移了(cx，cy)，并且边界框先验具有宽度和高度pw、ph，则预测对应于：<span class="math display">\[\begin{matrix} b_{x}  =\sigma(t_{x})+c_{x}\\ b_{y}  =\sigma(t_{y})+c_{y} \\b_{w}  =p_{w} e^{t_{w}} \\b_{h}  =p_{h} e^{t_{h}} \\\operatorname{Pr}(\text { object }) * \operatorname{IOU}(b, \text {object })  =\sigma(t_{o})\end{matrix}\]</span></p><p>由于我们对位置预测进行了约束，参数化更容易学习，从而使网络更加稳定。通过使用尺寸聚类以及直接预测边界框中心位置，相比使用锚定框的版本，YOLO的性能提高了近5%。</p><h2 id="fine-grained-features">1.6 Fine-Grained Features</h2><p><strong>降低特征提取网络输出的特征图的大小，增加输出通道</strong></p><p>这种修改后的YOLO在一个13×13的特征图上进行目标检测。虽然这对于大型物体已经足够，但对于定位较小物体可能会受益于更精细的特征。FasterR-CNN和SSD都在网络的不同特征图上运行其候选框网络，以获得不同的分辨率。我们采取了不同的方法，只需添加一个传递层，将26×26分辨率的较早层的特征传递到当前层。传递层通过将高分辨率特征与低分辨率特征进行连接，将相邻特征堆叠到不同的通道中，而不是在空间位置上堆叠，类似于ResNet中的身份映射。这将26×26×512的特征图转换为13×13×2048的特征图，可以与原始特征进行级联。我们的检测器在这个扩展的特征图上运行，以便可以使用细粒度的特征。这使得性能增加了1%左右。</p><h1 id="网络结构">网络结构</h1><p><ahref="https://github.com/pjreddie/darknet/blob/master/cfg/yolov1.cfg">cfg文件下载</a></p><p><img src="https://raw.githubusercontent.com/vexentox/reproduction/dad190f79839608ee59b76d89809a60bde7769b0/YOLOv1/weights/yolov1.cfg.svg"></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv2、论文解析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv1 论文解析</title>
    <link href="/2023/05/24/YOLOv1%E8%A7%A3%E6%9E%90/"/>
    <url>/2023/05/24/YOLOv1%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<p>YOLOv1 论文解析</p><span id="more"></span><p><a href="https://arxiv.org/pdf/1506.02640.pdf">论文地址</a></p><h1 id="思路">思路</h1><p>​ 将输入图像划分为 S × S 网格。如果一个物体的中心落在一个网格单元中，则该网格单元负责检测该物体。</p><p>​ 每个网格单元预测 B 个边界框和这些框的置信度。置信度反映了对于模型是盒子包含一个对象，以及它认为盒子是它预测的准确度的信任程度。将置信度定义为 <span class="math display">\[\operatorname{Pr}(\text { Object }) * \mathrm{IOU}_{\text {pred}}^{\text {truth }}\]</span> ​ 如果该单元格中不存在对象，则置信度分数应为零。否则，置信度分数等于预测框和真实框之间的 IOU。</p><p>​ 每个边界框由 5 个预测组成：x、y、w、h 和置信度。 (x, y)坐标表示框相对于网格单元边界的中心，w 和 h是相对于整个图像预测的，置信度表示预测框与实际框之间的IOU。因此，预测的值范围是 [0, 1]。</p><p>​ 同时，每个网格单元还预测类别的条件概率，即 <spanclass="math display">\[\operatorname{Pr}\left(\text { Class }_{i} \mid \text { Object }\right)\]</span> ​ 无论该单元格需要预测几个框，它只预测一组条件概率。</p><p>​ 在测试时，将条件概率和单个预测框的置信度相乘，即 <spanclass="math display">\[\operatorname{Pr}\left(\text { Class }_{i} \mid \text { Object }\right)* \operatorname{Pr}(\text { Object }) * \mathrm{IOU}_{\text {pred}}^{\text {truth }}=\operatorname{Pr}\left(\text { Class }_{i}\right) *\mathrm{IOU}_{\text {pred }}^{\text {truth }}\]</span> ​ 得到每个盒子的特定类别的置信度。</p><p>​ 最终输出的向量大小为 <span class="math display">\[(bathsize, S*S*(5*B+C))\]</span></p>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv1、论文解析</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv5 + DeepSort 实现多目标跟踪</title>
    <link href="/2023/05/18/yolov5_deepsort%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"/>
    <url>/2023/05/18/yolov5_deepsort%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/</url>
    
    <content type="html"><![CDATA[<p>YOLOv5 + DeepSort 实现多目标跟踪</p><span id="more"></span><h1 id="部署-yolov5">0 部署 YOLOv5</h1><p>参考博文 <ahref="https://vexentox.github.io/2023/05/17/yolov5%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/">YOLOv5实现目标检测</a></p><h1 id="环境配置">1 环境配置</h1><h2 id="克隆项目">1.1 克隆项目</h2><p>下载 <ahref="https://gitcode.net/mirrors/mikel-brostrom/Yolov5_DeepSort_Pytorch/-/tree/v3.0">项目</a></p><p>将 yolov5 文件夹替换为我们部署的 yolov5 项目文件夹</p><p>项目结构为：</p><ul><li>YOLOv5_DeepSort<ul><li>deep_sort_pytorch</li><li>MOT16_eval</li><li>yolov5</li></ul></li></ul><h2 id="安装依赖">1.2 安装依赖</h2><p><code>pip install -r .\requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p><h1 id="数据集准备">2 数据集准备</h1><h2 id="文件布置">2.1 文件布置</h2><p>根据 <ahref="https://vexentox.github.io/2023/05/17/yolov5%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/">YOLOv5实现目标检测</a> 数据格式，在 Data 下创建 DeepSort 文件夹，表示这是DeepSort 的训练数据。</p><h2 id="分割数据集">2.2 分割数据集</h2><p>在 deep_sort_pytorch\deep_sort\deep\data 文件夹下创建一个run.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2, os, random, shutil, argparse<br><span class="hljs-keyword">import</span> xml.etree.ElementTree <span class="hljs-keyword">as</span> ET<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">split</span>(<span class="hljs-params">train_scale</span>):<br>    img_path = <span class="hljs-string">&#x27;../JPEGImages/&#x27;</span><br>    anno_path = <span class="hljs-string">&#x27;../Annotations/&#x27;</span><br>    cut_path = <span class="hljs-string">&#x27;train/&#x27;</span><br><br>    os.makedirs(cut_path, exist_ok=<span class="hljs-literal">True</span>)<br><br>    txt_file = <span class="hljs-string">&quot;../classes.txt&quot;</span><br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(txt_file, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        dict_obj_i = &#123;line.strip(): i <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(f.read().splitlines())&#125;<br><br>    <span class="hljs-keyword">for</span> xml_file <span class="hljs-keyword">in</span> tqdm(os.listdir(anno_path), <span class="hljs-string">&#x27;生成数据集&#x27;</span>, ncols=<span class="hljs-number">100</span>):<br>        xml_pre, ext = os.path.splitext(xml_file)<br>        img_file = os.path.join(img_path, xml_pre + <span class="hljs-string">&#x27;.jpg&#x27;</span>)<br>        xml_file = os.path.join(anno_path, xml_file)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(img_file):<br>            <span class="hljs-keyword">continue</span><br>        img = cv2.imread(img_file)<br>        tree = ET.parse(xml_file)<br>        root = tree.getroot()<br>        <span class="hljs-keyword">for</span> obj <span class="hljs-keyword">in</span> root.<span class="hljs-built_in">iter</span>(<span class="hljs-string">&#x27;object&#x27;</span>):<br>            cls = obj.find(<span class="hljs-string">&#x27;name&#x27;</span>).text<br>            <span class="hljs-keyword">if</span> cls <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> dict_obj_i:<br>                <span class="hljs-keyword">continue</span><br>            obj_i = dict_obj_i[cls]<br>            xmlbox = obj.find(<span class="hljs-string">&#x27;bndbox&#x27;</span>)<br>            b = [<span class="hljs-built_in">int</span>(<span class="hljs-built_in">float</span>(xmlbox.find(name).text)) <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;xmin&#x27;</span>, <span class="hljs-string">&#x27;ymin&#x27;</span>, <span class="hljs-string">&#x27;xmax&#x27;</span>, <span class="hljs-string">&#x27;ymax&#x27;</span>]]<br>            img_cut = img[b[<span class="hljs-number">1</span>]:b[<span class="hljs-number">3</span>], b[<span class="hljs-number">0</span>]:b[<span class="hljs-number">2</span>], :]<br>            cls_path = os.path.join(cut_path, cls)<br>            os.makedirs(cls_path, exist_ok=<span class="hljs-literal">True</span>)<br>            img_cut_file = os.path.join(cls_path, <span class="hljs-string">&#x27;&#123;&#125;_&#123;:0&gt;2d&#125;.jpg&#x27;</span>.<span class="hljs-built_in">format</span>(xml_pre, obj_i))<br>            cv2.imwrite(img_cut_file, img_cut)<br><br>    src_path = <span class="hljs-string">&#x27;train&#x27;</span><br>    dst_path = <span class="hljs-string">&#x27;val&#x27;</span><br>    os.makedirs(dst_path, exist_ok=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">for</span> classes <span class="hljs-keyword">in</span> tqdm(os.listdir(src_path), <span class="hljs-string">&#x27;分割数据集&#x27;</span>, ncols=<span class="hljs-number">100</span>):<br>        dst_dir = os.path.join(dst_path, classes)<br>        os.makedirs(dst_dir, exist_ok=<span class="hljs-literal">True</span>)<br>        deal_class = os.path.join(src_path, classes)<br>        in_class = os.listdir(deal_class)<br>        total_num = <span class="hljs-built_in">len</span>(in_class)<br>        train_num = <span class="hljs-built_in">int</span>(total_num * train_scale)<br>        <span class="hljs-built_in">print</span>(train_num)<br>        val_num = total_num - train_num<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(val_num):<br>            val_jpg = random.choice(in_class)<br>            in_class.remove(val_jpg)<br>            val_path = os.path.join(deal_class, val_jpg)<br>            <span class="hljs-comment"># if not os.path.exists(val_path):</span><br>            shutil.move(val_path, dst_dir)<br><br><br>parser = argparse.ArgumentParser()<br>parser.add_argument(<span class="hljs-string">&#x27;--train_scale&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.8</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Training scale&#x27;</span>)<br>args = parser.parse_args()<br>train_scale = args.train_scale<br>split(train_scale)<br></code></pre></td></tr></table></figure><p>参数表为：</p><table><thead><tr class="header"><th style="text-align: left;">参数</th><th style="text-align: left;">意义</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">train_scale</td><td style="text-align: left;">训练集的比例</td></tr></tbody></table><p>运行 run.py：<code>python run.py --train_scale 0.8</code></p><p>Data / DeepSort 文件夹下将产生两个文件夹 train 和val，分别包含了训练集和验证集从检测框中截取的图片。</p><h2 id="文件结构">2.3 文件结构</h2><ul><li>Data<ul><li>Annotations</li><li>JPEGImages</li><li>DeepSort<ul><li>train<ul><li>classx</li><li>...</li></ul></li><li>val<ul><li>classx</li><li>...</li></ul></li></ul></li></ul></li></ul><h1 id="训练">3 训练</h1><p>将 deep_sort_pytorch / deep_sort / deep / train.py 32 行改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">test_dir = os.path.join(root, <span class="hljs-string">&quot;val&quot;</span>)<br></code></pre></td></tr></table></figure><p>进入 deep_sort_pytorch / deep_sort / deep 文件夹，运行 train.py</p><table><thead><tr class="header"><th style="text-align: left;">参数</th><th style="text-align: left;">意义</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">data-dir</td><td style="text-align: left;">数据集目录</td></tr><tr class="even"><td style="text-align: left;">no-cuda</td><td style="text-align: left;">是否没有 gpu</td></tr><tr class="odd"><td style="text-align: left;">gpu-id</td><td style="text-align: left;">gpu 编号</td></tr><tr class="even"><td style="text-align: left;">lr</td><td style="text-align: left;">学习率</td></tr></tbody></table><p><code>python train.py --data-dir 'D:\TX\Behavior Recognition\Data\DeepSort'</code></p><h1 id="多目标跟踪">4 多目标跟踪</h1><p>运行 track.py</p><h2 id="可能出现的-error">4.1 可能出现的 Error</h2><p><strong>Error</strong>：<code>AttributeError: module 'numpy' has no attribute 'float'.</code></p><p><strong>Solution</strong>：</p><p>将 deep_sort_pytorch_sort.py 中的 30 行改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.tlwh = np.asarray(tlwh, dtype=np.float32)<br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>AttributeError: module 'numpy' has no attribute 'int'.</code></p><p><strong>Solution</strong>：</p><p>将 deep_sort_pytorch_sort_sort.py 中的 50 行改为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">outputs.append(np.array([x1, y1, x2, y2, track_id], dtype=np.int32))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv5 + DeepSort 实现多目标跟踪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv5 实现目标检测</title>
    <link href="/2023/05/17/yolov5%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    <url>/2023/05/17/yolov5%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<p>YOLOv5 实现目标检测</p><span id="more"></span><h1 id="环境配置">1 环境配置</h1><h2 id="代码克隆">1.1 代码克隆</h2><p><a href="https://github.com/ultralytics/yolov5/tree/v5.0">YOLOv5代码仓库</a></p><h2 id="目录解析">1.2 目录解析</h2><ul><li>data</li><li>images：官方提供的测试图片</li><li>script</li><li>.yaml 文件：用于配置训练集、验证集、类别数、类名的文件<ul><li>train：训练集路径</li><li>val：验证集路径</li><li>nc：类别数量</li><li>names：类别名称列表</li></ul></li><li>models：YOLO网络的配置文件以及函数，包含了s（small）、m（medium）、l（large）、x四个不同的版本</li><li>utils：存放的是工具类的函数，包括 loss 函数，metrics 函数，plots函数等</li><li>weights：权重参数</li><li>detect.py：推理函数，即目标检测</li><li>train.py：训练</li><li>test.py：测试</li><li>requirements.txt：所需要的依赖包</li></ul><h2 id="安装依赖">1.3 安装依赖</h2><ul><li>创建新的环境：<code>conda create -n BR python=3.8</code></li><li>进入 YOLO 文件：<code>cd yolov5</code></li><li>将 requirements.txt 中的 <code>pycocotools&gt;=2.0</code> 替换为<code>pycocotools-windows</code></li><li>pip下载：<code>pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</code></li></ul><h1 id="目标检测预训练模型">2 目标检测（预训练模型）</h1><h2 id="下载预训练模型">2.1 下载预训练模型</h2><p><ahref="https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt">yolov5s</a></p><p>放入 weights 文件夹中</p><h2 id="检测图片">2.2 检测图片</h2><p><code>python .\detect.py --weights .\weights\yolov5s.pt --source .\data\images\bus.jpg</code></p><h2 id="检测视频">2.3 检测视频</h2><p><code>python .\detect.py --weights .\weights\yolov5s.pt --source .\data\videos\1.mp4</code></p><h2 id="可能出现的-error">2.4 可能出现的 Error</h2><p><strong>Error</strong>：<code>AttributeError: Can't get attribute 'SPPF' on &lt;module 'models.common' from 'D:\\TX\\Behavior Recognition\\yolov5\\models\\common.py'&gt;</code></p><p><strong>Solution</strong>：在 <code>models\\common.py</code>添加下面这段代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> warnings<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPPF</span>(nn.Module):<br>    <span class="hljs-comment"># Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, c1, c2, k=<span class="hljs-number">5</span></span>):  <span class="hljs-comment"># equivalent to SPP(k=(5, 9, 13))</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        c_ = c1 // <span class="hljs-number">2</span>  <span class="hljs-comment"># hidden channels</span><br>        self.cv1 = Conv(c1, c_, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        self.cv2 = Conv(c_ * <span class="hljs-number">4</span>, c2, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        self.m = nn.MaxPool2d(kernel_size=k, stride=<span class="hljs-number">1</span>, padding=k // <span class="hljs-number">2</span>)<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.cv1(x)<br>        <span class="hljs-keyword">with</span> warnings.catch_warnings():<br>            warnings.simplefilter(<span class="hljs-string">&#x27;ignore&#x27;</span>)  <span class="hljs-comment"># suppress torch 1.9.0 max_pool2d() warning</span><br>            y1 = self.m(x)<br>            y2 = self.m(y1)<br>            <span class="hljs-keyword">return</span> self.cv2(torch.cat([x, y1, y2, self.m(y2)], <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>AttributeError: 'Upsample' object has no attribute 'recompute_scale_factor'</code></p><p><strong>Solution</strong>：在 yolo.py 第 127行下，添加下面这段代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Upsample):<br>m.recompute_scale_factor = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_once</span>(<span class="hljs-params">self, x, profile=<span class="hljs-literal">False</span></span>):<br>    y, dt = [], []  <span class="hljs-comment"># outputs</span><br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.model:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Upsample):<br>            m.recompute_scale_factor = <span class="hljs-literal">None</span><br>            <span class="hljs-keyword">if</span> m.f != -<span class="hljs-number">1</span>:  <span class="hljs-comment"># if not from previous layer</span><br>                x = y[m.f] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m.f, <span class="hljs-built_in">int</span>) <span class="hljs-keyword">else</span> [x <span class="hljs-keyword">if</span> j == -<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> y[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> m.f] <br>                <span class="hljs-keyword">if</span> profile:<br>                    o = thop.profile(m, inputs=(x,), verbose=<span class="hljs-literal">False</span>)[<span class="hljs-number">0</span>] / <span class="hljs-number">1E9</span> * <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> thop <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># FLOPS</span><br>                    t = time_synchronized()<br>                    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>                        _ = m(x)<br>                        dt.append((time_synchronized() - t) * <span class="hljs-number">100</span>)<br>                        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%10.1f%10.0f%10.1fms %-40s&#x27;</span> % (o, m.np, dt[-<span class="hljs-number">1</span>], m.<span class="hljs-built_in">type</span>))<br><br>                        x = m(x)  <span class="hljs-comment"># run</span><br>                        y.append(x <span class="hljs-keyword">if</span> m.i <span class="hljs-keyword">in</span> self.save <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)  <span class="hljs-comment"># save output</span><br><br>                        <span class="hljs-keyword">if</span> profile:<br>                            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%.1fms total&#x27;</span> % <span class="hljs-built_in">sum</span>(dt))<br>                            <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>RuntimeError: The size of tensor a (60) must match the size of tensor b (56) at non-singleton dimension 3</code></p><p><strong>Solution</strong>：将 yolov5s.pt 替换为 5.0 版本，即 <ahref="https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt">yolov5s5.0 权重</a>。</p><h2 id="查看结果">2.5 查看结果</h2><p>在目录 runs\detect\exp下查看生成的文件</p><h1 id="数据集准备">3 数据集准备</h1><h2 id="数据标注">3.1 数据标注</h2><h3 id="安装-labelimg">3.1.1 安装 labelimg</h3><p><code>pip install labelimg -i https://pypi.tuna.tsinghua.edu.cn/simple</code></p><h3 id="创建-voc-格式目录">3.1.2 创建 VOC 格式目录</h3><ul><li><p>yolov5：项目文件夹</p></li><li><p>Data</p><ul><li>JPEGImages：存放图片文件</li><li>Annotations：存放标注的标签文件</li><li>classes.txt：定义自己要标注的所有类别</li></ul></li></ul><h3 id="运行-labelimg">3.1.3 运行 labelimg</h3><p>进入 Data文件夹，运行：<code>labelimg JPEGImages classes.txt</code></p><h2 id="进行标注">3.2 进行标注</h2><p><strong>Open Dir</strong>：打开图片文件夹</p><p><strong>Create RectBox</strong>：选择目标框</p><p><strong>Change Save Dir</strong>：选择生成的 xml 文件的保存目录</p><h2 id="数据分割">3.3 数据分割</h2><p>在 Data 文件夹下创建一个文件夹 YOLOv5 用来存放YOLOv5 训练数据。</p><p>在 Data / YOLOv5 文件夹下创建一个 run.py：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os, random, argparse<br><span class="hljs-keyword">import</span> xml.etree.ElementTree <span class="hljs-keyword">as</span> ET<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_xml_to_txt</span>(<span class="hljs-params">xml_file, txt_file</span>):<br>    tree = ET.parse(xml_file)<br>    root = tree.getroot()<br>    image_width = <span class="hljs-built_in">int</span>(root.find(<span class="hljs-string">&quot;size/width&quot;</span>).text)<br>    image_height = <span class="hljs-built_in">int</span>(root.find(<span class="hljs-string">&quot;size/height&quot;</span>).text)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(txt_file, <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> obj <span class="hljs-keyword">in</span> root.<span class="hljs-built_in">iter</span>(<span class="hljs-string">&quot;object&quot;</span>):<br>            name = obj.find(<span class="hljs-string">&quot;name&quot;</span>).text<br>            class_index = class_mapping[name]<br><br>            xmin = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/xmin&quot;</span>).text)<br>            ymin = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/ymin&quot;</span>).text)<br>            xmax = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/xmax&quot;</span>).text)<br>            ymax = <span class="hljs-built_in">int</span>(obj.find(<span class="hljs-string">&quot;bndbox/ymax&quot;</span>).text)<br><br>            x_center = (xmin + xmax) / <span class="hljs-number">2</span> / image_width<br>            y_center = (ymin + ymax) / <span class="hljs-number">2</span> / image_height<br>            width = (xmax - xmin) / image_width<br>            height = (ymax - ymin) / image_height<br><br>            line = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;class_index&#125;</span> <span class="hljs-subst">&#123;x_center&#125;</span> <span class="hljs-subst">&#123;y_center&#125;</span> <span class="hljs-subst">&#123;width&#125;</span> <span class="hljs-subst">&#123;height&#125;</span>\n&quot;</span><br>            f.write(line)<br><br>parser = argparse.ArgumentParser()<br>parser.add_argument(<span class="hljs-string">&#x27;--train_scale&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.8</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Training scale&#x27;</span>)<br>args = parser.parse_args()<br><br>train_scale = args.train_scale<br>train_scale = <span class="hljs-number">0.5</span><br>train_folder = <span class="hljs-string">&#x27;./labels/train&#x27;</span><br>val_folder = <span class="hljs-string">&#x27;./labels/val&#x27;</span><br>os.makedirs(train_folder, exist_ok=<span class="hljs-literal">True</span>)<br>os.makedirs(val_folder, exist_ok=<span class="hljs-literal">True</span>)<br>annotations_file = <span class="hljs-string">&#x27;../Annotations&#x27;</span><br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../classes.txt&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    class_mapping = &#123;line.strip(): i <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(f.read().splitlines())&#125;<br><br>annotations_list = os.listdir(annotations_file)<br>random.shuffle(annotations_list)<br>split_index = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(annotations_list) * train_scale)<br>train_list = annotations_list[:split_index]<br>val_list = annotations_list[split_index:]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_data</span>(<span class="hljs-params">file_list, folder, name</span>):<br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> tqdm(file_list, name, ncols=<span class="hljs-number">100</span>):<br>        <span class="hljs-keyword">if</span> file_name.endswith(<span class="hljs-string">&#x27;.xml&#x27;</span>):<br>            xml_file = os.path.join(annotations_file, file_name)<br>            txt_file = os.path.join(folder, os.path.splitext(file_name)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.txt&#x27;</span>)<br>            convert_xml_to_txt(xml_file, txt_file)<br><br>process_data(train_list, train_folder, <span class="hljs-string">&#x27;train&#x27;</span>)<br>process_data(val_list, val_folder, <span class="hljs-string">&#x27;validation&#x27;</span>)<br></code></pre></td></tr></table></figure><p>参数表为：</p><table><thead><tr class="header"><th>参数</th><th>意义</th></tr></thead><tbody><tr class="odd"><td>train_scale</td><td>训练集的比例</td></tr></tbody></table><p>运行 run.py：<code>python run.py --train_scale 0.8</code></p><p>Data / YOLOv5 文件夹下将产生两个文件夹 train 和val，分别包含了训练集的 txt 标签文件和验证集的 txt 标签文件。</p><h2 id="文件结构">3.4 文件结构</h2><ul><li>Data<ul><li>Annotations</li><li>JPEGImages</li><li>YOLOv5<ul><li>images<ul><li>train</li><li>val</li></ul></li><li>labels<ul><li>train</li><li>val</li></ul></li><li>run.py</li></ul></li></ul></li></ul><p>在查询标签文件时，<strong>会自动将 images 替换为labels</strong>，因此 images、labels、train、val这几个文件夹的名字一定要和上面一样。</p><p>参考：<ahref="https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data">https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data</a></p><h1 id="配置文件">4 配置文件</h1><p>为了方便，我们把所有配置文件放在一个文件夹下。</p><h2 id="数据集配置">4.1 数据集配置</h2><p>在 yolov5（项目文件夹）下创建一个 config 目录，在 config 目录下创建data.yaml：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 训练和验证图片文件夹</span><br><span class="hljs-attr">train:</span> <span class="hljs-string">../Data/YOLOv5/images/train</span><br><span class="hljs-attr">val:</span> <span class="hljs-string">../Data/YOLOv5/images/val</span><br><span class="hljs-comment"># 类别数</span><br><span class="hljs-attr">nc:</span> <span class="hljs-number">2</span><br><span class="hljs-comment"># 类名</span><br><span class="hljs-attr">names:</span> [ <span class="hljs-string">&#x27;xx&#x27;</span>, <span class="hljs-string">&#x27;wcq&#x27;</span> ]<br></code></pre></td></tr></table></figure><p><strong>注意：相对路径是以 train.py 为起始</strong></p><h2 id="网络结构配置">4.2 网络结构配置</h2><p>将 yolov5中的 yolov5s.yaml 复制到 config 文件夹下，并修改yolov5s.yaml 中的：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">nc:</span> <span class="hljs-number">2</span>  <span class="hljs-comment"># 类别数</span><br></code></pre></td></tr></table></figure><p>yolov5s.yaml 的内容为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># parameters</span><br><span class="hljs-attr">nc:</span> <span class="hljs-number">2</span>  <span class="hljs-comment"># number of classes</span><br><span class="hljs-attr">depth_multiple:</span> <span class="hljs-number">0.33</span>  <span class="hljs-comment"># model depth multiple</span><br><span class="hljs-attr">width_multiple:</span> <span class="hljs-number">0.50</span>  <span class="hljs-comment"># layer channel multiple</span><br><br><span class="hljs-comment"># anchors</span><br><span class="hljs-attr">anchors:</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">10</span>,<span class="hljs-number">13</span>, <span class="hljs-number">16</span>,<span class="hljs-number">30</span>, <span class="hljs-number">33</span>,<span class="hljs-number">23</span>]  <span class="hljs-comment"># P3/8</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">30</span>,<span class="hljs-number">61</span>, <span class="hljs-number">62</span>,<span class="hljs-number">45</span>, <span class="hljs-number">59</span>,<span class="hljs-number">119</span>]  <span class="hljs-comment"># P4/16</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">116</span>,<span class="hljs-number">90</span>, <span class="hljs-number">156</span>,<span class="hljs-number">198</span>, <span class="hljs-number">373</span>,<span class="hljs-number">326</span>]  <span class="hljs-comment"># P5/32</span><br><br><span class="hljs-comment"># YOLOv5 backbone</span><br><span class="hljs-attr">backbone:</span><br>  <span class="hljs-comment"># [from, number, module, args]</span><br>  [[<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Focus</span>, [<span class="hljs-number">64</span>, <span class="hljs-number">3</span>]],  <span class="hljs-comment"># 0-P1/2</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">128</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 1-P2/4</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 3-P3/8</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">9</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">256</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 5-P4/16</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">9</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 7-P5/32</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">SPP</span>, [<span class="hljs-number">1024</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">9</span>, <span class="hljs-number">13</span>]]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">1024</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 9</span><br>  ]<br><br><span class="hljs-comment"># YOLOv5 head</span><br><span class="hljs-attr">head:</span><br>  [[<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">nn.Upsample</span>, [<span class="hljs-string">None</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;nearest&#x27;</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat backbone P4</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 13</span><br><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">nn.Upsample</span>, [<span class="hljs-string">None</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;nearest&#x27;</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">4</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat backbone P3</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">256</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 17 (P3/8-small)</span><br><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">14</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat head P4</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 20 (P4/16-medium)</span><br><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">10</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat head P5</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">1024</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 23 (P5/32-large)</span><br><br>   [[<span class="hljs-number">17</span>, <span class="hljs-number">20</span>, <span class="hljs-number">23</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Detect</span>, [<span class="hljs-string">nc</span>, <span class="hljs-string">anchors</span>]],  <span class="hljs-comment"># Detect(P3, P4, P5)</span><br>  ]<br></code></pre></td></tr></table></figure><h2 id="超参数配置">4.3 超参数配置</h2><p>将 yolov5/data/hyp.scratch.yaml 复制到 config 文件夹中：</p><p>hyp.scratch.yaml （从头开始训练）的内容为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Hyperparameters for COCO training from scratch</span><br><span class="hljs-comment"># python train.py --batch 40 --cfg yolov5m.yaml --weights &#x27;&#x27; --data coco.yaml --img 640 --epochs 300</span><br><br><span class="hljs-attr">lr0:</span> <span class="hljs-number">0.01</span>  <span class="hljs-comment"># initial learning rate (SGD=1E-2, Adam=1E-3)</span><br><span class="hljs-attr">lrf:</span> <span class="hljs-number">0.2</span>  <span class="hljs-comment"># final OneCycleLR learning rate (lr0 * lrf)</span><br><span class="hljs-attr">momentum:</span> <span class="hljs-number">0.937</span>  <span class="hljs-comment"># SGD momentum/Adam beta1</span><br><span class="hljs-attr">weight_decay:</span> <span class="hljs-number">0.0005</span>  <span class="hljs-comment"># optimizer weight decay 5e-4</span><br><span class="hljs-attr">warmup_epochs:</span> <span class="hljs-number">3.0</span>  <span class="hljs-comment"># warmup epochs (fractions ok)</span><br><span class="hljs-attr">warmup_momentum:</span> <span class="hljs-number">0.8</span>  <span class="hljs-comment"># warmup initial momentum</span><br><span class="hljs-attr">warmup_bias_lr:</span> <span class="hljs-number">0.1</span>  <span class="hljs-comment"># warmup initial bias lr</span><br><span class="hljs-attr">box:</span> <span class="hljs-number">0.05</span>  <span class="hljs-comment"># box loss gain</span><br><span class="hljs-attr">cls:</span> <span class="hljs-number">0.5</span>  <span class="hljs-comment"># cls loss gain</span><br><span class="hljs-attr">cls_pw:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># cls BCELoss positive_weight</span><br><span class="hljs-attr">obj:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># obj loss gain (scale with pixels)</span><br><span class="hljs-attr">obj_pw:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># obj BCELoss positive_weight</span><br><span class="hljs-attr">iou_t:</span> <span class="hljs-number">0.20</span>  <span class="hljs-comment"># IoU training threshold</span><br><span class="hljs-attr">anchor_t:</span> <span class="hljs-number">4.0</span>  <span class="hljs-comment"># anchor-multiple threshold</span><br><span class="hljs-comment"># anchors: 3  # anchors per output layer (0 to ignore)</span><br><span class="hljs-attr">fl_gamma:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># focal loss gamma (efficientDet default gamma=1.5)</span><br><span class="hljs-attr">hsv_h:</span> <span class="hljs-number">0.015</span>  <span class="hljs-comment"># image HSV-Hue augmentation (fraction)</span><br><span class="hljs-attr">hsv_s:</span> <span class="hljs-number">0.7</span>  <span class="hljs-comment"># image HSV-Saturation augmentation (fraction)</span><br><span class="hljs-attr">hsv_v:</span> <span class="hljs-number">0.4</span>  <span class="hljs-comment"># image HSV-Value augmentation (fraction)</span><br><span class="hljs-attr">degrees:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># image rotation (+/- deg)</span><br><span class="hljs-attr">translate:</span> <span class="hljs-number">0.1</span>  <span class="hljs-comment"># image translation (+/- fraction)</span><br><span class="hljs-attr">scale:</span> <span class="hljs-number">0.5</span>  <span class="hljs-comment"># image scale (+/- gain)</span><br><span class="hljs-attr">shear:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># image shear (+/- deg)</span><br><span class="hljs-attr">perspective:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># image perspective (+/- fraction), range 0-0.001</span><br><span class="hljs-attr">flipud:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># image flip up-down (probability)</span><br><span class="hljs-attr">fliplr:</span> <span class="hljs-number">0.5</span>  <span class="hljs-comment"># image flip left-right (probability)</span><br><span class="hljs-attr">mosaic:</span> <span class="hljs-number">1.0</span>  <span class="hljs-comment"># image mosaic (probability)</span><br><span class="hljs-attr">mixup:</span> <span class="hljs-number">0.0</span>  <span class="hljs-comment"># image mixup (probability)</span><br></code></pre></td></tr></table></figure><p>将 yolov5/data/hyp.finetune.yaml 复制到 config 文件夹中：</p><p>hyp.finetune.yaml（从预训练模型开始训练）的内容为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># Hyperparameters for VOC finetuning</span><br><span class="hljs-comment"># python train.py --batch 64 --weights yolov5m.pt --data voc.yaml --img 512 --epochs 50</span><br><br><span class="hljs-comment"># Hyperparameter Evolution Results</span><br><span class="hljs-comment"># Generations: 306</span><br><span class="hljs-comment">#                   P         R     mAP.5 mAP.5:.95       box       obj       cls</span><br><span class="hljs-comment"># Metrics:        0.6     0.936     0.896     0.684    0.0115   0.00805   0.00146</span><br><br><span class="hljs-attr">lr0:</span> <span class="hljs-number">0.0032</span><br><span class="hljs-attr">lrf:</span> <span class="hljs-number">0.12</span><br><span class="hljs-attr">momentum:</span> <span class="hljs-number">0.843</span><br><span class="hljs-attr">weight_decay:</span> <span class="hljs-number">0.00036</span><br><span class="hljs-attr">warmup_epochs:</span> <span class="hljs-number">2.0</span><br><span class="hljs-attr">warmup_momentum:</span> <span class="hljs-number">0.5</span><br><span class="hljs-attr">warmup_bias_lr:</span> <span class="hljs-number">0.05</span><br><span class="hljs-attr">box:</span> <span class="hljs-number">0.0296</span><br><span class="hljs-attr">cls:</span> <span class="hljs-number">0.243</span><br><span class="hljs-attr">cls_pw:</span> <span class="hljs-number">0.631</span><br><span class="hljs-attr">obj:</span> <span class="hljs-number">0.301</span><br><span class="hljs-attr">obj_pw:</span> <span class="hljs-number">0.911</span><br><span class="hljs-attr">iou_t:</span> <span class="hljs-number">0.2</span><br><span class="hljs-attr">anchor_t:</span> <span class="hljs-number">2.91</span><br><span class="hljs-comment"># anchors: 3.63</span><br><span class="hljs-attr">fl_gamma:</span> <span class="hljs-number">0.0</span><br><span class="hljs-attr">hsv_h:</span> <span class="hljs-number">0.0138</span><br><span class="hljs-attr">hsv_s:</span> <span class="hljs-number">0.664</span><br><span class="hljs-attr">hsv_v:</span> <span class="hljs-number">0.464</span><br><span class="hljs-attr">degrees:</span> <span class="hljs-number">0.373</span><br><span class="hljs-attr">translate:</span> <span class="hljs-number">0.245</span><br><span class="hljs-attr">scale:</span> <span class="hljs-number">0.898</span><br><span class="hljs-attr">shear:</span> <span class="hljs-number">0.602</span><br><span class="hljs-attr">perspective:</span> <span class="hljs-number">0.0</span><br><span class="hljs-attr">flipud:</span> <span class="hljs-number">0.00856</span><br><span class="hljs-attr">fliplr:</span> <span class="hljs-number">0.5</span><br><span class="hljs-attr">mosaic:</span> <span class="hljs-number">1.0</span><br><span class="hljs-attr">mixup:</span> <span class="hljs-number">0.243</span><br></code></pre></td></tr></table></figure><h2 id="文件结构-1">4.4 文件结构</h2><ul><li>config：配置文件夹<ul><li>data.yaml：数据集配置</li><li>yolov5s.yaml：网络结构配置</li><li>hyp.scratch.yaml：超参数配置（从零开始训练）</li><li>hyp.finetune.yaml：超参数配置（从预训练模型开始训练）</li></ul></li></ul><h1 id="训练">5 训练</h1><h2 id="参数表">5.1 参数表</h2><table><thead><tr class="header"><th style="text-align: left;">参数</th><th style="text-align: left;">意义</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">weights</td><td style="text-align: left;">预训练权重</td></tr><tr class="even"><td style="text-align: left;">cfg</td><td style="text-align: left;">模型配置文件</td></tr><tr class="odd"><td style="text-align: left;">data</td><td style="text-align: left;">数据集配置文件</td></tr><tr class="even"><td style="text-align: left;">hyp</td><td style="text-align: left;">超参数配置文件</td></tr><tr class="odd"><td style="text-align: left;">epochs</td><td style="text-align: left;">训练世代</td></tr><tr class="even"><td style="text-align: left;">batch-size</td><td style="text-align: left;">批量大小</td></tr><tr class="odd"><td style="text-align: left;">device</td><td style="text-align: left;">设备</td></tr></tbody></table><h2 id="开始训练">5.2 开始训练</h2><p><code>python .\train.py --weights weights/yolov5s.pt --cfg models/yolov5s.yaml --data data/voc.yaml</code></p><h2 id="可能出现的-error-1">5.3 可能出现的 Error</h2><p><strong>Error</strong>：<code>AttributeError: module 'numpy' has no attribute 'int'</code></p><p><strong>Solution</strong>：</p><p>在 utils\datasets.py 413 行， 将 np.int 改为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">bi = np.floor(np.arange(n) / batch_size).astype(<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># batch index</span><br></code></pre></td></tr></table></figure><p>在 utils\datasets.py 441 行， 将 np.int 改为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(<span class="hljs-built_in">int</span>) * stride<br></code></pre></td></tr></table></figure><p>在 utils\general.py 222 行， 将 np.int 改为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">classes = labels[:, <span class="hljs-number">0</span>].astype(<span class="hljs-built_in">int</span>)  <span class="hljs-comment"># labels = [class xywh]</span><br></code></pre></td></tr></table></figure><p><strong>Error</strong>：<code>RuntimeError: result type Float can't be cast to the desired output type __int64</code></p><p><strong>Solution</strong>：</p><p>在 utils\loss.py 212 行，将 gain 强制转为 int，即</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">indices.append((b, a, gj.clamp_(<span class="hljs-number">0</span>, <span class="hljs-built_in">int</span>(gain[<span class="hljs-number">3</span>]) - <span class="hljs-number">1</span>), gi.clamp_(<span class="hljs-number">0</span>, <span class="hljs-built_in">int</span>(gain[<span class="hljs-number">2</span>]) - <span class="hljs-number">1</span>)))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>项目</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv5 目标检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLOv1 网络复现</title>
    <link href="/2023/05/16/yolov1/"/>
    <url>/2023/05/16/yolov1/</url>
    
    <content type="html"><![CDATA[<p>YOLOv1 网络复现</p><span id="more"></span><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">leaky_reLu</span>(<span class="hljs-params">x, negative_slope=<span class="hljs-number">0.01</span></span>):<br>    <span class="hljs-keyword">return</span> torch.where(x &gt;= <span class="hljs-number">0</span>, x, negative_slope * x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚层">全局平均汇聚层</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="加载-resnet34-预训练模型">加载 resnet34 预训练模型</h1><p>原论文是采用自己设计的20层卷积层先在ImageNet上训练了一周，完成特征提取部分的训练。这里我用ResNet34 预训练模型替代。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> tvmodel<br>resnet = tvmodel.resnet34(pretrained=<span class="hljs-literal">True</span>)<br>resnet_out_channel = resnet.fc.in_features<br>resnet = nn.Sequential(*<span class="hljs-built_in">list</span>(resnet.children())[:-<span class="hljs-number">2</span>])<br>GL_CLASSES = [<span class="hljs-string">&#x27;person&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;cow&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;sheep&#x27;</span>,<br>           <span class="hljs-string">&#x27;aeroplane&#x27;</span>, <span class="hljs-string">&#x27;bicycle&#x27;</span>, <span class="hljs-string">&#x27;boat&#x27;</span>, <span class="hljs-string">&#x27;bus&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;motorbike&#x27;</span>, <span class="hljs-string">&#x27;train&#x27;</span>,<br>           <span class="hljs-string">&#x27;bottle&#x27;</span>, <span class="hljs-string">&#x27;chair&#x27;</span>, <span class="hljs-string">&#x27;diningtable&#x27;</span>, <span class="hljs-string">&#x27;pottedplant&#x27;</span>, <span class="hljs-string">&#x27;sofa&#x27;</span>, <span class="hljs-string">&#x27;tvmonitor&#x27;</span>]<br>GL_NUMBBOX = <span class="hljs-number">2</span><br>GL_NUMGRID = <span class="hljs-number">7</span><br></code></pre></td></tr></table></figure><h1 id="构建-yolov1-网络">构建 YOLOv1 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">YOLOv1Net</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    <span class="hljs-string">&quot;&quot;&quot;卷积层&quot;&quot;&quot;</span><br>    W_1 = normal((<span class="hljs-number">1024</span>, resnet_out_channel, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_1 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    W_2 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_2 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    W_3 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_3 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    W_4 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_4 = torch.zeros(<span class="hljs-number">1024</span>, device=device)<br>    convs = [W_1, b_1, W_2, b_2, W_3, b_3, W_4, b_4]<br>    W_1 = normal((GL_NUMGRID * GL_NUMGRID * <span class="hljs-number">1024</span>, <span class="hljs-number">4096</span>)); b_1 = torch.zeros(<span class="hljs-number">4096</span>, device=device)<br>    W_2 = normal((<span class="hljs-number">4096</span>, GL_NUMGRID * GL_NUMGRID * (<span class="hljs-number">5</span> * GL_NUMBBOX + <span class="hljs-built_in">len</span>(GL_CLASSES)))); <br>    b_2 = torch.zeros(GL_NUMGRID * GL_NUMGRID * (<span class="hljs-number">5</span> * GL_NUMBBOX + <span class="hljs-built_in">len</span>(GL_CLASSES)), device=device)<br>    linears = [W_1, b_1, W_2, b_2]<br>    self.params = [convs, linears]; self.flt_params = []<br>    <span class="hljs-keyword">for</span> params <span class="hljs-keyword">in</span> [convs, linears]:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            self.flt_params.append(param)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)     <br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    convs, linears = self.params<br>    X = resnet(X)<br>    W_1, b_1, W_2, b_2, W_3, b_3, W_4, b_4 = convs<br>    X = relu(conv2d(X, W_1, b_1, padding=<span class="hljs-number">1</span>))<br>    X = relu(conv2d(X, W_2, b_2, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br>    X = relu(conv2d(X, W_3, b_3, padding=<span class="hljs-number">1</span>))<br>    X = relu(conv2d(X, W_4, b_4, padding=<span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    W_1, b_1, W_2, b_2 = linears<br>    X = relu(X @ W_1 + b_1)<br>    X = sigmoid(X @ W_2 + b_2)<br>    Y = X.reshape(-<span class="hljs-number">1</span>, (<span class="hljs-number">5</span> * GL_NUMBBOX + <span class="hljs-built_in">len</span>(GL_CLASSES)), GL_NUMGRID, GL_NUMGRID)<br>    <span class="hljs-keyword">return</span> Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="误差函数">误差函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, pred, labels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        pred: (batchsize, 30, 7, 7) 的网络输出数据</span><br><span class="hljs-string">        labels: (batchsize, 30, 7, 7) 的样本标签数据</span><br><span class="hljs-string">        return: 当前批次样本的平均损失</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        num_gridx, num_gridy = labels.size()[-<span class="hljs-number">2</span>:]  <br>        num_b = <span class="hljs-number">2</span>  <span class="hljs-comment"># 每个网格的 bbox 数量</span><br>        num_cls = <span class="hljs-number">20</span>  <span class="hljs-comment"># 类别数量</span><br>        noobj_confi_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 不含目标的网格损失(只有置信度损失)</span><br>        coor_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 含有目标的bbox的坐标损失</span><br>        obj_confi_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 含有目标的bbox的置信度损失</span><br>        class_loss = <span class="hljs-number">0.</span>  <span class="hljs-comment"># 含有目标的网格的类别损失</span><br>        n_batch = labels.size()[<span class="hljs-number">0</span>]  <span class="hljs-comment"># batchsize的大小</span><br>        <br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_iou</span>(<span class="hljs-params">bbox1, bbox2</span>):<br>            <span class="hljs-string">&quot;&quot;&quot;计算 bbox1 = (x1, y1, x2, y2) 和 bbox2 = (x3, y3, x4, y4) 两个 bbox 的 iou&quot;&quot;&quot;</span><br>            x1, y1, x2, y2 = bbox1<br>            x3, y3, x4, y4 = bbox2<br>            intersect_width = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">min</span>(x2, x4) - <span class="hljs-built_in">max</span>(x1, x3))<br>            intersect_height = <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">min</span>(y2, y4) - <span class="hljs-built_in">max</span>(y1, y3))<br>            intersection_area = intersect_width * intersect_height<br>            area1 = (x2 - x1) * (y2 - y1)<br>            area2 = (x4 - x3) * (y4 - y3)<br>            iou = intersection_area / (area1 + area2 - intersection_area) <span class="hljs-keyword">if</span> intersection_area &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            <span class="hljs-keyword">return</span> iou<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_batch): <br>            <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>):<br>                <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>):<br>                    <span class="hljs-keyword">if</span> labels[i, <span class="hljs-number">4</span>, m, n] == <span class="hljs-number">1</span>: <span class="hljs-comment"># 如果包含物体</span><br>                        bbox1_pred_xyxy = ((pred[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx - pred[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy - pred[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx + pred[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy + pred[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>)<br>                        bbox2_pred_xyxy = ((pred[i, <span class="hljs-number">5</span>, m, n] + n) / num_gridx - pred[i, <span class="hljs-number">7</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">6</span>, m, n] + m) / num_gridy - pred[i, <span class="hljs-number">8</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">5</span>, m, n] + n) / num_gridx + pred[i, <span class="hljs-number">7</span>, m, n] / <span class="hljs-number">2</span>,<br>                                           (pred[i, <span class="hljs-number">6</span>, m, n] + m) / num_gridy + pred[i, <span class="hljs-number">8</span>, m, n] / <span class="hljs-number">2</span>)<br>                        bbox_gt_xyxy = ((labels[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx - labels[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                        (labels[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy - labels[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>,<br>                                        (labels[i, <span class="hljs-number">0</span>, m, n] + n) / num_gridx + labels[i, <span class="hljs-number">2</span>, m, n] / <span class="hljs-number">2</span>,<br>                                        (labels[i, <span class="hljs-number">1</span>, m, n] + m) / num_gridy + labels[i, <span class="hljs-number">3</span>, m, n] / <span class="hljs-number">2</span>)<br>                        iou1 = calculate_iou(bbox1_pred_xyxy, bbox_gt_xyxy)<br>                        iou2 = calculate_iou(bbox2_pred_xyxy, bbox_gt_xyxy)<br>                        coor_loss += <span class="hljs-number">5</span> * (torch.<span class="hljs-built_in">sum</span>((pred[i, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], m, n] - labels[i, [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], m, n]) ** <span class="hljs-number">2</span>)<br>                                          + torch.<span class="hljs-built_in">sum</span>((pred[i, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], m, n].sqrt() - <br>                                                       labels[i, [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], m, n].sqrt()) ** <span class="hljs-number">2</span>))<br>                        obj_confi_loss += (pred[i, <span class="hljs-number">4</span>, m, n] - iou1) ** <span class="hljs-number">2</span> \<br>                                        <span class="hljs-keyword">if</span> iou1 &gt;= iou2 <span class="hljs-keyword">else</span> (pred[i, <span class="hljs-number">9</span>, m, n] - iou2) ** <span class="hljs-number">2</span><br>                        noobj_confi_loss += <span class="hljs-number">0.5</span> * ((pred[i, <span class="hljs-number">9</span>, m, n] - iou2) ** <span class="hljs-number">2</span> \<br>                                        <span class="hljs-keyword">if</span> iou1 &gt;= iou2 <span class="hljs-keyword">else</span> (pred[i, <span class="hljs-number">4</span>, m, n] - iou1) ** <span class="hljs-number">2</span>)<br>                        class_loss += torch.<span class="hljs-built_in">sum</span>((pred[i, <span class="hljs-number">10</span>:, m, n] - labels[i, <span class="hljs-number">10</span>:, m, n]) ** <span class="hljs-number">2</span>)<br>                    <span class="hljs-keyword">else</span>:<br>                        noobj_confi_loss += <span class="hljs-number">0.5</span> * torch.<span class="hljs-built_in">sum</span>(pred[i, [<span class="hljs-number">4</span>, <span class="hljs-number">9</span>], m, n] ** <span class="hljs-number">2</span>)<br>        loss = coor_loss + obj_confi_loss + noobj_confi_loss + class_loss<br>        <span class="hljs-keyword">return</span> loss / n_batch<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="加载数据">加载数据</h1><h2 id="数据生成器">数据生成器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dataset_dir, seed=<span class="hljs-literal">None</span>, mode=<span class="hljs-string">&quot;train&quot;</span>, train_val_ratio=<span class="hljs-number">0.9</span>, trans=<span class="hljs-literal">None</span></span>):<br>        random.seed(seed)<br>        self.dataset_dir = dataset_dir<br>        self.mode = mode<br>        img_list_txt = os.path.join(dataset_dir, mode.replace(<span class="hljs-string">&quot;val&quot;</span>, <span class="hljs-string">&quot;train&quot;</span>) + <span class="hljs-string">&quot;.txt&quot;</span>)<br>        label_csv = os.path.join(dataset_dir, mode.replace(<span class="hljs-string">&quot;val&quot;</span>, <span class="hljs-string">&quot;train&quot;</span>) + <span class="hljs-string">&quot;.csv&quot;</span>)<br>        self.img_list = <span class="hljs-built_in">open</span>(img_list_txt).read().splitlines()<br>        self.label = np.loadtxt(label_csv, dtype=np.float32)<br>        self.num_all_data = <span class="hljs-built_in">len</span>(self.img_list)<br>        all_ids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(self.num_all_data))<br>        num_train = <span class="hljs-built_in">int</span>(train_val_ratio * self.num_all_data)<br>        self.use_ids = all_ids[:num_train] <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&quot;train&quot;</span> <span class="hljs-keyword">else</span> all_ids[num_train:]<br>        self.trans = trans<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.use_ids)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-built_in">id</span> = self.use_ids[item]<br>        label = torch.tensor(self.label[<span class="hljs-built_in">id</span>, :])<br>        img_path = self.img_list[<span class="hljs-built_in">id</span>]<br>        img = Image.<span class="hljs-built_in">open</span>(img_path)<br>        <span class="hljs-keyword">if</span> self.trans <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            trans = transforms.Compose([transforms.ToTensor(),])<br>        <span class="hljs-keyword">else</span>:<br>            trans = self.trans<br>        img = trans(img)<br>        <span class="hljs-keyword">return</span> img, label<br></code></pre></td></tr></table></figure><h2 id="生成数据">生成数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">epoch, batch_size, lr, num_epochs = <span class="hljs-number">50</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span><br>dataset_dir = <span class="hljs-string">&quot;../DataSet/VOCdevkit/VOC2012/voc2012_forYolov1/&quot;</span><br>dataset = MyDataset(dataset_dir)<br>train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">net = YOLOv1Net()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> i, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):<br>        y = y.view(batch_size, GL_NUMGRID, GL_NUMGRID, -<span class="hljs-number">1</span>)<br>        y = y.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l * batch_size; metrics[<span class="hljs-number">1</span>] += batch_size<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;i %d loss %f&#x27;</span> % (i + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">weight_path = <span class="hljs-string">&#x27;../YOLOv1/weights/net.pkl&#x27;</span><br>torch.save(net, weight_path)<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><h2 id="非极大值抑制nms">非极大值抑制（NMS）</h2><h3 id="单类别-nms">单类别 NMS</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">nms_1cls</span>(<span class="hljs-params">dets, thresh</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    单类别NMS</span><br><span class="hljs-string">    dets: ndarray, nx5, dets[i, 0:4] 分别是 bbox 坐标；dets[i, 4] 是置信度 score</span><br><span class="hljs-string">    thresh: NMS 算法设置的 iou 阈值</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    x1, y1, x2, y2, scores = dets[:, <span class="hljs-number">0</span>], dets[:, <span class="hljs-number">1</span>], dets[:, <span class="hljs-number">2</span>], dets[:, <span class="hljs-number">3</span>], dets[:, <span class="hljs-number">4</span>]<br>    areas = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)<br>    order = scores.argsort()[::-<span class="hljs-number">1</span>]<br>    keep = []<br><br>    <span class="hljs-keyword">while</span> order.size &gt; <span class="hljs-number">0</span>:<br>        i = order[<span class="hljs-number">0</span>]<br>        keep.append(i)<br>        xx1 = np.maximum(x1[i], x1[order[<span class="hljs-number">1</span>:]])<br>        yy1 = np.maximum(y1[i], y1[order[<span class="hljs-number">1</span>:]])<br>        xx2 = np.minimum(x2[i], x2[order[<span class="hljs-number">1</span>:]])<br>        yy2 = np.minimum(y2[i], y2[order[<span class="hljs-number">1</span>:]])<br><br>        w = np.maximum(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)<br>        h = np.maximum(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)<br>        inter = w * h<br>        iou = inter / (areas[i] + areas[order[<span class="hljs-number">1</span>:]] - inter)<br><br>        inds = np.where(iou &lt;= thresh)[<span class="hljs-number">0</span>]<br>        order = order[inds + <span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> keep<br></code></pre></td></tr></table></figure><h3 id="多类别极大值抑制">多类别极大值抑制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">nms_multi_cls</span>(<span class="hljs-params">dets, thresh, n_cls</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    多类别的NMS算法</span><br><span class="hljs-string">    dets: ndarray, nx6, dets[i, 0:4] 是 bbox 坐标；dets[i, 4] 是置信度 score；dets[i, 5] 是类别序号；</span><br><span class="hljs-string">    thresh: NMS 算法的阈值；</span><br><span class="hljs-string">    n_cls: 是类别总数</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    keeps_index = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_cls):<br>        order_i = np.where(dets[:, <span class="hljs-number">5</span>] == i)[<span class="hljs-number">0</span>]<br>        det = dets[dets[:, <span class="hljs-number">5</span>] == i, <span class="hljs-number">0</span>:<span class="hljs-number">5</span>]<br>        <span class="hljs-keyword">if</span> det.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">0</span>:<br>            keeps_index.append([])<br>            <span class="hljs-keyword">continue</span><br>        keep = nms_1cls(det, thresh)<br>        keeps_index.append(order_i[keep])<br>    <span class="hljs-keyword">return</span> keeps_index<br></code></pre></td></tr></table></figure><h2 id="yolov1net-输出向量处理">YOLOv1Net 输出向量处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">labels2bbox</span>(<span class="hljs-params">matrix</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    将网络输出的 7*7*30 的数据转换为 bbox 的 (98, 25) 的格式，然后再将 NMS 处理后的结果返回</span><br><span class="hljs-string">    matrix: 注意，输入的数据中，bbox坐标的格式是 (px,py,w,h)，需要转换为 (x1,y1,x2,y2) 的格式再输入NMS</span><br><span class="hljs-string">    return: 返回NMS处理后的结果,bboxes.shape = (-1, 6), 0:4 是(x1,y1,x2,y2), 4是conf， 5是cls</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> matrix.size()[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>] != (<span class="hljs-number">7</span>,<span class="hljs-number">7</span>):<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Error: Wrong labels size: &quot;</span>, matrix.size(), <span class="hljs-string">&quot; != (7,7)&quot;</span>)<br>    matrix = matrix.numpy()<br>    bboxes = np.zeros((<span class="hljs-number">98</span>, <span class="hljs-number">6</span>))<br>    matrix = matrix.reshape(<span class="hljs-number">49</span>, -<span class="hljs-number">1</span>)<br>    bbox = matrix[:, :<span class="hljs-number">10</span>].reshape(<span class="hljs-number">98</span>, <span class="hljs-number">5</span>)<br>    r_grid = np.array(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>)))<br>    r_grid = np.repeat(r_grid, repeats=<span class="hljs-number">14</span>, axis=<span class="hljs-number">0</span>)<br>    c_grid = np.array(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>)))<br>    c_grid = np.repeat(c_grid, repeats=<span class="hljs-number">2</span>, axis=<span class="hljs-number">0</span>)[np.newaxis, :]<br>    c_grid = np.repeat(c_grid, repeats=<span class="hljs-number">7</span>, axis=<span class="hljs-number">0</span>).reshape(-<span class="hljs-number">1</span>)<br>    bboxes[:, <span class="hljs-number">0</span>] = np.maximum((bbox[:, <span class="hljs-number">0</span>] + c_grid) / <span class="hljs-number">7.0</span> - bbox[:, <span class="hljs-number">2</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">0</span>)<br>    bboxes[:, <span class="hljs-number">1</span>] = np.maximum((bbox[:, <span class="hljs-number">1</span>] + r_grid) / <span class="hljs-number">7.0</span> - bbox[:, <span class="hljs-number">3</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">0</span>)<br>    bboxes[:, <span class="hljs-number">2</span>] = np.minimum((bbox[:, <span class="hljs-number">0</span>] + c_grid) / <span class="hljs-number">7.0</span> + bbox[:, <span class="hljs-number">2</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">1</span>)<br>    bboxes[:, <span class="hljs-number">3</span>] = np.minimum((bbox[:, <span class="hljs-number">1</span>] + r_grid) / <span class="hljs-number">7.0</span> + bbox[:, <span class="hljs-number">3</span>] / <span class="hljs-number">2.0</span>, <span class="hljs-number">1</span>)<br>    bboxes[:, <span class="hljs-number">4</span>] = bbox[:, <span class="hljs-number">4</span>]<br>    cls = np.argmax(matrix[:, <span class="hljs-number">10</span>:], axis=<span class="hljs-number">1</span>)<br>    cls = np.repeat(cls, repeats=<span class="hljs-number">2</span>, axis=<span class="hljs-number">0</span>)<br>    bboxes[:, <span class="hljs-number">5</span>] = cls<br>    keepid = nms_multi_cls(bboxes, thresh=<span class="hljs-number">0.01</span>, n_cls=<span class="hljs-number">20</span>)<br>    ids = []<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> keepid:<br>        ids = ids + <span class="hljs-built_in">list</span>(x)<br>    ids = <span class="hljs-built_in">sorted</span>(ids)<br>    <span class="hljs-keyword">return</span> bboxes[ids, :]<br></code></pre></td></tr></table></figure><h2 id="绘制-bounding-box">绘制 bounding box</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">draw_bbox</span>(<span class="hljs-params">img, bbox</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    根据bbox的信息在图像上绘制 bounding box</span><br><span class="hljs-string">    :param img: 绘制bbox的图像</span><br><span class="hljs-string">    :param bbox: 是(n,6)的尺寸，0:4是(x1,y1,x2,y2), 4是conf， 5是cls</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    h, w = img.shape[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>]<br>    n = bbox.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        confidence = bbox[i, <span class="hljs-number">4</span>]<br>        <span class="hljs-keyword">if</span> confidence&lt;<span class="hljs-number">0.2</span>:<br>            <span class="hljs-keyword">continue</span><br>        p1 = (<span class="hljs-built_in">int</span>(w * bbox[i, <span class="hljs-number">0</span>]), <span class="hljs-built_in">int</span>(h * bbox[i, <span class="hljs-number">1</span>]))<br>        p2 = (<span class="hljs-built_in">int</span>(w * bbox[i, <span class="hljs-number">2</span>]), <span class="hljs-built_in">int</span>(h * bbox[i, <span class="hljs-number">3</span>]))<br>        cls_name = GL_CLASSES[<span class="hljs-built_in">int</span>(bbox[i, <span class="hljs-number">5</span>])]<br>        <span class="hljs-built_in">print</span>(cls_name, p1, p2)<br>        cv2.rectangle(img, p1, p2, COLOR[<span class="hljs-built_in">int</span>(bbox[i, <span class="hljs-number">5</span>])])<br>        cv2.putText(img, cls_name, p1, cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>))<br>        cv2.putText(img, <span class="hljs-built_in">str</span>(confidence), (p1[<span class="hljs-number">0</span>],p1[<span class="hljs-number">1</span>]-<span class="hljs-number">10</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="hljs-number">0.5</span>, (<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>))<br>    cv2.imshow(<span class="hljs-string">&quot;bbox&quot;</span>, img)<br>    cv2.waitKey(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h2 id="预测-1">预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br>COLOR = [(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">125</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">250</span>),<br>         (<span class="hljs-number">255</span>,<span class="hljs-number">125</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">125</span>,<span class="hljs-number">250</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">125</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),<br>         (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">0</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">125</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">125</span>,<span class="hljs-number">255</span>),<br>         (<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0</span>),(<span class="hljs-number">125</span>,<span class="hljs-number">255</span>,<span class="hljs-number">125</span>),(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>),(<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">100</span>),(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),]  <span class="hljs-comment"># 用来标识20个类别的bbox颜色，可自行设定</span><br>test_image_dir = <span class="hljs-string">&#x27;./Test_Images/&#x27;</span><br>img_list = os.listdir(test_image_dir)<br>trans = transforms.Compose([transforms.ToTensor(),])<br><span class="hljs-keyword">for</span> img_name <span class="hljs-keyword">in</span> img_list:<br>    img_path = os.path.join(test_image_dir, img_name)<br>    img = Image.<span class="hljs-built_in">open</span>(img_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    img = trans(img)<br>    img = torch.unsqueeze(img, dim=<span class="hljs-number">0</span>)<br>    <span class="hljs-built_in">print</span>(img_name, img.shape)<br>    preds = torch.squeeze(net(img), dim=<span class="hljs-number">0</span>).detach().cpu()<br>    preds = preds.permute(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>)<br>    bbox = labels2bbox(preds)<br>    draw_img = cv2.imread(img_path)<br>    draw_bbox(draw_img, bbox)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>计算机视觉</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLOv1、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NiN 网络复现</title>
    <link href="/2023/05/14/ninnet/"/>
    <url>/2023/05/14/ninnet/</url>
    
    <content type="html"><![CDATA[<p>NiN 网络复现</p><span id="more"></span><p><img src="https://github.com/vexentox/reproduction/blob/main/NiN/NiN%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚层">全局平均汇聚层</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="构建-nin-网络">构建 NiN 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NiNNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">nin_block</span>(<span class="hljs-params">in_channels, out_channels, kernel_size</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>        W_conv1 = normal((out_channels, in_channels, kernel_size, kernel_size))<br>        b_conv1 = torch.zeros(out_channels, device=device)<br>        W_conv2 = normal((out_channels, out_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        b_conv2 = torch.zeros(out_channels, device=device)<br>        W_conv3 = normal((out_channels, out_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        b_conv3 = torch.zeros(out_channels, device=device)<br>        <span class="hljs-keyword">return</span> [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3]<br>    nin1 = nin_block(<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>)<br>    nin2 = nin_block(<span class="hljs-number">96</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>)<br>    nin3 = nin_block(<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>)<br>    nin4 = nin_block(<span class="hljs-number">384</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>)<br>    self.params = [nin1, nin2, nin3, nin4]<br>    self.flt_params = []<br>    <span class="hljs-keyword">for</span> nin <span class="hljs-keyword">in</span> self.params:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> nin:<br>            self.flt_params.append(param)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)    <br></code></pre></td></tr></table></figure><h2 id="推理函数">推理函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    strides = [<span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]; paddings = [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>];<br>    <span class="hljs-keyword">for</span> i, nin <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.params):<br>        W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3 = nin<br>        X = relu(conv2d(X, W_conv1, b_conv1, stride=strides[i], padding=paddings[i]))<br>        X = conv2d(X, W_conv2, b_conv2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br>        X = conv2d(X, W_conv3, b_conv3, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">if</span> i &lt;= <span class="hljs-number">2</span>:<br>            X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">2</span>:<br>            X = dropout(X, <span class="hljs-number">0.5</span>)<br>    X = AdaptiveAvgPool2d(X, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    Y = sigmoid(X)<br>    <span class="hljs-keyword">return</span> Y<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="更新函数">更新函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">net = NiNNet()<br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">16</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>        i += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;i %d loss %f&#x27;</span> % (i + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br>        <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">30</span>:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>NiN、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VggNet 网络复现</title>
    <link href="/2023/05/14/vggnet/"/>
    <url>/2023/05/14/vggnet/</url>
    
    <content type="html"><![CDATA[<p>VggNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/VggNet/VggNet%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">max 池化朴素实现</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=None, padding=0):</span><br><span class="hljs-string">    batch_size, channels, height, width = input.size()</span><br><span class="hljs-string">    output_height = int((height + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output_width = int((width + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c in range(channels):</span><br><span class="hljs-string">            for i in range(output_height):</span><br><span class="hljs-string">                for j in range(output_width):</span><br><span class="hljs-string">                    avg_value = torch.max(</span><br><span class="hljs-string">                        input[b, c, i * stride:i * stride + kernel_size, j * stride:j * stride + kernel_size]</span><br><span class="hljs-string">                    )</span><br><span class="hljs-string">                    output[b, c, i, j] = avg_value</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    output = torch.nn.functional.max_pool2d(<span class="hljs-built_in">input</span>, kernel_size, stride=stride, padding=padding)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * torch.empty_like(X.bernoulli_(<span class="hljs-number">1</span> - p) / (<span class="hljs-number">1</span> - p))<br><span class="hljs-comment">#     return torch.nn.functional.dropout(X, p=p, training=True)</span><br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="构建-vggnet-网络">构建 VggNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VggNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, conv_arch</span>):<br>        self._init_params(conv_arch)<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self, conv_arch</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">vgg_block</span>(<span class="hljs-params">num_convs, in_channels, out_channels</span>):<br>        params = []<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_convs):<br>            <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>            params.append([<br>                normal((out_channels, in_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)),<br>                torch.zeros(out_channels, device=device)<br>            ])<br>            in_channels = out_channels<br>        <span class="hljs-keyword">return</span> params<br>    conv_blks = []<br>    in_channels = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> (num_convs, out_channels) <span class="hljs-keyword">in</span> conv_arch:<br>        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))<br>        in_channels = out_channels<br>    W_h1h2 = normal((out_channels * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">4096</span>)); b_h1h2 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h2h3 = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>)); b_h2h3 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h3y = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>)); b_h3y = torch.zeros(<span class="hljs-number">10</span>, device=device);<br>    linears = [W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y]<br>    params = [conv_blks, linears]<br>    self.flt_params = []<br>    <span class="hljs-keyword">for</span> vgg_blk <span class="hljs-keyword">in</span> conv_blks:<br>        <span class="hljs-keyword">for</span> W, b <span class="hljs-keyword">in</span> vgg_blk:<br>            self.flt_params.append(W)<br>            self.flt_params.append(b)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> linears:<br>        self.flt_params.append(param)<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    self.params = params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    conv_blks, [W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y] = self.params<br>    <span class="hljs-keyword">for</span> vgg_blk <span class="hljs-keyword">in</span> conv_blks:<br>        <span class="hljs-keyword">for</span> W, b <span class="hljs-keyword">in</span> vgg_blk:<br>            X = relu(conv2d(X, W, b, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>))<br>        X = max_pool2d(X, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    H1 = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>) <span class="hljs-comment"># 展平</span><br>    H2 = dropout(relu(H1 @ W_h1h2 + b_h1h2), <span class="hljs-number">0.5</span>)<br>    H3 = dropout(relu(H2 @ W_h2h3 + b_h2h3), <span class="hljs-number">0.5</span>)<br>    Y = sigmoid(H3 @ W_h3y + b_h3y)<br>    <span class="hljs-keyword">return</span> Y<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">ratio = <span class="hljs-number">4</span><br>small_conv_arch = [(pair[<span class="hljs-number">0</span>], pair[<span class="hljs-number">1</span>] // ratio) <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> conv_arch]<br>net = VggNet(small_conv_arch)<br><br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VggNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet 网络复现</title>
    <link href="/2023/05/14/alexnet/"/>
    <url>/2023/05/14/alexnet/</url>
    
    <content type="html"><![CDATA[<p>AlexNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/AlexNet/AlexNet%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">max 池化朴素实现</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=None, padding=0):</span><br><span class="hljs-string">    batch_size, channels, height, width = input.size()</span><br><span class="hljs-string">    output_height = int((height + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output_width = int((width + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c in range(channels):</span><br><span class="hljs-string">            for i in range(output_height):</span><br><span class="hljs-string">                for j in range(output_width):</span><br><span class="hljs-string">                    avg_value = torch.max(</span><br><span class="hljs-string">                        input[b, c, i * stride:i * stride + kernel_size, j * stride:j * stride + kernel_size]</span><br><span class="hljs-string">                    )</span><br><span class="hljs-string">                    output[b, c, i, j] = avg_value</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    output = torch.nn.functional.max_pool2d(<span class="hljs-built_in">input</span>, kernel_size, stride=stride, padding=padding)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * torch.empty_like(X.bernoulli_(<span class="hljs-number">1</span> - p) / (<span class="hljs-number">1</span> - p))<br><span class="hljs-comment">#     return torch.nn.functional.dropout(X, p=p, training=True)</span><br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="构建-alexnet-网络">构建 AlexNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AlexNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    W_conv1 = normal((<span class="hljs-number">96</span>, <span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">11</span>)); b_conv1 = torch.zeros(<span class="hljs-number">96</span>, device=device);<br>    W_conv2 = normal((<span class="hljs-number">256</span>, <span class="hljs-number">96</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_conv2 = torch.zeros(<span class="hljs-number">256</span>, device=device);<br>    W_conv3 = normal((<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_conv3 = torch.zeros(<span class="hljs-number">384</span>, device=device);<br>    W_conv4 = normal((<span class="hljs-number">384</span>, <span class="hljs-number">384</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_conv4 = torch.zeros(<span class="hljs-number">384</span>, device=device);<br>    W_conv5 = normal((<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_conv5 = torch.zeros(<span class="hljs-number">256</span>, device=device);<br>    <br>    W_h1h2 = normal((<span class="hljs-number">6400</span>, <span class="hljs-number">4096</span>)); b_h1h2 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h2h3 = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>)); b_h2h3 = torch.zeros(<span class="hljs-number">4096</span>, device=device);<br>    W_h3y = normal((<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>)); b_h3y = torch.zeros(<span class="hljs-number">10</span>, device=device);<br>    <br>    params = [W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_conv4, b_conv4, W_conv5, b_conv5, <br>              W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_conv1, b_conv1, W_conv2, b_conv2, W_conv3, b_conv3, W_conv4, b_conv4, W_conv5, b_conv5, \<br>        W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y = self.params<br>    <br>    C1 = max_pool2d(relu(conv2d(X, W_conv1, b_conv1, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">1</span>)), <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    C2 = max_pool2d(relu(conv2d(C1, W_conv2, b_conv2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>)), <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    C3 = relu(conv2d(C2, W_conv3, b_conv3, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>))<br>    C4 = relu(conv2d(C3, W_conv4, b_conv4, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>))<br>    C5 = max_pool2d(relu(conv2d(C4, W_conv5, b_conv5, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)), <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    H1 = C5.reshape(C5.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    H2 = dropout(relu(H1 @ W_h1h2 + b_h1h2), <span class="hljs-number">0.5</span>)<br>    H3 = dropout(relu(H2 @ W_h2h3 + b_h2h3), <span class="hljs-number">0.5</span>)<br>    Y = sigmoid(H3 @ W_h3y + b_h3y)<br>    <span class="hljs-keyword">return</span> Y<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="更新参数">更新参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params:<br>            p.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br>net = AlexNet()<br>num_epochs = <span class="hljs-number">100</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_iter):<br>        l = net.update(X, y, lr=<span class="hljs-number">1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AlexNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeNet 网络复现</title>
    <link href="/2023/05/13/lenet/"/>
    <url>/2023/05/13/lenet/</url>
    
    <content type="html"><![CDATA[<p>LeNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/LeNet/strcut.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string">卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(<span class="hljs-built_in">input</span>, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="池化">池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">ave 池化朴素实现</span><br><span class="hljs-string">def avg_pool2d(input, kernel_size, stride=None, padding=0):</span><br><span class="hljs-string">    batch_size, channels, height, width = input.size()</span><br><span class="hljs-string">    output_height = int((height + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output_width = int((width + 2 * padding - kernel_size) / stride) + 1</span><br><span class="hljs-string">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c in range(channels):</span><br><span class="hljs-string">            for i in range(output_height):</span><br><span class="hljs-string">                for j in range(output_width):</span><br><span class="hljs-string">                    avg_value = torch.mean(</span><br><span class="hljs-string">                        input[b, c, i * stride:i * stride + kernel_size, j * stride:j * stride + kernel_size]</span><br><span class="hljs-string">                    )</span><br><span class="hljs-string">                    output[b, c, i, j] = avg_value</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">avg_pool2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    output = torch.nn.functional.avg_pool2d(<span class="hljs-built_in">input</span>, kernel_size, stride=stride, padding=padding)<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><h1 id="构建-lenet-网络">构建 LeNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LeNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    W_conv1 = normal((<span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_conv1 = torch.zeros(<span class="hljs-number">6</span>, device=device);<br>    W_conv2 = normal((<span class="hljs-number">16</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_conv2 = torch.zeros(<span class="hljs-number">16</span>, device=device);<br>    W_h1h2 = normal((<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>)); b_h1h2 = torch.zeros(<span class="hljs-number">120</span>, device=device);<br>    W_h2h3 = normal((<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)); b_h2h3 = torch.zeros(<span class="hljs-number">84</span>, device=device);<br>    W_h3y = normal((<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)); b_h3y = torch.zeros(<span class="hljs-number">10</span>, device=device);<br>    <br>    params = [W_conv1,b_conv1, W_conv2, b_conv2, W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_conv1, b_conv1, W_conv2, b_conv2, W_h1h2, b_h1h2, W_h2h3, b_h2h3, W_h3y, b_h3y = self.params<br>    C1 = torch.sigmoid(conv2d(X, W_conv1, b_conv1, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>))<br>    C2 = avg_pool2d(C1, <span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    C3 = torch.sigmoid(conv2d(C2, W_conv2, b_conv2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>))<br>    C4 = avg_pool2d(C3, <span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>)<br>    H1 = C4.reshape(C4.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    H2 = torch.sigmoid(H1 @ W_h1h2 + b_h1h2)<br>    H3 = torch.sigmoid(H2 @ W_h2h3 + b_h2h3)<br>    Y = torch.sigmoid(H3 @ W_h3y + b_h3y)<br>    <span class="hljs-keyword">return</span> Y<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, device = <span class="hljs-number">16</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">28</span>)<br>net = LeNet()<br>num_epochs = <span class="hljs-number">5</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_iter, ncols=<span class="hljs-number">100</span>):<br>        l = net.update(X, y, lr=<span class="hljs-number">0.1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n].reshape((n, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LeNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Softmax 回归复现</title>
    <link href="/2023/05/13/softmax/"/>
    <url>/2023/05/13/softmax/</url>
    
    <content type="html"><![CDATA[<p>softmax 回归复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[Y = softmax(WX+b)\]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><h1 id="构建-softmax-网络">构建 softmax 网络</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SoftMax</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_inputs, num_outputs</span>):<br>        self.num_inputs, self.num_outputs = num_inputs, num_outputs<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    num_inputs = self.num_inputs; num_outputs = self.num_outputs<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    W = normal((num_inputs, num_outputs)); b = torch.zeros(num_outputs, device=device)<br>    params = [W, b]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="softmax">softmax</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">self, X</span>):<br>    X_exp = torch.exp(X)<br>    partition = X_exp.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> X_exp / partition  <span class="hljs-comment"># 这里应用了广播机制</span><br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, inputs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    outputs = []<br>    W, b = self.params<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        Y = self.softmax(X.reshape((-<span class="hljs-number">1</span>, W.shape[<span class="hljs-number">0</span>])) @ W + b)<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, device = <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">28</span>)<br>num_epochs, num_inputs, num_outputs = <span class="hljs-number">3</span>, <span class="hljs-number">784</span>, <span class="hljs-number">10</span><br>net = SoftMax(num_inputs, num_outputs)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_iter, ncols=<span class="hljs-number">100</span>):<br>        l = net.update(X, y, lr=<span class="hljs-number">1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">6</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n].reshape((n, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>softmax 回归、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归网络复现</title>
    <link href="/2023/05/13/linear/"/>
    <url>/2023/05/13/linear/</url>
    
    <content type="html"><![CDATA[<p>线性回归网络复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[ Y = XW + b \]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure><h1 id="构建线性回归网络">构建线性回归网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_inputs, num_outputs</span>):<br>        self.num_inputs, self.num_outputs = num_inputs, num_outputs<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    num_inputs = self.num_inputs; num_outputs = self.num_outputs<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    W = normal((num_inputs, num_outputs)); b = torch.zeros(num_outputs, device=device)<br>    params = [W, b]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, inputs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    outputs = []<br>    W, b = self.params<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        Y = X @ W + b<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y.T.reshape(-<span class="hljs-number">1</span>))<br>    l.<span class="hljs-built_in">sum</span>().backward()<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="均方损失">均方损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;均方损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="hljs-number">2</span> / <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h1 id="生成测试数据">生成测试数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">synthetic_data</span>(<span class="hljs-params">w, b, num_examples</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;生成y=Xw+b+噪声&quot;&quot;&quot;</span><br>    X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (num_examples, <span class="hljs-built_in">len</span>(w)))<br>    y = torch.matmul(X, w) + b<br>    y += torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, y.shape)<br>    <span class="hljs-keyword">return</span> X, y.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br><br>true_w = torch.tensor([<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>])<br>true_b = <span class="hljs-number">4.2</span><br>features, labels = synthetic_data(true_w, true_b, <span class="hljs-number">1000</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_iter</span>(<span class="hljs-params">batch_size, features, labels</span>):<br>    num_examples = <span class="hljs-built_in">len</span>(features)<br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_examples))<br>    <span class="hljs-comment"># 这些样本是随机读取的，没有特定的顺序</span><br>    random.shuffle(indices)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_examples, batch_size):<br>        batch_indices = torch.tensor(<br>            indices[i: <span class="hljs-built_in">min</span>(i + batch_size, num_examples)])<br>        <span class="hljs-keyword">yield</span> features[batch_indices], labels[batch_indices]<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, device = <span class="hljs-number">32</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>num_epochs, num_inputs, num_outputs = <span class="hljs-number">10</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span><br>net = MLP(num_inputs, num_outputs)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels):<br>        l = net.update(X, y, lr=<span class="hljs-number">1</span>)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="结果">结果</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">W, b = net.params<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;w的估计误差: <span class="hljs-subst">&#123;true_w - W.reshape(true_w.shape)&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;b的估计误差: <span class="hljs-subst">&#123;true_b - b&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>线性回归、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LSTM 网络复现</title>
    <link href="/2023/05/12/lstm/"/>
    <url>/2023/05/12/lstm/</url>
    
    <content type="html"><![CDATA[<p>LSTM 网络复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[ I_{t} = \sigma(X_{t}W_{xi} +H_{t-1}W_{hi} + b_{i}) \]</span></p><p><span class="math display">\[ F_{t} = \sigma(X_{t}W_{xf} +H_{t-1}W_{hf} + b_{f}) \]</span></p><p><span class="math display">\[ O_{t} = \sigma(X_{t}W_{xo} +H_{t-1}W_{ho} + b_{o}) \]</span></p><p><span class="math display">\[ \hat{C}_{t} = tanh(X_{t}W_{xc} +H_{t-1}W_{hc} + b_{c}) \]</span></p><p><span class="math display">\[ C_{t} = F_{t} \odot C_{t-1} + I_{t}\odot \hat{C}_{t} \]</span></p><p><span class="math display">\[ H_{t} = O_{t} \odot tanh(C_{t})\]</span></p><p><span class="math display">\[ Y_{t} = H_{t}W_{hq} + b_{q}\]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><h1 id="构建-lstm-网络">构建 LSTM 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LSTM</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = self.init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>(<span class="hljs-params">self</span>):<br>    num_inputs = num_outputs = self.vocab_size; num_hiddens = self.num_hiddens<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">three</span>():<br>        <span class="hljs-keyword">return</span> (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device))<br>    W_xi, W_hi, b_i = three(); W_xf, W_hf, b_f = three(); W_xo, W_ho, b_o = three(); W_xc, W_hc, b_c = three();<br>    W_hq, b_q = normal((num_hiddens, num_outputs)), torch.zeros(num_outputs, device=device)<br>    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="初始化隐藏状态">初始化隐藏状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, batch_size</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, self.num_hiddens), device=device), torch.zeros((batch_size, self.num_hiddens), device=device))<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, state</span>):<br>    C, H = state; outputs = []<br>    W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q = self.params<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        I = torch.sigmoid(X @ W_xi + H @ W_hi + b_i)<br>        F = torch.sigmoid(X @ W_xf + H @ W_hf + b_f)<br>        O = torch.sigmoid(X @ W_xo + H @ W_ho + b_o)<br>        C_hat = torch.tanh(X @ W_xc + H @ W_hc + b_c)<br>        C = F * C + I * C_hat<br>        H = O * torch.tanh(C)<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (C, H)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>    inputs = F.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>    <span class="hljs-keyword">return</span> self.forward(inputs, state)<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params:<br>            p.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="数据分割">数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot;</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure><h1 id="迭代器">迭代器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;错误：未知词元类型：&#x27;</span> + token)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_vocab</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;词元索引列表和词表&quot;&quot;&quot;</span><br>    lines = texts<br>    tokens = d2l.tokenize(lines)<br>    vocab = d2l.Vocab(tokens)<br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>: <br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = load_corpus_vocab(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, num_steps, device = <span class="hljs-number">32</span>, <span class="hljs-number">35</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br><span class="hljs-comment"># train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br>texts = [<span class="hljs-string">&#x27;I love cat&#x27;</span>] * <span class="hljs-number">1000</span><br>train_iter, vocab = load_data(batch_size, num_steps, max_tokens=<span class="hljs-number">10000</span>)<br>num_epochs, num_hiddens = <span class="hljs-number">100</span>, <span class="hljs-number">256</span><br>net = LSTM(<span class="hljs-built_in">len</span>(vocab), num_hiddens)<br>loss = torch.nn.CrossEntropyLoss()<br>updater = torch.optim.SGD(net.params, lr=<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    state = <span class="hljs-literal">None</span>; metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            state = net.init_state(batch_size)<br>        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state: s.detach_()<br>        y_hat, state = net(X, state)<br>        y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>        l = loss(y_hat, y)<br>        l.backward()<br>        net.grad_clipping(<span class="hljs-number">1</span>)<br>        updater.step()<br>        metrics[<span class="hljs-number">0</span>] += l * y.numel(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % (num_epochs // <span class="hljs-number">10</span>) == <span class="hljs-number">0</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d 困惑度 %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, torch.exp(metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>])))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">prefix, num_preds</span>):<br>    state = net.init_state(<span class="hljs-number">1</span>)<br>    outputs = [vocab[prefix[<span class="hljs-number">0</span>]]]<br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor(outputs[-<span class="hljs-number">1</span>]).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:<br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):<br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br><br>predict(<span class="hljs-string">&#x27;I love&#x27;</span>.split(<span class="hljs-string">&#x27; &#x27;</span>), <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LSTM、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GoogLeNet 网络复现</title>
    <link href="/2023/05/12/googlenet/"/>
    <url>/2023/05/12/googlenet/</url>
    
    <content type="html"><![CDATA[<p>GoogLeNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/GoogLeNet/inception.png?raw=true"></p><p><img src="https://github.com/vexentox/reproduction/blob/main/GoogLeNet/GoogLeNet%E6%9E%B6%E6%9E%84.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="池化">池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚">全局平均汇聚</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="构建-googlenet-网络">构建 GoogLeNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GoogLeNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Inception</span>(<span class="hljs-params">in_channels, c1, c2, c3, c4</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>        W_1 = normal((c1, in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_1 = torch.zeros(c1, device=device)<br>        W_21 = normal((c2[<span class="hljs-number">0</span>], in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_21 = torch.zeros(c2[<span class="hljs-number">0</span>], device=device)<br>        W_22 = normal((c2[<span class="hljs-number">1</span>], c2[<span class="hljs-number">0</span>], <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_22 = torch.zeros(c2[<span class="hljs-number">1</span>], device=device)<br>        W_31 = normal((c3[<span class="hljs-number">0</span>], in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_31 = torch.zeros(c3[<span class="hljs-number">0</span>], device=device)<br>        W_32 = normal((c3[<span class="hljs-number">1</span>], c3[<span class="hljs-number">0</span>], <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)); b_32 = torch.zeros(c3[<span class="hljs-number">1</span>], device=device)<br>        W_4 = normal((c4, in_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_4 = torch.zeros(c4, device=device)<br>        <span class="hljs-keyword">return</span> [W_1, b_1, W_21, b_21, W_22, b_22, W_31, b_31, W_32, b_32, W_4, b_4]<br>    W_1 = normal((<span class="hljs-number">64</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>)); b_1 = torch.zeros(<span class="hljs-number">64</span>, device=device)<br>    W_21 = normal((<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_21 = torch.zeros(<span class="hljs-number">64</span>, device=device)<br>    W_22 = normal((<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>)); b_22 = torch.zeros(<span class="hljs-number">192</span>, device=device)<br>    inc1 = Inception(<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>), <span class="hljs-number">32</span>)<br>    inc2 = Inception(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">192</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">96</span>), <span class="hljs-number">64</span>)<br>    W_3 = [inc1, inc2]<br>    inc1 = Inception(<span class="hljs-number">480</span>, <span class="hljs-number">192</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">208</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">48</span>), <span class="hljs-number">64</span>)<br>    inc2 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">160</span>, (<span class="hljs-number">112</span>, <span class="hljs-number">224</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>)<br>    inc3 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>)<br>    inc4 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">112</span>, (<span class="hljs-number">144</span>, <span class="hljs-number">288</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>)<br>    inc5 = Inception(<span class="hljs-number">528</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>)<br>    W_4 = [inc1, inc2, inc3, inc4, inc5]<br>    inc1 = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>)<br>    inc2 = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">384</span>, (<span class="hljs-number">192</span>, <span class="hljs-number">384</span>), (<span class="hljs-number">48</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>)<br>    W_5 = [inc1, inc2]<br>    W_6 = normal((<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>)); b_6 = torch.zeros(<span class="hljs-number">10</span>, device=device)<br>    self.params = [W_1, b_1, W_21, b_21, W_22, b_22, W_3, W_4, W_5, W_6, b_6]<br>    self.flt_params = [W_1, b_1, W_21, b_21, W_22, b_22]<br>    <span class="hljs-keyword">for</span> W <span class="hljs-keyword">in</span> [W_3, W_4, W_5]:<br>        <span class="hljs-keyword">for</span> inc <span class="hljs-keyword">in</span> W:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> inc:<br>                self.flt_params.append(param)<br>    self.flt_params.extend([W_6, b_6])<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)     <br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_1, b_1, W_21, b_21, W_22, b_22, W_3, W_4, W_5, W_6, b_6 = self.params<br>    X = relu(conv2d(X, W_1, b_1, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>))<br>    X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    X = relu(conv2d(X, W_21, b_21))<br>    X = relu(conv2d(X, W_22, b_22, padding=<span class="hljs-number">1</span>))<br>    X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Inception</span>(<span class="hljs-params">X, inc</span>):<br>        [W_1, b_1, W_21, b_21, W_22, b_22, W_31, b_31, W_32, b_32, W_4, b_4] = inc<br>        p1 = relu(conv2d(X, W_1, b_1))<br>        p2 = relu(conv2d(X, W_21, b_21))<br>        p2 = relu(conv2d(p2, W_22, b_22, padding=<span class="hljs-number">1</span>))<br>        p3 = relu(conv2d(X, W_31, b_31))<br>        p3 = relu(conv2d(p3, W_32, b_32, padding=<span class="hljs-number">2</span>))<br>        p4 = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        p4 = relu(conv2d(p4, W_4, b_4))<br>        <span class="hljs-keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> W <span class="hljs-keyword">in</span> [W_3, W_4]:<br>        <span class="hljs-keyword">for</span> inc <span class="hljs-keyword">in</span> W:<br>            X = Inception(X, inc)<br>        X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> inc <span class="hljs-keyword">in</span> W_5:<br>        X = Inception(X, inc)<br>    X = AdaptiveAvgPool2d(X, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    X = X @ W_6 + b_6<br>    Y = sigmoid(X)<br>    <span class="hljs-keyword">return</span> Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度剪裁">梯度剪裁</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">net = GoogLeNet()<br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">16</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>        i += <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;i %d loss %f&#x27;</span> % (i + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br>        <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">30</span>:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GoogLeNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GRU 网络复现</title>
    <link href="/2023/05/12/gru/"/>
    <url>/2023/05/12/gru/</url>
    
    <content type="html"><![CDATA[<p>GRU 网络复现</p><span id="more"></span><h1 id="推理公式">推理公式</h1><p><span class="math display">\[ R_{t} = \sigma(X_{t}W_{xr} +H_{t-1}W_{hr} + b_{r}) \]</span></p><p><span class="math display">\[ Z_{t} = \sigma(X_{t}W_{xz} +H_{t-1}W_{hz} + b_{z}) \]</span></p><p><span class="math display">\[ \hat{H}_{t} = tanh(X_{t}W_{xh}+(R_{t}\odot H_{t-1})W_{hh} + b_{h}) \]</span></p><p><span class="math display">\[ H_{t} = Z_{t} \odot H_{t-1} + (1 -Z_{t}) \odot \hat{H}_{t} \]</span></p><p><span class="math display">\[ Y_{t} = H_{t}W_{hq} +b_{q}\]</span></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure><h1 id="构建-gru-网络">构建 GRU 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GRU</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens, get_params, init_state, forward_fn</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = self.init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>(<span class="hljs-params">self</span>):<br>    num_inputs = num_outputs = self.vocab_size<br>    num_hiddens = self.num_hiddens<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">three</span>():<br>        <span class="hljs-keyword">return</span> (normal((num_inputs, num_hiddens)), <br>                normal((num_hiddens, num_hiddens)), <br>                torch.zeros(num_hiddens, device=device))<br>    W_xr, W_hr, b_r = three()<br>    W_xz, W_hz, b_z = three()<br>    W_xh, W_hh, b_h = three()<br>    W_hq = normal((num_hiddens, num_outputs)); b_q = torch.zeros(num_outputs, device=device)<br>    params = [W_xr, W_hr, b_r, W_xz, W_hz, b_z, W_xh, W_hh, b_h, W_hq, b_q]<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="初始化隐藏状态">初始化隐藏状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, batch_size</span>):<br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, self.num_hiddens), device=device),)<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, state</span>):<br>    W_xr, W_hr, b_r, W_xz, W_hz, b_z, W_xh, W_hh, b_h, W_hq, b_q = self.params<br>    outputs = []; H, = state<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        R = torch.sigmoid(X @ W_xr + H @ W_hr + b_r)<br>        Z = torch.sigmoid(X @ W_xz + H @ W_hz + b_z)<br>        H_hat = torch.tanh(X @ W_xh + (R * H) @ W_hh + b_h)<br>        H = Z * H + (<span class="hljs-number">1</span> - Z) * H_hat<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H, )<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>    inputs = F.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>    <span class="hljs-keyword">return</span> self.forward(inputs, state)<br></code></pre></td></tr></table></figure><h2 id="梯度剪裁">梯度剪裁</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(param.grad ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.params:<br>            param.grad[:] *= theta / norm      <br></code></pre></td></tr></table></figure><h1 id="数据分割">数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot;</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure><h1 id="迭代器">迭代器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;错误：未知词元类型：&#x27;</span> + token)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_vocab</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;词元索引列表和词表&quot;&quot;&quot;</span><br>    lines = texts<br>    tokens = d2l.tokenize(lines)<br>    vocab = d2l.Vocab(tokens)<br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>: <br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = load_corpus_vocab(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, train_iter, lr, num_epochs</span>):<br>    loss = nn.CrossEntropyLoss()<br>    updater = torch.optim.SGD(net.params, lr)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_epochs), ncols=<span class="hljs-number">100</span>):<br>        state = <span class="hljs-literal">None</span><br>        metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>            <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                state = net.init_state(X.shape[<span class="hljs-number">0</span>])<br>            <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state: s.detach_()<br>            y_hat, state = net(X, state)<br>            y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>            l = loss(y_hat, y.long()).mean()<br>            l.backward()<br>            net.grad_clipping(<span class="hljs-number">1</span>)<br>            updater.step()<br>            metrics[<span class="hljs-number">0</span>] += l * y.numel(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>        l = torch.exp(metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;困惑度 %f&#x27;</span> % l)<br><br>batch_size, num_steps = <span class="hljs-number">32</span>, <span class="hljs-number">35</span><br><span class="hljs-comment"># train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)</span><br>texts = [<span class="hljs-string">&#x27;I love cat&#x27;</span>] * <span class="hljs-number">1000</span><br>train_iter, vocab = load_data(batch_size, num_steps, max_tokens=<span class="hljs-number">10000</span>)<br>vocab_size, num_hiddens, device = <span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>num_epochs, lr = <span class="hljs-number">10</span>, <span class="hljs-number">1</span><br>net = GRU(vocab_size, num_hiddens, get_params, init_gru_state, gru)<br>train(net, train_iter, lr, num_epochs)<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">prefix, num_preds, net, vocab</span>):<br>    state = net.init_state(<span class="hljs-number">1</span>); outputs = [vocab[prefix[<span class="hljs-number">0</span>]]]<br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor([outputs[-<span class="hljs-number">1</span>]], device=device).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:<br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):<br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br><br>predict(<span class="hljs-string">&#x27;I love&#x27;</span>.split(<span class="hljs-string">&#x27; &#x27;</span>), <span class="hljs-number">1</span>, net, vocab)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GRU、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ResNet 网络复现</title>
    <link href="/2023/05/12/resnet/"/>
    <url>/2023/05/12/resnet/</url>
    
    <content type="html"><![CDATA[<p>ResNet 网络复现</p><span id="more"></span><h1 id="架构">架构</h1><p><img src="https://github.com/vexentox/reproduction/blob/main/ResNet/%E6%AE%8B%E5%B7%AE%E5%9D%97.png?raw=true"></p><p><img src="https://github.com/vexentox/reproduction/blob/main/ResNet/ResNet%E6%9E%B6%E6%9E%84%20-%20%E5%89%AF%E6%9C%AC.png?raw=true"></p><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure><h1 id="卷积">卷积</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot; </span><br><span class="hljs-string"># 卷积朴素实现</span><br><span class="hljs-string">def conv2d(input, weight, bias=None, stride=1, padding=0):</span><br><span class="hljs-string">    batch_size, in_channels, in_height, in_width = input.size()</span><br><span class="hljs-string">    out_channels, _, kernel_height, kernel_width = weight.size()</span><br><span class="hljs-string">    out_height = int((in_height + 2 * padding - kernel_height) / stride) + 1</span><br><span class="hljs-string">    out_width = int((in_width + 2 * padding - kernel_width) / stride) + 1</span><br><span class="hljs-string">    padded_input = torch.nn.functional.pad(input, (padding, padding, padding, padding))</span><br><span class="hljs-string">    output = torch.zeros(batch_size, out_channels, out_height, out_width)</span><br><span class="hljs-string">    for b in range(batch_size):</span><br><span class="hljs-string">        for c_out in range(out_channels):</span><br><span class="hljs-string">            for h_out in range(out_height):</span><br><span class="hljs-string">                for w_out in range(out_width):</span><br><span class="hljs-string">                    h_start = h_out * stride</span><br><span class="hljs-string">                    w_start = w_out * stride</span><br><span class="hljs-string">                    h_end = h_start + kernel_height</span><br><span class="hljs-string">                    w_end = w_start + kernel_width</span><br><span class="hljs-string">                    input_patch = padded_input[b, :, h_start:h_end, w_start:w_end]</span><br><span class="hljs-string">                    output[b, c_out, h_out, w_out] = torch.sum(input_patch * weight[c_out]) + (bias[c_out] if bias is not None else 0)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv2d</span>(<span class="hljs-params">inputs, weight, bias=<span class="hljs-literal">None</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span></span>):<br>    padded_input = torch.nn.functional.pad(inputs, (padding, padding, padding, padding))<br>    output = torch.nn.functional.conv2d(padded_input, weight, bias=bias, stride=stride)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="max-池化">max 池化</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># max 池化朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">max_pool2d</span>(<span class="hljs-params">inputs, kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span></span>):<br>    batch_size, channels, height, width = inputs.size()<br>    output_height = <span class="hljs-built_in">int</span>((height + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    output_width = <span class="hljs-built_in">int</span>((width + <span class="hljs-number">2</span> * padding - kernel_size) / stride) + <span class="hljs-number">1</span><br>    unfolded = torch.nn.functional.unfold(<br>        inputs,<br>        kernel_size=kernel_size,<br>        dilation=<span class="hljs-number">1</span>,<br>        padding=padding,<br>        stride=stride<br>    )<br>    unfolded = unfolded.view(batch_size, channels, -<span class="hljs-number">1</span>, output_height, output_width)<br>    output, _ = torch.<span class="hljs-built_in">max</span>(unfolded, dim=<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def max_pool2d(input, kernel_size, stride=1, padding=0):</span><br><span class="hljs-string">    output = torch.nn.functional.max_pool2d(input, kernel_size, stride=stride, padding=padding)</span><br><span class="hljs-string">    return output</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="dropout">dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout</span>(<span class="hljs-params">X, p</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;dropout&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> X * (torch.rand_like(X) &gt; p).<span class="hljs-built_in">float</span>() / (<span class="hljs-number">1</span> - p)<br></code></pre></td></tr></table></figure><h1 id="relu">relu</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(torch.zeros_like(x), x)<br></code></pre></td></tr></table></figure><h1 id="sigmoid">sigmoid</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + torch.exp(-x))<br></code></pre></td></tr></table></figure><h1 id="全局平均汇聚层">全局平均汇聚层</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># &quot;&quot;&quot;</span><br><span class="hljs-comment"># 全局平均汇聚层朴素实现</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">AdaptiveAvgPool2d</span>(<span class="hljs-params">x, output_size</span>):<br>    batch_size, channels, height, width = x.size()<br>    output_h, output_w = output_size<br>    stride_h = height // output_h<br>    stride_w = width // output_w<br>    output = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_h):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output_w):<br>            h_start = i * stride_h<br>            h_end = <span class="hljs-built_in">min</span>(h_start + stride_h, height)<br>            w_start = j * stride_w<br>            w_end = <span class="hljs-built_in">min</span>(w_start + stride_w, width)<br>            pool_region = x[:, :, h_start:h_end, w_start:w_end]<br>            pool_avg = torch.mean(pool_region, dim=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>            output.append(pool_avg)<br>    output = torch.stack(output, dim=<span class="hljs-number">2</span>)<br>    output = output.view(batch_size, channels, output_h, output_w)<br><br>    <span class="hljs-keyword">return</span> output<br><span class="hljs-comment"># &quot;&quot;&quot;</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">def AdaptiveAvgPool2d(x, output_size):</span><br><span class="hljs-string">    return torch.nn.AdaptiveAvgPool2d(output_size)(x)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h1 id="构建-resnet-网络">构建 ResNet 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResNet</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化参数&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.nn.init.xavier_uniform_(torch.empty(shape))<br>    <span class="hljs-string">&quot;&quot;&quot;输出通道 * 输入通道 * 卷积核边长 * 卷积核边长&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual</span>(<span class="hljs-params">input_channels, num_channels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;残差块&quot;&quot;&quot;</span><br>        W_1 = normal((num_channels, input_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_1 = torch.zeros(num_channels, device=device)<br>        W_2 = normal((num_channels, num_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_2 = torch.zeros(num_channels, device=device)<br>        <span class="hljs-keyword">return</span> [W_1, b_1, W_2, b_2]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual_use_1x1conv</span>(<span class="hljs-params">input_channels, num_channels</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;带1*1卷积核的残差块&quot;&quot;&quot;</span><br>        W_1 = normal((num_channels, input_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_1 = torch.zeros(num_channels, device=device)<br>        W_2 = normal((num_channels, num_channels, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)); b_2 = torch.zeros(num_channels, device=device)<br>        W_3 = normal((num_channels, input_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)); b_3 = torch.zeros(num_channels, device=device)<br>        <span class="hljs-keyword">return</span> [W_1, b_1, W_2, b_2, W_3, b_3]   <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">input_channels, num_channels, num_residuals, first_block=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;resnet 块&quot;&quot;&quot;</span><br>        blk = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>                blk.append(Residual_use_1x1conv(input_channels, num_channels))<br>            <span class="hljs-keyword">else</span>:<br>                blk.append(Residual(num_channels, num_channels))<br>        <span class="hljs-keyword">return</span> blk<br>    W_conv = normal((<span class="hljs-number">64</span>, <span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>)); b_conv = torch.zeros(<span class="hljs-number">64</span>, device=device)<br>    resnet_b1 = resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, first_block=<span class="hljs-literal">True</span>)<br>    resnet_b2 = resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>)<br>    resnet_b3 = resnet_block(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>)<br>    resnet_b4 = resnet_block(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">2</span>)<br>    W_linear = normal((<span class="hljs-number">512</span>, <span class="hljs-number">10</span>)); b_linear = torch.zeros(<span class="hljs-number">10</span>, device=device)<br>    self.params = [W_conv, b_conv, resnet_b1, resnet_b2, resnet_b3, resnet_b4, W_linear, b_linear]<br>    self.flt_params = [W_conv, b_conv]<br>    <span class="hljs-keyword">for</span> resnet_b <span class="hljs-keyword">in</span> [resnet_b1, resnet_b2, resnet_b3, resnet_b4]:<br>        <span class="hljs-keyword">for</span> res <span class="hljs-keyword">in</span> resnet_b:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> res:<br>                self.flt_params.append(param)<br>    self.flt_params.extend([W_linear, b_linear])<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)   <br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;推理函数&quot;&quot;&quot;</span><br>    W_conv, b_conv, resnet_b1, resnet_b2, resnet_b3, resnet_b4, W_linear, b_linear = self.params<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual</span>(<span class="hljs-params">X, params, strides=<span class="hljs-number">1</span></span>):<br>        W_1, b_1, W_2, b_2 = params<br>        Y = relu(conv2d(X, W_1, b_1, stride=strides, padding=<span class="hljs-number">1</span>))<br>        Y = conv2d(Y, W_2, b_2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        Y += X<br>        Y = relu(Y)<br>        <span class="hljs-keyword">return</span> Y<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Residual_use_1x1conv</span>(<span class="hljs-params">X, params, strides=<span class="hljs-number">1</span></span>):<br>        W_1, b_1, W_2, b_2, W_3, b_3 = params<br>        Y = relu(conv2d(X, W_1, b_1, stride=strides, padding=<span class="hljs-number">1</span>))<br>        Y = conv2d(Y, W_2, b_2, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        Y += conv2d(X, W_3, b_3, stride=strides)<br>        Y = relu(Y)<br>        <span class="hljs-keyword">return</span> Y<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">X, params, first_block=<span class="hljs-literal">False</span></span>):<br>        num_residuals = <span class="hljs-built_in">len</span>(params)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>            param = params[i]<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>                X = Residual_use_1x1conv(X, param, strides=<span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">else</span>:<br>                X = Residual(X, param)<br>        <span class="hljs-keyword">return</span> X<br>    X = relu(conv2d(X, W_conv, b_conv, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>))<br>    X = max_pool2d(X, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>    X = resnet_block(X, resnet_b1, first_block=<span class="hljs-literal">True</span>)<br>    X = resnet_block(X, resnet_b2)<br>    X = resnet_block(X, resnet_b3)<br>    X = resnet_block(X, resnet_b4)<br>    X = AdaptiveAvgPool2d(X, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>    X = X.reshape(X.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    Y = sigmoid(X @ W_linear + b_linear)<br>    <span class="hljs-keyword">return</span> Y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X</span>):<br>    <span class="hljs-keyword">return</span> self._forward(X)<br></code></pre></td></tr></table></figure><h2 id="参数更新">参数更新</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, X, y, lr</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;更新函数&quot;&quot;&quot;</span><br>    y_hat = self._forward(X)<br>    l = self._loss(y_hat, y)<br>    l.mean().backward()<br>    self.grad_clipping(<span class="hljs-number">1</span>)<br>    <span class="hljs-string">&quot;&quot;&quot;sgd&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param -= lr * param.grad / X.shape[<span class="hljs-number">0</span>]<br>            param.grad.zero_()<br>    <span class="hljs-keyword">return</span> l<br></code></pre></td></tr></table></figure><h2 id="交叉熵损失">交叉熵损失</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_loss</span>(<span class="hljs-params">self, y_hat, y</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;交叉熵损失&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br></code></pre></td></tr></table></figure><h2 id="梯度裁剪">梯度裁剪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p ** <span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.flt_params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.flt_params:<br>            param.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">net = ResNet()<br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">16</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    metrics = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        l = net.update(X, y, lr=lr)<br>        metrics[<span class="hljs-number">0</span>] += l.<span class="hljs-built_in">sum</span>(); metrics[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, metrics[<span class="hljs-number">0</span>] / metrics[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>    <span class="hljs-keyword">break</span><br>n = <span class="hljs-number">4</span><br>trues = d2l.get_fashion_mnist_labels(y)<br>preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>d2l.show_images(<br>    X[<span class="hljs-number">0</span>:n, <span class="hljs-number">0</span>, :, :], <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ResNet、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RNN 网络复现</title>
    <link href="/2023/05/12/rnn/"/>
    <url>/2023/05/12/rnn/</url>
    
    <content type="html"><![CDATA[<p>RNN 网络复现</p><span id="more"></span><h1 id="导入-torch">导入 torch</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure><h1 id="构建-rnn-网络">构建 RNN 网络</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab_size, num_hiddens</span>):<br>        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens<br>        self.params = self._init_params()<br></code></pre></td></tr></table></figure><h2 id="初始化参数">初始化参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_params</span>(<span class="hljs-params">self</span>):<br>    num_inputs = num_outputs = self.vocab_size; num_hiddens = self.num_hiddens<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normal</span>(<span class="hljs-params">shape</span>):<br>        <span class="hljs-keyword">return</span> torch.randn(size=shape, device=device) * <span class="hljs-number">0.01</span><br>    W_xh = normal((num_inputs, num_hiddens)); <br>    W_hh = normal((num_hiddens, num_hiddens))<br>    b_h = torch.zeros(num_hiddens, device=device)<br>    W_hq = normal((num_hiddens, num_outputs)); <br>    b_q = torch.zeros(num_outputs, device=device)<br>    params = [W_xh, W_hh, b_h, W_hq, b_q]<br><br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>        param.requires_grad_(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> params<br></code></pre></td></tr></table></figure><h2 id="初始化隐藏状态">初始化隐藏状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_state</span>(<span class="hljs-params">self, batch_size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;初始化隐藏状态&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> (torch.zeros((batch_size, self.num_hiddens), device=device), )<br></code></pre></td></tr></table></figure><h2 id="前向推理">前向推理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward</span>(<span class="hljs-params">self, inputs, state</span>):    <br>    W_xh, W_hh, b_h, W_hq, b_q = self.params<br>    H, = state<br>    outputs = []<br>    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> inputs:<br>        H = torch.tanh(X @ W_xh + H @ W_hh + b_h)<br>        Y = H @ W_hq + b_q<br>        outputs.append(Y)<br>    <span class="hljs-keyword">return</span> torch.cat(outputs, dim=<span class="hljs-number">0</span>), (H, )<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, X, state</span>):<br>    inputs = torch.nn.functional.one_hot(X.T, self.vocab_size).<span class="hljs-built_in">type</span>(torch.float32)<br>    <span class="hljs-keyword">return</span> self._forward(inputs, state)<br></code></pre></td></tr></table></figure><h2 id="梯度剪裁">梯度剪裁</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">grad_clipping</span>(<span class="hljs-params">self, theta</span>):<br>    norm = torch.sqrt(<span class="hljs-built_in">sum</span>([torch.<span class="hljs-built_in">sum</span>(p) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params]))<br>    <span class="hljs-keyword">if</span> norm &gt; theta:<br>        <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.params:<br>            p.grad[:] *= theta / norm<br></code></pre></td></tr></table></figure><h1 id="数据分割">数据分割</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_random</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用随机抽样生成一个小批量子序列&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1</span><br>    corpus = corpus[random.randint(<span class="hljs-number">0</span>, num_steps - <span class="hljs-number">1</span>):]<br>    <span class="hljs-comment"># 减去1，是因为我们需要考虑标签</span><br>    num_subseqs = (<span class="hljs-built_in">len</span>(corpus) - <span class="hljs-number">1</span>) // num_steps<br>    <span class="hljs-comment"># 长度为num_steps的子序列的起始索引</span><br>    initial_indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_subseqs * num_steps, num_steps))<br>    <span class="hljs-comment"># 在随机抽样的迭代过程中，</span><br>    <span class="hljs-comment"># 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻</span><br>    random.shuffle(initial_indices)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">data</span>(<span class="hljs-params">pos</span>):<br>        <span class="hljs-comment"># 返回从pos位置开始的长度为num_steps的序列</span><br>        <span class="hljs-keyword">return</span> corpus[pos: pos + num_steps]<br><br>    num_batches = num_subseqs // batch_size<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, batch_size * num_batches, batch_size):<br>        <span class="hljs-comment"># 在这里，initial_indices包含子序列的随机起始索引</span><br>        initial_indices_per_batch = initial_indices[i: i + batch_size]<br>        X = [data(j) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        Y = [data(j + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> initial_indices_per_batch]<br>        <span class="hljs-keyword">yield</span> torch.tensor(X), torch.tensor(Y)<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">seq_data_iter_sequential</span>(<span class="hljs-params">corpus, batch_size, num_steps</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用顺序分区生成一个小批量子序列&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 从随机偏移量开始划分序列</span><br>    offset = random.randint(<span class="hljs-number">0</span>, num_steps)<br>    num_tokens = ((<span class="hljs-built_in">len</span>(corpus) - offset - <span class="hljs-number">1</span>) // batch_size) * batch_size<br>    Xs = torch.tensor(corpus[offset: offset + num_tokens])<br>    Ys = torch.tensor(corpus[offset + <span class="hljs-number">1</span>: offset + <span class="hljs-number">1</span> + num_tokens])<br>    Xs, Ys = Xs.reshape(batch_size, -<span class="hljs-number">1</span>), Ys.reshape(batch_size, -<span class="hljs-number">1</span>)<br>    num_batches = Xs.shape[<span class="hljs-number">1</span>] // num_steps<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_steps * num_batches, num_steps):<br>        X = Xs[:, i: i + num_steps]<br>        Y = Ys[:, i: i + num_steps]<br>        <span class="hljs-keyword">yield</span> X, Y<br></code></pre></td></tr></table></figure><h1 id="迭代器">迭代器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">lines, token=<span class="hljs-string">&#x27;word&#x27;</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;将文本行拆分为单词或字符词元&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> token == <span class="hljs-string">&#x27;word&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [line.split() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">elif</span> token == <span class="hljs-string">&#x27;char&#x27;</span>:<br>        <span class="hljs-keyword">return</span> [<span class="hljs-built_in">list</span>(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;错误：未知词元类型：&#x27;</span> + token)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_corpus_vocab</span>(<span class="hljs-params">max_tokens=-<span class="hljs-number">1</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;词元索引列表和词表&quot;&quot;&quot;</span><br>    lines = texts<br>    tokens = d2l.tokenize(lines)<br>    vocab = d2l.Vocab(tokens)<br>    corpus = [vocab[token] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tokens <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> line]<br>    <span class="hljs-keyword">if</span> max_tokens:<br>        corpus = corpus[:max_tokens]<br>    <span class="hljs-keyword">return</span> corpus, vocab<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SeqDataLoader</span>: <br>    <span class="hljs-string">&quot;&quot;&quot;加载序列数据的迭代器&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, batch_size, num_steps, use_random_iter, max_tokens</span>):<br>        <span class="hljs-keyword">if</span> use_random_iter:<br>            self.data_iter_fn = d2l.seq_data_iter_random<br>        <span class="hljs-keyword">else</span>:<br>            self.data_iter_fn = d2l.seq_data_iter_sequential<br>        self.corpus, self.vocab = load_corpus_vocab(max_tokens)<br>        self.batch_size, self.num_steps = batch_size, num_steps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__iter__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>(<span class="hljs-params">batch_size, num_steps,  <span class="hljs-comment">#@save</span></span><br><span class="hljs-params">                           use_random_iter=<span class="hljs-literal">False</span>, max_tokens=<span class="hljs-number">10000</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;返回迭代器和词表&quot;&quot;&quot;</span><br>    data_iter = SeqDataLoader(<br>        batch_size, num_steps, use_random_iter, max_tokens)<br>    <span class="hljs-keyword">return</span> data_iter, data_iter.vocab<br></code></pre></td></tr></table></figure><h1 id="训练">训练</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size, num_steps, device = <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;cpu&#x27;</span><br>texts = [<span class="hljs-string">&#x27;I am a cat&#x27;</span>] * <span class="hljs-number">1000</span><br>train_iter, vocab = load_data(batch_size, num_steps, max_tokens=<span class="hljs-number">10000</span>)<br>num_epochs, lr = <span class="hljs-number">10</span>, <span class="hljs-number">1</span><br>net = RNN(<span class="hljs-built_in">len</span>(vocab), <span class="hljs-number">256</span>)<br>updater = torch.optim.SGD(net.params, lr)<br>loss = torch.nn.CrossEntropyLoss()<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    state = <span class="hljs-literal">None</span><br>    metric = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            state = net.init_state(batch_size=X.shape[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> state: s.detach_()<br>        y_hat, state = net(X, state)<br>        y = Y.T.reshape(-<span class="hljs-number">1</span>)<br>        l = loss(y_hat, y.long()).mean()<br>        updater.zero_grad()<br>        l.backward()<br>        net.grad_clipping(<span class="hljs-number">1</span>)<br>        updater.step()<br>        metric[<span class="hljs-number">0</span>] += l * y.numel(); metric[<span class="hljs-number">1</span>] += y.numel()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d 困惑度 %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, torch.exp(metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>])))<br></code></pre></td></tr></table></figure><h1 id="预测">预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">prefix, num_preds, net, vocab, device</span>):<br>    state = net.init_state(batch_size=<span class="hljs-number">1</span>)<br>    outputs = [vocab[prefix[<span class="hljs-number">0</span>]]]<br>    get_input = <span class="hljs-keyword">lambda</span>: torch.tensor([outputs[-<span class="hljs-number">1</span>]], device=device).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> prefix[<span class="hljs-number">1</span>:]:<br>        _, state = net(get_input(), state)<br>        outputs.append(vocab[y])<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_preds):<br>        y, state = net(get_input(), state)<br>        outputs.append(<span class="hljs-built_in">int</span>(y.argmax(dim=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>.join([vocab.idx_to_token[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> outputs])<br>predict(<span class="hljs-string">&#x27;I am a&#x27;</span>.split(<span class="hljs-string">&#x27; &#x27;</span>), <span class="hljs-number">1</span>, net, vocab, device)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文</category>
      
      <category>基础网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RNN、复现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python IO 优化</title>
    <link href="/2023/03/23/python_IO_%E4%BC%98%E5%8C%96/"/>
    <url>/2023/03/23/python_IO_%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>python IO 优化</p><span id="more"></span><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.setrecursionlimit(<span class="hljs-built_in">int</span>(<span class="hljs-number">1e7</span>))<br><span class="hljs-built_in">input</span> = sys.stdin.readline<br><span class="hljs-built_in">print</span> = sys.stdout.write<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python, IO, 优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>裁剪序列 (线段树优化Dp) From 算法进阶指南</title>
    <link href="/2023/03/23/%E7%AE%97%E6%B3%95%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97_%E8%A3%81%E5%89%AA%E5%BA%8F%E5%88%97/"/>
    <url>/2023/03/23/%E7%AE%97%E6%B3%95%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97_%E8%A3%81%E5%89%AA%E5%BA%8F%E5%88%97/</url>
    
    <content type="html"><![CDATA[<p>线段树优化dp</p><span id="more"></span><h2 id="链接">链接</h2><p><ahref="https://www.acwing.com/problem/content/description/301/">https://www.acwing.com/problem/content/description/301/</a></p><h2 id="题意">题意</h2><p><span class="math inline">\(~~~~\)</span>给定一个长度为 <spanclass="math inline">\(N\)</span> 的序列 <spanclass="math inline">\(A\)</span>，要求把该序列分成若干段，在满足每段中所有数的和不超过<span class="math inline">\(M\)</span>的前提下，让每段中所有数的最大值之和最小。<br /><span class="math inline">\(~~~~\)</span>试计算这个最小值。</p><h2 id="题解">题解</h2><p><span class="math inline">\(~~~~\)</span>考虑 <spanclass="math inline">\(DP\)</span>。<br /><span class="math inline">\(~~~~\)</span>设状态： <spanclass="math display">\[f[i]：前 i 个数中每段中所有数的最大值之和的最小值， i \in [1, n]\]</span> <span class="math inline">\(~~~~\)</span> 对于 <spanclass="math inline">\(i\)</span>，枚举它转移的上一个答案 <spanclass="math inline">\(f[j]\)</span>，更新为 <spanclass="math inline">\(i\)</span> 前面的若干个数（满足 <spanclass="math inline">\(\sum_{k=j+1}^{i} a[k] &lt;=M\)</span>）中的最大值，取最小值。<br /><span class="math inline">\(~~~~\)</span> 即状态转移方程为： <spanclass="math display">\[f[i] = \min\{f[j] + \max\{a[j+1], a[j+2], ..., a[i]\}\}, 其中j \in [1,i], \sum_{k=j+1}^{i} a[k] &lt;= M\]</span> <span class="math inline">\(~~~~\)</span> 注意到 <spanclass="math display">\[\max\{a[i]\} &lt;= \max\{a[i], a[i-1]\} &lt;= ... &lt;= \max\{a[j+1],a[j+2], ..., a[i]\}\]</span> <span class="math inline">\(~~~~\)</span> 因此对于每一个 <spanclass="math inline">\(i\)</span>，可以用单调栈找到 <spanclass="math inline">\(&gt;a[i]\)</span> 的第一个数 <spanclass="math inline">\(a[pre[i]]\)</span>，维护 <spanclass="math inline">\(i\)</span> 之前 <span class="math inline">\(\lea[i]\)</span> 的一段连续的区间 <span class="math inline">\([pre[i]+1,i]\)</span>，这段区间的最大值即为 <spanclass="math inline">\(a[i]\)</span>。<br /><span class="math inline">\(~~~~\)</span> 考虑线段树优化，对于 <spanclass="math inline">\(i\)</span>，由于 <spanclass="math inline">\(f[i]\)</span> 是固定的，因此</p><ul><li>将 <span class="math inline">\(f[i]\)</span> 赋给线段树的第 <spanclass="math inline">\(i\)</span> 位<br /></li><li>在由单调栈维护出来的区间 <span class="math inline">\([pre[i]+1,i]\)</span> 加上 <span class="math inline">\(a[i]\)</span><br /></li><li>使用二分找到满足 <span class="math inline">\(\sum_{k=j+1}^{i} a[k]&lt;= M\)</span> 的 <span class="math inline">\(j\)</span><br /></li><li><span class="math inline">\(f[i] = query(j+1, i)\)</span></li></ul><h2 id="python-代码">python 代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br>sys.setrecursionlimit(<span class="hljs-built_in">int</span>(<span class="hljs-number">1e7</span>))<br><span class="hljs-built_in">input</span> = sys.stdin.readline<br><span class="hljs-built_in">print</span> = sys.stdout.write<br>n, L = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>inf = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e18</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, l=<span class="hljs-number">0</span>, r=<span class="hljs-number">0</span>, v=inf, mn=inf, add=inf</span>):<br>        self.l, self.r, self.v, self.mn, self.add = l, r, v, mn, add<br>tr = [Node() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(<span class="hljs-number">1e5</span>)&lt;&lt;<span class="hljs-number">2</span>)]<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ls</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">return</span> u &lt;&lt; <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rs</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">return</span> u &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mid</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">return</span> tr[u].l + tr[u].r &gt;&gt; <span class="hljs-number">1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build</span>(<span class="hljs-params">u, l, r</span>):<br>    tr[u] = Node(l, r)<br>    <span class="hljs-keyword">if</span> l == r:<br>        <span class="hljs-keyword">return</span><br>    build(ls(u), l, mid(u))<br>    build(rs(u), mid(u)+<span class="hljs-number">1</span>, r)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pushup</span>(<span class="hljs-params">u</span>):<br>    tr[u].mn = <span class="hljs-built_in">min</span>(tr[ls(u)].mn, tr[rs(u)].mn)<br>    tr[u].v = <span class="hljs-built_in">min</span>(tr[ls(u)].v, tr[rs(u)].v)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pushdown</span>(<span class="hljs-params">u</span>):<br>    <span class="hljs-keyword">if</span> tr[u].add != inf:<br>        tr[ls(u)].mn = tr[ls(u)].v + tr[u].add<br>        tr[rs(u)].mn = tr[rs(u)].v + tr[u].add<br>        tr[ls(u)].add = tr[u].add<br>        tr[rs(u)].add = tr[u].add<br>        tr[u].add = inf<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">change</span>(<span class="hljs-params">u, x, v</span>):<br>    <span class="hljs-keyword">if</span> tr[u].l == tr[u].r:<br>        tr[u].mn = inf<br>        tr[u].v = v<br>        <span class="hljs-keyword">return</span><br>    pushdown(u)<br>    <span class="hljs-keyword">if</span> x &lt;= mid(u):<br>        change(ls(u), x, v)<br>    <span class="hljs-keyword">else</span>:<br>        change(rs(u), x, v)<br>    pushup(u)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">u, l, r, v</span>):<br>    <span class="hljs-keyword">if</span> l &lt;= tr[u].l <span class="hljs-keyword">and</span> tr[u].r &lt;= r:<br>        tr[u].mn = tr[u].v + v<br>        tr[u].add = v<br>        <span class="hljs-keyword">return</span><br>    pushdown(u)<br>    <span class="hljs-keyword">if</span> l &lt;= mid(u):<br>        update(ls(u), l, r, v)<br>    <span class="hljs-keyword">if</span> r &gt; mid(u):<br>        update(rs(u), l, r, v)<br>    pushup(u)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">query</span>(<span class="hljs-params">u, l, r</span>):<br>    <span class="hljs-keyword">if</span> l &lt;= tr[u].l <span class="hljs-keyword">and</span> tr[u].r &lt;= r:<br>        <span class="hljs-keyword">return</span> tr[u].mn<br>    res = inf<br>    pushdown(u)<br>    <span class="hljs-keyword">if</span> l &lt;= mid(u):<br>        res = <span class="hljs-built_in">min</span>(res, query(ls(u), l, r))<br>    <span class="hljs-keyword">if</span> r &gt; mid(u):<br>        res = <span class="hljs-built_in">min</span>(res, query(rs(u), l, r))<br>    <span class="hljs-keyword">return</span> res<br>h = [<span class="hljs-number">0</span>] + [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>sw = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>    sw[i] = sw[i-<span class="hljs-number">1</span>] + h[i]<br>stk = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>top = <span class="hljs-number">1</span><br>stk[top] = <span class="hljs-number">1</span><br>pre = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, n+<span class="hljs-number">1</span>):<br>    <span class="hljs-keyword">while</span> top &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> h[stk[top]] &lt;= h[i]:<br>        top -= <span class="hljs-number">1</span><br>    <span class="hljs-keyword">if</span> top &gt; <span class="hljs-number">0</span>:<br>        pre[i] = stk[top]<br>    top += <span class="hljs-number">1</span><br>    stk[top] = i<br>f = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_bound</span>(<span class="hljs-params">l, r, x</span>):<br>    <span class="hljs-keyword">while</span> l &lt; r:<br>        mid = l + r &gt;&gt; <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> sw[mid] &gt;= x:<br>            r = mid<br>        <span class="hljs-keyword">else</span>:<br>            l = mid + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> r<br>build(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, n)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>    change(<span class="hljs-number">1</span>, i, f[i-<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">if</span> pre[i] + <span class="hljs-number">1</span> &lt;= i:<br>        update(<span class="hljs-number">1</span>, pre[i] + <span class="hljs-number">1</span>, i, h[i])<br>    left = lower_bound(<span class="hljs-number">0</span>, i, sw[i] - L)<br>    <span class="hljs-keyword">if</span> left &lt; i:<br>        f[i] = query(<span class="hljs-number">1</span>, left+<span class="hljs-number">1</span>, i)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d\n&#x27;</span> % f[n])<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>算法进阶指南</category>
      
    </categories>
    
    
    <tags>
      
      <tag>裁剪序列, 算法进阶指南, 线段树, DP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Nebius Welcome Round (Div. 1 + Div. 2) a - D</title>
    <link href="/2023/03/20/cf_1804/"/>
    <url>/2023/03/20/cf_1804/</url>
    
    <content type="html"><![CDATA[<p>A (思维) B (贪心) C (数论) D (贪心)</p><span id="more"></span><h2 id="链接">链接</h2><p><ahref="https://codeforces.com/contest/1804">https://codeforces.com/contest/1804</a></p><h2 id="a">A</h2><h3 id="题意">题意</h3><p><span class="math inline">\(~~~~\)</span> 从 <spanclass="math inline">\((0, 0)\)</span>开始走，每次只能走上下左右四个方向，走一步，且方向和上一次不同，问走到<span class="math inline">\((a, b)\)</span> 最短步数。</p><h3 id="题解">题解</h3><p><span class="math inline">\(~~~~\)</span> 一般地，将 <spanclass="math inline">\((0, 0)\)</span> 和 <span class="math inline">\((a,b)(a &lt; b \ and \ a &gt; 0 \ and \ b &gt; 0)\)</span>视为长方形的两个顶点，则最优策略是从 <span class="math inline">\((0,0)\)</span> 走到 <span class="math inline">\((a, a)\)</span>，在从 <spanclass="math inline">\((a, a)\)</span> 走到 <spanclass="math inline">\((a, b)\)</span>。<br /><span class="math inline">\(~~~~\)</span> 则答案为 <spanclass="math inline">\(2 * (b - a) - 1\)</span></p><h3 id="python-代码">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    x, y = [<span class="hljs-built_in">abs</span>(<span class="hljs-built_in">int</span>(_)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    <span class="hljs-keyword">if</span> x &gt; y:<br>        x, y = y, x<br>    res = <span class="hljs-number">2</span> * x<br>    <span class="hljs-keyword">if</span> y &gt; x:<br>        res+=<span class="hljs-number">2</span> * (y-x)-<span class="hljs-number">1</span><br><br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><h2 id="b">B</h2><h3 id="题意-1">题意</h3><p><span class="math inline">\(~~~~\)</span> 给出一些区间 <spanclass="math inline">\([t_{i}, t_{i}+w], t_{i} \le t_{i+1},i \in [1,n]\)</span>，要求使用数量最少的个区间 <span class="math inline">\([x,x+w]\)</span>，其中 <span class="math inline">\(x\)</span>自定，使得所有的区间和 <span class="math inline">\([x, x+w]\)</span>有交集。</p><h3 id="题解-1">题解</h3><p><span class="math inline">\(~~~~\)</span> 考虑贪心。从前往后遍历<span class="math inline">\(t_{i}\)</span>，以 <spanclass="math inline">\(t_{i} + w\)</span> 作为左边界，<spanclass="math inline">\(t_{i} + w+d\)</span>作为右边界，寻找和该区间相交的区间，直到下一个区间不再与该区间相交，则另起一个新的区间。</p><h3 id="python-代码-1">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> *<br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, k, d, w = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    right = -<span class="hljs-number">1</span><br>    res = <span class="hljs-number">0</span><br>    nowk = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">if</span> a[i] &lt;= right <span class="hljs-keyword">and</span> nowk:<br>            nowk -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            res += <span class="hljs-number">1</span><br>            right = a[i] + w + d<br>            nowk = k - <span class="hljs-number">1</span><br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><h2 id="c">C</h2><h3 id="题意-2">题意</h3><p><span class="math inline">\(~~~~\)</span> 找到一个 <spanclass="math inline">\(f, f \in [1, p]\)</span>，使得 <spanclass="math inline">\((x + \frac{f * (f + 1)}{2}) \% n == 0\)</span>成立。</p><h3 id="题解-2">题解</h3><p><span class="math inline">\(~~~~\)</span> 上结论， <spanclass="math display">\[\frac{(a * n + b) * (a * n + b + 1)}{2} \ \% n = (\frac{(a * n) * (a * n+ 1)}{2} \% n + \frac{b * (b + 1)}{2} \% n) \% n\]</span> <span class="math inline">\(~~~~\)</span> 证明待补。<br /><span class="math inline">\(~~~~\)</span> 因此，<spanclass="math inline">\(f = a * n + b, b &lt; n\)</span>，枚举 <spanclass="math inline">\(a\)</span> 即可。</p><h3 id="python-代码-2">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> *<br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, x, p = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    s = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>    mp = <span class="hljs-built_in">dict</span>()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        s[i] = i*(i+<span class="hljs-number">1</span>)//<span class="hljs-number">2</span> % n<br>        <span class="hljs-keyword">if</span> mp.__contains__(s[i]):<br>            mp[s[i]] = <span class="hljs-built_in">min</span>(mp[s[i]], i)<br>        <span class="hljs-keyword">else</span>:<br>            mp.update(&#123;s[i]: i&#125;)<br>    ok = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        now = (<span class="hljs-number">2</span>*n-s[n]*a%n-x)%n<br>        <span class="hljs-keyword">if</span> mp.__contains__(now) <span class="hljs-keyword">and</span> mp[now] + a*n &lt;= p:<br>            ok = <span class="hljs-number">1</span><br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">if</span> ok:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;YES&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;NO&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="d">D</h2><h3 id="题意-3">题意</h3><p><span class="math inline">\(~~~~\)</span> 给一个 $ n m , 4|m$ 的<span class="math inline">\(01\)</span>矩阵，对于每一行，满足两个连在一起的块数量和单个块的数量都为 <spanclass="math inline">\(\frac{m}{4}\)</span>。<br /><span class="math inline">\(~~~~\)</span>要求分配两种块的位置，使得至少有一个 <spanclass="math inline">\(1\)</span> 的块的数量最少或最多。</p><h3 id="题解-3">题解</h3><p><span class="math inline">\(~~~~\)</span>显然每一行是独立的。记每一行 <span class="math inline">\(1\)</span>的数量为 $ cnt1 $。<br /><span class="math inline">\(~~~~\)</span> 对于最小值，贪心的找每一行<span class="math inline">\(11\)</span> 块数量 $ cnt11 $。</p><ul><li>如果 <span class="math inline">\(cnt11 \le\frac{m}{4}\)</span>，答案为 <span class="math inline">\(cnt1 - 2 \timescnt11 + cnt11\)</span><br /></li><li>如果 <span class="math inline">\(cnt11 &gt;\frac{m}{4}\)</span>，答案为 <span class="math inline">\(cnt1 - 2 \times\frac{m}{4} + \frac{m}{4}\)</span></li></ul><p><span class="math inline">\(~~~~\)</span>对于最大值，贪心的找每一个不是 <span class="math inline">\(11\)</span>块的数量 <span class="math inline">\(cnt11n\)</span>。</p><ul><li>如果 <span class="math inline">\(cnt11 \le \frac{m}{4}\)</span>，则<span class="math inline">\(cnt11 = \frac{m}{4} -cnt11n\)</span>，答案为 <span class="math inline">\(cnt1 - 2 \timescnt11 + cnt11\)</span><br /></li><li>如果 <span class="math inline">\(cnt11 &gt; \frac{m}{4}\)</span>，则<span class="math inline">\(cnt11 = \frac{m}{4} - cnt11n\)</span>,答案为 <span class="math inline">\(cnt1\)</span></li></ul><h3 id="python-代码-3">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">n, m = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>mn, mx = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>    s = <span class="hljs-built_in">input</span>()<br>    cnt1 = s.count(<span class="hljs-string">&#x27;1&#x27;</span>)<br>    x = <span class="hljs-number">0</span><br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i &lt; m:<br>        <span class="hljs-keyword">if</span> i + <span class="hljs-number">1</span> &lt; m <span class="hljs-keyword">and</span> s[i] == <span class="hljs-string">&#x27;1&#x27;</span> <span class="hljs-keyword">and</span> s[i+<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;1&#x27;</span>:<br>            x += <span class="hljs-number">1</span><br>            i += <span class="hljs-number">1</span><br>        i += <span class="hljs-number">1</span><br>    mn += cnt1 - <span class="hljs-built_in">min</span>(m//<span class="hljs-number">4</span>, x)<br>    x = <span class="hljs-number">0</span><br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> i &lt; m:<br>        <span class="hljs-keyword">if</span> i + <span class="hljs-number">1</span> &lt; m <span class="hljs-keyword">and</span> (s[i] == <span class="hljs-string">&#x27;0&#x27;</span> <span class="hljs-keyword">or</span> s[i] != s[i+<span class="hljs-number">1</span>]):<br>            x += <span class="hljs-number">1</span><br>            i += <span class="hljs-number">1</span><br>        i += <span class="hljs-number">1</span><br>    mx += cnt1 - <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, (m//<span class="hljs-number">4</span> - x))<br><span class="hljs-built_in">print</span>(mn, mx)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, A, B, C, D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Educational Codeforces Round 143 (Rated for Div. 2) C - D</title>
    <link href="/2023/03/15/cf_1795/"/>
    <url>/2023/03/15/cf_1795/</url>
    
    <content type="html"><![CDATA[<p>C (二分) D (组合数学) <span id="more"></span></p><h2 id="链接">链接</h2><p><ahref="https://codeforces.com/contest/1795">https://codeforces.com/contest/1795</a></p><h2 id="c-二分">C (二分)</h2><h3 id="题意">题意</h3><p><span class="math inline">\(~~~~\)</span>给两个数组 <spanclass="math inline">\(a\)</span>, <spanclass="math inline">\(b\)</span>，进行 <spanclass="math inline">\(n\)</span> 轮操作，对于第 <spanclass="math inline">\(k\)</span> 次操作，<spanclass="math inline">\(\forall i \in [1, n-k+1], a[i] -= min(b[i+k-1],a[i])\)</span>，对第 <span class="math inline">\(i+k-1\)</span>个答案产生 <span class="math inline">\(min(b[i+k-1], a[i])\)</span>的贡献。</p><p><span class="math inline">\(~~~~\)</span>求出所有的答案。</p><h3 id="题解">题解</h3><p><span class="math inline">\(~~~~\)</span>反过来考虑每个 <spanclass="math inline">\(a[i]\)</span> 的贡献，对于 <spanclass="math inline">\(b[j], j &gt;= i\)</span>，它会对第 <spanclass="math inline">\(j\)</span> 个答案产生 <spanclass="math inline">\(b[j]\)</span> 的贡献，直到 <spanclass="math inline">\(a[i] &lt;= b[i] + b[i+1] + ... + b[e]\)</span>未知，特别的， <span class="math inline">\(a[i]\)</span> 对第 <spanclass="math inline">\(e\)</span> 个答案产生的贡献为 <spanclass="math inline">\(a[i] - b[i] - b[i+1] - ... - b[e-1]\)</span>。</p><p><span class="math inline">\(~~~~\)</span>因此我们可以先求出 <spanclass="math inline">\(b\)</span> 的前缀和 <spanclass="math inline">\(sb\)</span>，要计算每个 <spanclass="math inline">\(a[i]\)</span> 的贡献，我们只需要在 <spanclass="math inline">\(j \in [i, n]\)</span> 范围二分找到 <spanclass="math inline">\(sb[n] - sb[i-1] &gt;= a[i]\)</span>的第一个数，即为 <span class="math inline">\(e\)</span>。</p><h3 id="python-代码">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_bound</span>(<span class="hljs-params">num, left, right</span>):<br>    l, r = left, right<br>    <span class="hljs-keyword">while</span> l &lt; r:<br>        mid = (l + r) // <span class="hljs-number">2</span><br>        <span class="hljs-keyword">if</span> b[mid] &gt;= num:<br>            r = mid<br>        <span class="hljs-keyword">else</span>:<br>            l = mid + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> r<br><br><br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    a = [<span class="hljs-number">0</span>] + [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    b = [<span class="hljs-number">0</span>] + [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    c = b.copy()<br>    s = <span class="hljs-built_in">sum</span>(b)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(b)):<br>        b[i] += b[i - <span class="hljs-number">1</span>]<br>    f = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n + <span class="hljs-number">2</span>)]<br>    g = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n + <span class="hljs-number">2</span>)]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">if</span> a[i] + b[i-<span class="hljs-number">1</span>] &gt;= b[n]:<br>            f[i] += <span class="hljs-number">1</span><br>            f[n+<span class="hljs-number">1</span>] -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">continue</span><br>        pos = lower_bound(a[i] + b[i-<span class="hljs-number">1</span>], i, n)<br>        <span class="hljs-keyword">if</span> i != pos:<br>            f[i] += <span class="hljs-number">1</span><br>            f[pos] -= <span class="hljs-number">1</span><br>        g[pos] += a[i] + b[i-<span class="hljs-number">1</span>] - b[pos-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        f[i] += f[i-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % (f[i] * c[i] + g[i]), end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h2 id="d-组合数学">D (组合数学)</h2><h3 id="题意-1">题意</h3><p><spanclass="math inline">\(~~~~\)</span>给出每三个点一组的完全图（三个点两两相连），一共有<span class="math inline">\(\frac{n}{3} (6|n)\)</span>组，要求对所有节点染色，一共有两种颜色（红、蓝），最终的染色方案必须满足两种颜色数量相同。</p><p><spanclass="math inline">\(~~~~\)</span>在每一组中，若两个点的颜色不同，则对答案的贡献为两个点的边权。要求计算使得答案最大的染色方案的数量。模<span class="math inline">\(998244353\)</span>。</p><h3 id="题解-1">题解</h3><p><spanclass="math inline">\(~~~~\)</span>要使答案最大，只需从每个组中选出两个最大的边权对答案产生贡献即可，因此每个组中的颜色必然满足存在两个颜色相同，不妨设三中颜色分别为<span class="math inline">\(x ~ x ~ y, (x &gt;=y)\)</span>，对于每一组，只要 <span class="math inline">\(y\)</span>确定了，则 <span class="math inline">\(x\)</span> 也就确定了。</p><p><span class="math inline">\(~~~~\)</span>因此考虑 <spanclass="math inline">\(y\)</span>，要使两种颜色数量相同，只需平均分配即可，即从<span class="math inline">\(\frac{n}{3}\)</span> 个组中选 <spanclass="math inline">\(\frac{n}{6}\)</span> 个染成红色，其他 <spanclass="math inline">\(\frac{n}{6}\)</span> 个染成蓝色。因此答案为 <spanclass="math inline">\(C(\frac{n}{3}, \frac{n}{6}) \% mod\)</span>。</p><p><span class="math inline">\(~~~~\)</span>考虑一下特殊情况：</p><ul><li>当某一组 <span class="math inline">\(y\)</span> 的数量为 <spanclass="math inline">\(2\)</span> 时，<spanclass="math inline">\(y\)</span> 的位置可以选择两个与 <spanclass="math inline">\(x\)</span> 交汇处之一，因此对答案贡献 <spanclass="math inline">\(*2\)</span><br /></li><li>当某一组 <span class="math inline">\(y\)</span> 的数量为 <spanclass="math inline">\(2\)</span> 时，<spanclass="math inline">\(y\)</span>的位置可以选择任意两个点交汇处之一，因此对答案贡献 <spanclass="math inline">\(*3\)</span></li></ul><h3 id="python-代码-1">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python">N = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e5</span>)<br>f = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N + <span class="hljs-number">5</span>)]<br>inv = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N + <span class="hljs-number">5</span>)]<br>f[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>mod = <span class="hljs-number">998244353</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, N + <span class="hljs-number">1</span>):<br>    f[i] = f[i - <span class="hljs-number">1</span>] * i % mod<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">qmi</span>(<span class="hljs-params">a, b</span>):<br>    res = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> b:<br>        <span class="hljs-keyword">if</span> b &amp; <span class="hljs-number">1</span>:<br>            res = res * a % mod<br>        a = a * a % mod<br>        b &gt;&gt;= <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br><br><br>inv[N] = qmi(f[N], mod - <span class="hljs-number">2</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N - <span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>    inv[i] = inv[i + <span class="hljs-number">1</span>] * (i + <span class="hljs-number">1</span>) % mod<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">C</span>(<span class="hljs-params">n, m</span>):<br>    <span class="hljs-keyword">if</span> m &gt; n:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> f[n] * inv[m] * inv[n - m] % mod<br><br><br>n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>res = <span class="hljs-number">1</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, n, <span class="hljs-number">3</span>):<br>    b = a[i:i + <span class="hljs-number">3</span>]<br>    res = res * b.count(<span class="hljs-built_in">min</span>(b)) % mod<br><span class="hljs-built_in">print</span>(res * C(n//<span class="hljs-number">3</span>, n//<span class="hljs-number">6</span>) % mod)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, C, D, Educational Codeforces Round 143</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codeforces Round 857 (Div. 2) C - E</title>
    <link href="/2023/03/14/cf_1802_C_E/"/>
    <url>/2023/03/14/cf_1802_C_E/</url>
    
    <content type="html"><![CDATA[<p>C (构造) D (贪心、multiset) E (树状数组优化dp)</p><span id="more"></span><h2 id="链接">链接</h2><p><ahref="https://codeforces.com/contest/1802">https://codeforces.com/contest/1802</a></p><h2 id="c-构造">C (构造)</h2><h3 id="题意">题意</h3><p><span class="math inline">\(~~~~\)</span>构造一个 <spanclass="math inline">\(n \times m\)</span> 的矩阵，使得每一个 <spanclass="math inline">\(2 \times 2\)</span> 的子矩阵满足： <spanclass="math display">\[\begin{matrix} A_{11} \oplus A_{12} \oplus A_{21} \oplusA_{22}=A_{33}\oplus A_{34} \oplus A_{43} \oplus A_{44}\\A_{13} \oplus A_{14} \oplus A_{23} \oplus A_{24}=A_{31}\oplus A_{32}\oplus A_{41} \oplus A_{42}\end{matrix}\]</span></p><h3 id="题解">题解</h3><p><spanclass="math inline">\(~~~~\)</span>通过观察样例，可以猜想每一个子矩阵的异或和是一个常数。（待证明）</p><p><spanclass="math inline">\(~~~~\)</span>因此，我们可以随机化矩阵的第一行和第一列，并设定一个常数<span class="math inline">\(C\)</span>作为每个子矩阵的异或和。对于一个子矩阵，若已知三个数的值 <spanclass="math inline">\(A_{1}, A_{2}, A_{3}\)</span>，则第四个值 <spanclass="math inline">\(A_{4}=C \oplus A_{1} \oplus A_{2} \oplusA_{3}\)</span>。</p><h3 id="python-代码">python 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>mod = (<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">63</span>) - <span class="hljs-number">1</span><br>f = [[<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>)] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>)]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>):<br>    f[i][<span class="hljs-number">0</span>] = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100000000000000012</span>)<br>    f[<span class="hljs-number">0</span>][i] = random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100000000000000012</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>):<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>):<br>        f[i][j] = mod ^ f[i - <span class="hljs-number">1</span>][j] ^ f[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] ^ f[i][j - <span class="hljs-number">1</span>]<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, m = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    <span class="hljs-built_in">print</span>(n*m)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % f[i][j], end=<span class="hljs-string">&#x27;&#x27;</span>)<br>        <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h2 id="d-贪心multiset">D (贪心、multiset)</h2><h3 id="题意-1">题意</h3><p><span class="math inline">\(~~~~\)</span>给出两个数组 <spanclass="math inline">\(a, b\)</span>，操作 <spanclass="math inline">\(n\)</span> 次，对于第 <spanclass="math inline">\(i\)</span> 次，每次只能从 <spanclass="math inline">\(a_{i}、b_{i}\)</span> 中选出一个，记从 <spanclass="math inline">\(a\)</span> 随选出的数列为 <spanclass="math inline">\(a_{choose}\)</span>，从 <spanclass="math inline">\(b\)</span> 中选出的数列为 <spanclass="math inline">\(b_{choose}\)</span>，目标是最小化 $| (a_{choose})- (b_{choose}) | $。</p><h3 id="题解-1">题解</h3><p><span class="math inline">\(~~~~\)</span>将 <spanclass="math inline">\(a, b\)</span> 一起按照 <spanclass="math inline">\(a\)</span> 从大到小排序，从前往后遍历 <spanclass="math inline">\(a\)</span>，对于 <spanclass="math inline">\(a_{i}\)</span>，将其作为从 <spanclass="math inline">\(a\)</span> 中选出的最大值。</p><p><span class="math inline">\(~~~~\)</span>由于 <spanclass="math inline">\(\forall j \in [1,i-1], a_{j} &lt;a_{i}\)</span>，因此，<span class="math inline">\(i\)</span> 前面的<span class="math inline">\(a\)</span> 一定不选，<spanclass="math inline">\(i\)</span> 前面的 <spanclass="math inline">\(b\)</span> 一定要选；<spanclass="math inline">\(i\)</span> 后面的 <spanclass="math inline">\(b\)</span> 可选可不选。</p><p><span class="math inline">\(~~~~\)</span>记 <spanclass="math inline">\(mxb = \max(b_{j}, j \in [1,i-1])\)</span>，则只需要在 <span class="math inline">\(i\)</span> 后面的 <spanclass="math inline">\(b\)</span> 中找到和 <spanclass="math inline">\(a_{i}\)</span> 最相近的且 <spanclass="math inline">\(&gt; mxb\)</span> 的数 <spanclass="math inline">\(b_{k}\)</span> 即可用 <spanclass="math inline">\(\left | a_{i} - b_{k} \right |\)</span>更新答案；如果没有找到，则用 <span class="math inline">\(\left | a_{i} -mxb \right |\)</span> 更新答案。</p><p><span class="math inline">\(~~~~\)</span>可用 <spanclass="math inline">\(muliset\)</span> 维护，<spanclass="math inline">\(lower_bound\)</span> 用于寻找最相近的数。</p><p><span class="math inline">\(~~~~\)</span>时间复杂度 <spanclass="math inline">\(O(nlogn)\)</span></p><h3 id="代码">代码</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;set&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for( i, L, R ) for ( int i = L; i &lt;= R; ++i )</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">5e5</span> + <span class="hljs-number">5</span>;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span> &#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-type">int</span> a, b;<br><span class="hljs-type">bool</span> <span class="hljs-keyword">operator</span>&lt;( <span class="hljs-type">const</span> Node &amp; o ) <span class="hljs-type">const</span><br>&#123;<br><span class="hljs-keyword">return</span>(a &gt; o.a);<br>&#125;<br>&#125; e[N];<br><span class="hljs-type">int</span> n;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">solve</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;n );<br>multiset&lt;<span class="hljs-type">int</span>&gt; s;<br>_for( i, <span class="hljs-number">1</span>, n ) <span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d%d&quot;</span>, &amp;e[i].a, &amp;e[i].b ), s.<span class="hljs-built_in">insert</span>( e[i].b );<br><span class="hljs-built_in">sort</span>( e + <span class="hljs-number">1</span>, e + n + <span class="hljs-number">1</span> );<br><span class="hljs-type">int</span> res = <span class="hljs-number">1e9</span>, mx = <span class="hljs-number">-1e9</span>;<br>_for( i, <span class="hljs-number">1</span>, n )<br>&#123;<br>s.<span class="hljs-built_in">erase</span>( s.<span class="hljs-built_in">find</span>( e[i].b ) );<br><span class="hljs-keyword">auto</span> it = s.<span class="hljs-built_in">lower_bound</span>( e[i].a );<br><span class="hljs-keyword">if</span> ( it != s.<span class="hljs-built_in">end</span>() <span class="hljs-keyword">and</span> * it &gt; mx )<br>res = <span class="hljs-built_in">min</span>( res, <span class="hljs-built_in">abs</span>( e[i].a - *it ) );<br><span class="hljs-keyword">if</span> ( it != s.<span class="hljs-built_in">begin</span>() <span class="hljs-keyword">and</span> * <span class="hljs-built_in">prev</span>( it ) &gt; mx )<br>res = <span class="hljs-built_in">min</span>( res, <span class="hljs-built_in">abs</span>( e[i].a - *<span class="hljs-built_in">prev</span>( it ) ) );<br>res= <span class="hljs-built_in">min</span>( res, <span class="hljs-built_in">abs</span>( e[i].a - mx ) );<br>mx= <span class="hljs-built_in">max</span>( e[i].b, mx );<br>&#125;<br><span class="hljs-built_in">printf</span>( <span class="hljs-string">&quot;%d\n&quot;</span>, res );<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;T );<br><span class="hljs-keyword">while</span> ( T-- )<br><span class="hljs-built_in">solve</span>();<br><span class="hljs-keyword">return</span>(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>同时可用树状数组实现 <spanclass="math inline">\(multiset\)</span><br /><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstdio&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstring&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for(i, L, R) for (int i = L; i &lt;= R; ++i)</span><br><span class="hljs-comment">// #define int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span> N = <span class="hljs-number">1e6</span> + <span class="hljs-number">5</span>;<br><span class="hljs-type">int</span> tot, sz, INF;<br><span class="hljs-type">int</span> num[N], tr[N];<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pos</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">lower_bound</span>(num + <span class="hljs-number">1</span>, num + <span class="hljs-number">1</span> + sz, x) - num;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> k)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">for</span> (x; x &lt;= sz; x += x &amp; -x)<br>tr[x] += k;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">query</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> tmp = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> (x; x; x -= x &amp; -x)<br>tmp += tr[x];<br><span class="hljs-keyword">return</span> tmp;<br>&#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">kth</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> rs = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">25</span>; i &gt;= <span class="hljs-number">0</span>; --i)<br>&#123;<br>rs += (<span class="hljs-number">1</span> &lt;&lt; i);<br><span class="hljs-keyword">if</span> (rs &gt; sz || tr[rs] &gt;= x)<br>rs -= (<span class="hljs-number">1</span> &lt;&lt; i);<br><span class="hljs-keyword">else</span><br>x -= tr[rs];<br>&#125;<br><span class="hljs-keyword">return</span> num[rs + <span class="hljs-number">1</span>];<br>&#125;<br><br><span class="hljs-type">int</span> n, a[N];<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Q</span><br>&#123;<br><span class="hljs-keyword">public</span>:<br><span class="hljs-type">int</span> a, b;<br><span class="hljs-type">bool</span> <span class="hljs-keyword">operator</span>&lt;(<span class="hljs-type">const</span> Q &amp;o) <span class="hljs-type">const</span><br>&#123;<br><span class="hljs-keyword">return</span> a &gt; o.a;<br>&#125;<br>&#125; e[N];<br><br><span class="hljs-type">int</span> mx;<br><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">check</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">return</span> x != INF <span class="hljs-keyword">and</span> x != -INF <span class="hljs-keyword">and</span> x &gt; mx;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">sovle</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;n);<br>tot = <span class="hljs-number">0</span>;<br>INF = <span class="hljs-number">0</span>;<br>_for(i, <span class="hljs-number">1</span>, n)<br>&#123;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d%d&quot;</span>, &amp;e[i].a, &amp;e[i].b), num[++tot] = e[i].a, num[++tot] = e[i].b;<br>INF = <span class="hljs-built_in">max</span>(INF, e[i].a);<br>INF = <span class="hljs-built_in">max</span>(INF, e[i].b);<br>&#125;<br>INF++;<br>num[++tot] = -INF;<br>num[++tot] = INF;<br><span class="hljs-built_in">sort</span>(num + <span class="hljs-number">1</span>, num + <span class="hljs-number">1</span> + tot);<br>sz = <span class="hljs-built_in">unique</span>(num + <span class="hljs-number">1</span>, num + <span class="hljs-number">1</span> + tot) - num - <span class="hljs-number">1</span>;<br><span class="hljs-built_in">sort</span>(e + <span class="hljs-number">1</span>, e + n + <span class="hljs-number">1</span>);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(-INF), <span class="hljs-number">1</span>);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(INF), <span class="hljs-number">1</span>);<br>_for(i, <span class="hljs-number">1</span>, n) <span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(e[i].b), <span class="hljs-number">1</span>);<br><span class="hljs-type">int</span> res = <span class="hljs-number">1e9</span>;<br>mx = <span class="hljs-number">-1e9</span>;<br>_for(i, <span class="hljs-number">1</span>, n)<br>&#123;<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(e[i].b), <span class="hljs-number">-1</span>);<br><span class="hljs-type">int</span> x = <span class="hljs-built_in">kth</span>(<span class="hljs-built_in">query</span>(<span class="hljs-built_in">pos</span>(e[i].a) - <span class="hljs-number">1</span>));<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(x))<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - e[i].a));<br>x = <span class="hljs-built_in">kth</span>(<span class="hljs-built_in">query</span>(<span class="hljs-built_in">pos</span>(x)));<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(x))<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - e[i].a));<br>x = <span class="hljs-built_in">kth</span>(<span class="hljs-built_in">query</span>(<span class="hljs-built_in">pos</span>(x)) + <span class="hljs-number">1</span>);<br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">check</span>(x))<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - e[i].a));<br>res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(e[i].a - mx));<br>mx = <span class="hljs-built_in">max</span>(e[i].b, mx);<br>&#125;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, res);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(-INF), <span class="hljs-number">-1</span>);<br><span class="hljs-built_in">add</span>(<span class="hljs-built_in">pos</span>(INF), <span class="hljs-number">-1</span>);<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%d&quot;</span>, &amp;T);<br><span class="hljs-keyword">while</span> (T--)<br><span class="hljs-built_in">sovle</span>();<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs python">N = <span class="hljs-built_in">int</span>(<span class="hljs-number">1e6</span> + <span class="hljs-number">5</span>)<br>tot = sz = INF = mx = <span class="hljs-number">0</span><br>vec = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br>tr = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br>es = [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lower_bound</span>(<span class="hljs-params">l, r, x</span>):<br>    <span class="hljs-keyword">while</span> l &lt; r:<br>        mid = (l + r) &gt;&gt; <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> num[mid] &gt;= x:<br>            r = mid<br>        <span class="hljs-keyword">else</span>:<br>            l = mid + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> r<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pos</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> lower_bound(<span class="hljs-number">1</span>, sz, x)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">x, k</span>):<br>    <span class="hljs-keyword">while</span> x &lt;= sz:<br>        tr[x] += k<br>        x += (x &amp; -x)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">query</span>(<span class="hljs-params">x</span>):<br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> x:<br>        res += tr[x]<br>        x -= (x &amp; -x)<br>    <span class="hljs-keyword">return</span> res<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">kth</span>(<span class="hljs-params">x</span>):<br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">25</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>        res += <span class="hljs-number">1</span> &lt;&lt; i<br>        <span class="hljs-keyword">if</span> res &gt; sz <span class="hljs-keyword">or</span> tr[res] &gt;= x:<br>            res -= <span class="hljs-number">1</span> &lt;&lt; i<br>        <span class="hljs-keyword">else</span>:<br>            x -= tr[res]<br>    <span class="hljs-keyword">return</span> num[res + <span class="hljs-number">1</span>]<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> x != INF <span class="hljs-keyword">and</span> x != -INF <span class="hljs-keyword">and</span> x &gt; mx<br><br><br>T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    tot = INF = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>        a, b = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>        es[i] = [a, b]<br>        tot += <span class="hljs-number">1</span><br>        vec[tot] = es[i][<span class="hljs-number">0</span>]<br>        tot += <span class="hljs-number">1</span><br>        vec[tot] = es[i][<span class="hljs-number">1</span>]<br>        INF = <span class="hljs-built_in">max</span>(INF, <span class="hljs-built_in">max</span>(es[i]))<br>    INF += <span class="hljs-number">1</span><br>    tot += <span class="hljs-number">1</span><br>    vec[tot] = -INF<br>    tot += <span class="hljs-number">1</span><br>    vec[tot] = INF<br>    num = [<span class="hljs-number">0</span>] + <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(vec[<span class="hljs-number">1</span>: tot+<span class="hljs-number">1</span>])))<br>    sz = <span class="hljs-built_in">len</span>(num) - <span class="hljs-number">1</span><br>    e = <span class="hljs-built_in">sorted</span>(es[:n], key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">0</span>], reverse=<span class="hljs-literal">True</span>)<br>    add(pos(-INF), <span class="hljs-number">1</span>)<br>    add(pos(INF), <span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> e:<br>        add(pos(b), <span class="hljs-number">1</span>)<br>    res, mx = <span class="hljs-number">1e9</span>, -<span class="hljs-number">1e9</span><br>    <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> e:<br>        add(pos(b), -<span class="hljs-number">1</span>)<br>        x = kth(query(pos(a) - <span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">if</span> check(x):<br>            res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - a))<br>        x = kth(query(pos(a)))<br>        <span class="hljs-keyword">if</span> check(x):<br>            res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - a))<br>        x = kth(query(pos(a)) + <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> check(x):<br>            res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(x - a))<br>        res = <span class="hljs-built_in">min</span>(res, <span class="hljs-built_in">abs</span>(mx - a))<br>        mx = <span class="hljs-built_in">max</span>(b, mx)<br>    <span class="hljs-built_in">print</span>(res)<br>    add(pos(-INF), -<span class="hljs-number">1</span>)<br>    add(pos(INF), -<span class="hljs-number">1</span>)<br><br></code></pre></td></tr></table></figure><h2 id="e-树状数组优化dp">E (树状数组优化dp)</h2><h3 id="题意-2">题意</h3><p><span class="math inline">\(~~~~\)</span>给出 <spanclass="math inline">\(n\)</span> 个数组，每个数组有 <spanclass="math inline">\(k_{i}\)</span>个数，找到一直数组拼接方式，使得拼接后的数组 <spanclass="math inline">\(b\)</span> 中满足 <spanclass="math inline">\(\forall j \in [1, i-1], b_{i} &gt; b_{j}\)</span>（条件1）的数最多。</p><h3 id="题解-2">题解</h3><p><span class="math inline">\(~~~~\)</span>考虑dp。记 <spanclass="math display">\[f[i]：前 i 个数组拼接而成的最大答案\]</span></p><ul><li>由于一个数组中可能对答案产生贡献的只有在本数组中满足条件1的数，因此在读入时即可使数组单调递增<br /></li><li>将 <span class="math inline">\(n\)</span>个数组按照最后一个元素从小到大排序，这样在更新 <spanclass="math inline">\(f[i]\)</span>时，前面的状态一定已经被更新完了<br /></li><li>对于 <span class="math inline">\(f[i]\)</span>，其中的某一个数 <spanclass="math inline">\(a_{i, j}\)</span>，贡献来自两部分<ul><li>由于 <span class="math inline">\(\forall p \in [j+1, k_{i}], a_{i,p} &gt; a_{i, j}\)</span>，因此贡献为 <spanclass="math inline">\(k_{i}-j\)</span></li><li>对于最大值小于 <span class="math inline">\(a_{i, j}\)</span> 的数组<span class="math inline">\(a_{s}\)</span>，其贡献为 <spanclass="math inline">\(\max(f[s])\)</span></li></ul></li></ul><p><span class="math inline">\(~~~~\)</span>因此，状态转移方程为<br /><span class="math display">\[f[i] = \max(\max(f[s]) + k_{i} - j), s = \{s| \max(a_{s}) &lt; a_{i,j}\}\]</span></p><p><span class="math inline">\(~~~~\)</span>其中，<spanclass="math inline">\(\max(f[s])\)</span> 可用树状数组维护。</p><p><span class="math inline">\(~~~~\)</span>时间复杂度 <spanclass="math inline">\(O(nklogn)\)</span></p><h3 id="c-代码">c++ 代码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(1)</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(2)</span><br><span class="hljs-meta">#<span class="hljs-keyword">pragma</span> GCC optimize(3,<span class="hljs-string">&quot;Ofast&quot;</span>,<span class="hljs-string">&quot;inline&quot;</span>)</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;vector&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;cstring&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _for( i, L, R ) for ( int i = L; i &lt;= R; ++i )</span><br><br>using namespace <span class="hljs-built_in">std</span>;<br><br><span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">lowbit</span><span class="hljs-params">( <span class="hljs-type">int</span> x )</span><br>&#123;<br><span class="hljs-keyword">return</span>(x &amp; - x);<br>&#125;<br><br><br><span class="hljs-type">const</span> <span class="hljs-type">int</span>N = <span class="hljs-number">2e5</span> + <span class="hljs-number">5</span>;<br><span class="hljs-type">int</span>n, tr[N], f[N], mxv;<br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Node</span> &#123;</span><br>public:<br><span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt; v;<br><span class="hljs-type">bool</span> operator&lt;( <span class="hljs-type">const</span> Node &amp; o ) <span class="hljs-type">const</span><br>&#123;<br><span class="hljs-keyword">return</span>(v.back() &lt; o.v.back() );<br>&#125;<br>&#125; a[N];<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">modify</span><span class="hljs-params">( <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y )</span><br>&#123;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> i = x; i &lt;= mxv; i += lowbit( i ) )<br>tr[i] = max( tr[i], y );<br>&#125;<br><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">query</span><span class="hljs-params">( <span class="hljs-type">int</span> x )</span><br>&#123;<br><span class="hljs-type">int</span> res = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> i = x; i; i -= lowbit( i ) )<br>res = max( res, tr[i] );<br><span class="hljs-keyword">return</span>(res);<br>&#125;<br><br><br><span class="hljs-type">void</span> <span class="hljs-title function_">clear</span><span class="hljs-params">( <span class="hljs-type">int</span> x )</span><br>&#123;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> i = x; i &lt;= mxv; i += lowbit( i ) )<br>tr[i] = <span class="hljs-number">0</span>;<br>&#125;<br><br><br><span class="hljs-type">void</span> <span class="hljs-title function_">solve</span><span class="hljs-params">()</span><br>&#123;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;n );<br>mxv = <span class="hljs-number">0</span>;<br>_for( i, <span class="hljs-number">1</span>, n )<br>&#123;<br><span class="hljs-type">int</span> m;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;m );<br><span class="hljs-keyword">while</span> ( m-- )<br>&#123;<br><span class="hljs-type">int</span> x;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;x );<br><span class="hljs-keyword">if</span> ( a[i].v.empty() or a[i].v.back() &lt; x )<br>a[i].v.push_back( x ), mxv = max( mxv, x );<br>&#125;<br>&#125;<br>sort( a + <span class="hljs-number">1</span>, a + <span class="hljs-number">1</span> + n );<br><span class="hljs-type">int</span> res = <span class="hljs-number">0</span>;<br>_for( i, <span class="hljs-number">1</span>, n )<br>&#123;<br><span class="hljs-type">int</span> k = a[i].v.size(), cnt = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> ( <span class="hljs-type">int</span> j = k - <span class="hljs-number">1</span>; j &gt;= <span class="hljs-number">0</span>; --j )<br>&#123;<br>cnt++;<br>f[i] = max( f[i], cnt + query( a[i].v[j] - <span class="hljs-number">1</span> ) );<br>&#125;<br>modify( a[i].v.back(), f[i] );<br>res = max( res, f[i] );<br>&#125;<br>_for( i, <span class="hljs-number">1</span>, n ) clear( a[i].v.back() ), a[i].v.clear(), f[i] = <span class="hljs-number">0</span>;<br><span class="hljs-built_in">printf</span>( <span class="hljs-string">&quot;%d\n&quot;</span>, res );<br>&#125;<br><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br><span class="hljs-type">int</span> T = <span class="hljs-number">1</span>;<br><span class="hljs-built_in">scanf</span>( <span class="hljs-string">&quot;%d&quot;</span>, &amp;T );<br><span class="hljs-keyword">while</span> ( T-- )<br>solve();<br><span class="hljs-keyword">return</span>(<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, C, D, E, Maximum Subarray, dp, DP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Educational Codeforces Round 144 (Rated for Div. 2) D. Maximum Subarray (Dp)</title>
    <link href="/2023/03/12/cf_1796_D/"/>
    <url>/2023/03/12/cf_1796_D/</url>
    
    <content type="html"><![CDATA[<p>D (dp) <span id="more"></span></p><h1 id="閾炬帴">閾炬帴</h1><p><ahref="https://codeforces.com/contest/1796/problem/D">https://codeforces.com/contest/1796/problem/D</a></p><h1 id="棰樻剰">棰樻剰</h1><p><span class="math inline">\(~~~~\)</span>缁欎竴涓暟缁� <spanclass="math inline">\(a\)</span>锛岃姹傞€夊嚭 <spanclass="math inline">\(a\)</span> 鐨勪竴涓暱搴︿负 <spanclass="math inline">\(k\)</span> 鐨勫瓙搴忓垪 <spanclass="math inline">\(b_{1}, b_{2}, ..., b_{k}\)</span>锛岃 <spanclass="math inline">\(\forall i \in [1, k], b_{i} += x\)</span>锛岃€岃<span class="math inline">\(\forall a_{i} \in a \ and \ a_{i} \notin b,a_{i} -= x\)</span>锛屼娇寰楀舰鎴愮殑鏂版暟缁勬渶澶у瓙娈靛拰鏈€澶с€�</p><h1 id="棰樿в">棰樿В</h1><p><span class="math inline">\(~~~~\)</span>鑰冭檻 DP銆�</p><p><span class="math inline">\(~~~~\)</span>璁� <spanclass="math inline">\(f[i][j]\)</span> : 鑰冭檻鍓� <spanclass="math inline">\(i\)</span> 涓暟锛屽凡缁忛€夋嫨浜� <spanclass="math inline">\(j\)</span> 涓暟鎵ц "<spanclass="math inline">\(+x\)</span>" 鎿嶄綔鐨勫ぇ瀛愭鍜屻€�</p><p><span class="math inline">\(~~~~\)</span>鍒嗙被璁ㄨ锛�</p><ul><li><span class="math inline">\(a[i]\)</span> 涓嶆墽琛� "<spanclass="math inline">\(+x\)</span>" 鎿嶄綔<ul><li>蹇呴』婊¤冻 <span class="math inline">\(i &gt;j\)</span>锛屽洜涓哄鏋� <span class="math inline">\(i=j\)</span>鍒欐剰鍛崇潃鍓� <span class="math inline">\(i\)</span>涓暟鍏ㄩ儴鎵ц浜� "<span class="math inline">\(+x\)</span>"鎿嶄綔锛屽洜姝� <span class="math inline">\(a[i]\)</span> 蹇呴』鎵ц"<span class="math inline">\(+x\)</span>" 鎿嶄綔<br /></li><li><span class="math inline">\(a[i]\)</span> 蹇呴』鎵ц "<spanclass="math inline">\(-x\)</span>" 鎿嶄綔</li><li><span class="math inline">\(a[i]\)</span>鍗曠嫭浣滀负涓€涓瓙娈靛拰锛屽嵆 <span class="math inline">\(a[i] -x\)</span></li><li><span class="math inline">\(a[i]\)</span> 鍚堝苟鍒� <spanclass="math inline">\([1, i-1]\)</span> 鐨勬渶澶у瓙娈靛拰涓紝鍗� <spanclass="math inline">\(f[i-1, j] + a[i] - x\)</span></li></ul></li><li><span class="math inline">\(a[i]\)</span> 鎵ц "<spanclass="math inline">\(+x\)</span>" 鎿嶄綔<ul><li><span class="math inline">\(a[i]\)</span>鍗曠嫭浣滀负涓€涓瓙娈靛拰锛屽嵆 <span class="math inline">\(a[i] +x\)</span></li><li><span class="math inline">\(a[i]\)</span> 鍚堝苟鍒� <spanclass="math inline">\([1, i-1]\)</span> 鐨勬渶澶у瓙娈靛拰涓紝鍗� <spanclass="math inline">\(f[i-1, j-1] + a[i] + x\)</span></li></ul></li></ul><p><spanclass="math inline">\(~~~~\)</span>鍥犳锛岀姸鎬佽浆绉绘柟绋嬩负锛�<span class="math display">\[f[i,j]=\left\{\begin{matrix}max(a[i]-x,f[i-1,j]+a[i]-x)\ \ j&lt;i\\max(a[i]+x, f[i-1, j-1]+a[i]+x)\ \ j &gt; 0\end{matrix}\right.\]</span></p><p><span class="math inline">\(~~~~\)</span>鍒濆鏉′欢涓猴細<spanclass="math inline">\(f[0, 0] = 0\)</span></p><h1 id="python-浠ｇ爜">python 浠ｇ爜</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n, k, x = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    inf = <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)<br>    f = [[-inf <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(k+<span class="hljs-number">1</span>)] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>    res = <span class="hljs-number">0</span><br>    f[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n+<span class="hljs-number">1</span>):<br>        <span class="hljs-comment"># 褰撳墠宸茬粡浣跨敤鐨� &quot;+x&quot; 鎿嶄綔 j 鏈€灏戜负 k-(n-i)锛屽嵆璁� i 鍚庨潰鐨勬暟鍏ㄩ儴鎵ц &quot;+x&quot; 鎿嶄綔</span><br>        <span class="hljs-comment"># 褰撳墠宸茬粡浣跨敤鐨� &quot;+x&quot; 鎿嶄綔 j 鏈€澶氫负 i锛屽嵆璁� i 鍓嶉潰鐨勬暟鍏ㄩ儴鎵ц &quot;+x&quot; 鎿嶄綔</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, k-(n-i)), <span class="hljs-built_in">min</span>(i, k)+<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> j &lt; i:<br>                f[i][j] = <span class="hljs-built_in">max</span>(a[i-<span class="hljs-number">1</span>] - x, f[i-<span class="hljs-number">1</span>][j] + a[i-<span class="hljs-number">1</span>] - x)<br>            <span class="hljs-keyword">if</span> j:<br>                <span class="hljs-comment"># 娉ㄦ剰姝ゅ f[i][j] 鍙兘宸茬粡琚洿鏂帮紝鍥犳瑕佸甫涓�</span><br>                f[i][j] = <span class="hljs-built_in">max</span>(f[i][j], <span class="hljs-built_in">max</span>(a[i-<span class="hljs-number">1</span>] + x, f[i-<span class="hljs-number">1</span>][j-<span class="hljs-number">1</span>] + a[i-<span class="hljs-number">1</span>] + x))<br>            <span class="hljs-comment"># 鑻ュ彧鑰冭檻褰撳墠鐨勬渶澶у瓙娈靛拰锛屽叾浠栫殑 &quot;+x&quot; 鎿嶄綔鍙戠敓鍦ㄤ粈涔堝湴鏂瑰褰撳墠缁撴灉娌℃湁褰卞搷</span><br>            res = <span class="hljs-built_in">max</span>(res, f[i][j])<br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, cf, D, Maximum Subarray, dp, DP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Codeforces Round 856 (Div. 2) a - D</title>
    <link href="/2023/03/11/cf_1794/"/>
    <url>/2023/03/11/cf_1794/</url>
    
    <content type="html"><![CDATA[<p>A (ćçť´) B (ćçť´) C (ćçť´) D (dp)</p><span id="more"></span><h1 id="éžćľ">éžćĽ</h1><p>https://codeforces.com/contest/1794</p><h1 id="a-ćçť">A (ćçť´)</h1><h2 id="éć">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťĺşä¸ä¸Şĺ­çŹŚä¸˛ <spanclass="math inline">\(s\)</span> çććĺ­ä¸? <spanclass="math inline">\(s_{sub}\)</span> çéćşćĺďźĺ¤ć­čżä¸Şĺ­çŹŚä¸? <spanclass="math inline">\(s\)</span> ćŻĺŚä¸şĺćä¸˛</p><h2 id="éčł">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>ćžĺşä¸¤ä¸ŞéżĺşŚćéżçĺ­ä¸˛<span class="math inline">\(s_{sub, max_{1}}\)</span>ă?<spanclass="math inline">\(s_{sub, max_{2}}\)</span>ďźĺčŽ? <spanclass="math inline">\(s_{sub, max_{1}}\)</span> ć? <spanclass="math inline">\(s\)</span> çĺçźďź?<spanclass="math inline">\(s_{sub, max_{2}}\)</span>ć? <spanclass="math inline">\(s\)</span> çĺçźďźĺ <span class="math display">\[s = s_{sub, max_{1}}[:] + s_{sub, max_{2}}[-1] \ \ or \  \ s_{sub,max_{1}}[0] + s_{sub, max_{2}}[:]   \]</span></p><p><span class="math inline">\(~~~~\)</span>ćä¸žä¸¤čćĺľĺłĺŻćąĺž? <spanclass="math inline">\(s\)</span>ďźćĺĺ¤ć? <spanclass="math inline">\(s\)</span> ćŻĺŚä¸şĺćä¸˛ĺłĺŻă?</p><h2 id="python-äťłç">python äťŁç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    s = <span class="hljs-built_in">input</span>().split()<br>    <span class="hljs-keyword">if</span> n == <span class="hljs-number">2</span>:<br>        res = s[<span class="hljs-number">0</span>] + s[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">else</span>:<br>        mxs = []<br>        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(c) == n-<span class="hljs-number">1</span>:<br>                mxs.append(c)<br>        <span class="hljs-comment"># print(mxs[0][:n-2], mxs[1][1:])</span><br>        <span class="hljs-keyword">if</span> mxs[<span class="hljs-number">0</span>][:n-<span class="hljs-number">2</span>] == mxs[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>:]:<br>            res = mxs[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>] + mxs[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">else</span>:<br>            res = mxs[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] + mxs[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> res == res[::-<span class="hljs-number">1</span>]:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;YES&#x27;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;NO&#x27;</span>)<br></code></pre></td></tr></table></figure><h1 id="b-ćçť">B (ćçť´)</h1><h2 id="éć-1">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťä¸ä¸Şć°çť? <spanclass="math inline">\(a\)</span>ďźćŻä¸ćŹĄćä˝ĺŻäťĽčŽŠ <spanclass="math inline">\(a_{i}=a_{i}+1\)</span>ďźćĺ¤ćä˝? <spanclass="math inline">\(n\)</span> ćŹĄďźčŚćąćĺä˝żĺž? <spanclass="math inline">\(a\)</span> ćťĄčśł <span class="math display">\[\forall i \in [1, n-1], a_{i} \ not\  \mid a_{i+1}\]</span></p><h2 id="éčł-1">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>č´ŞĺżĺłĺŻă?</p><p><span class="math inline">\(~~~~\)</span>äťĺĺžĺéĺďźĺŞčŚ <spanclass="math inline">\(a_{i-1} \mid a_{i}\)</span>ďźĺ ä¸? <spanclass="math inline">\(a_{i-1}+1\)</span> ĺŻč˝ć? <spanclass="math inline">\(a_{i}\)</span> çĺ ĺ­ďźč? <spanclass="math inline">\(a_{i-1}\)</span> ä¸ĺŻč˝ćŻ <spanclass="math inline">\(a_{i}+1\)</span> çĺ ĺ­ďźĺ ć­¤ĺ°ąčŽŠ <spanclass="math inline">\(a_{i} += 1\)</span>ă?</p><p><span class="math inline">\(~~~~\)</span>ćł¨ćďźĺ˝ <spanclass="math inline">\(a_{i-1}=1\)</span> ćśďźćć <spanclass="math inline">\(a_{i-1} | (a_{i}+1)\)</span>ďźĺ ć­¤ĺŚć? <spanclass="math inline">\(\exists k \in [1, n], a_{k}=1\)</span>ďźĺä˝? <spanclass="math inline">\(a_{k} += 1\)</span>ă?</p><h2 id="python-äťłç-1">python äťŁç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    <span class="hljs-keyword">if</span> <span class="hljs-number">1</span> <span class="hljs-keyword">in</span> a:<br>        a = [_ + <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> a]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>        <span class="hljs-keyword">if</span> a[i] % a[i-<span class="hljs-number">1</span>] == <span class="hljs-number">0</span>:<br>            a[i] += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> a:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % x, end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h1 id="c-ćçť">C (ćçť´)</h1><h2 id="éć-2">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťä¸ä¸Şĺč°éĺć°çť? <spanclass="math inline">\(a\)</span>ďź?<span class="math inline">\(\forall i\in [1, n]\)</span>ďźĺ¨ <span class="math inline">\(a_{j}, j \in [1,i]\)</span> ä¸­éĺşä¸ä¸Şĺ­ĺşĺ <span class="math inline">\(s_{1}, s_{2},..., s_{d}\)</span>ďźčŚä˝? $maxsocre_{i} = $ďźčžĺ? <spanclass="math inline">\(score_{i}\)</span>ă?</p><h2 id="éčł-2">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>ćł¨ćĺ°ďź<spanclass="math inline">\(a\)</span> ćŻä¸ä¸Şĺč°éĺçĺşĺďźä¸ĺŻšäş <spanclass="math inline">\(score =\frac{s_{1}*s_{2}*...*s_{d}}{d!}\)</span>ďźĺŚććłčŚĺ ĺĽä¸ä¸Şć° <spanclass="math inline">\(s_{d+1}\)</span>ďźĺ <spanclass="math inline">\(socre *= \frac{s_{d+1}}{d+1}\)</span>ă?</p><p><span class="math inline">\(~~~~\)</span>ĺ ć­¤ĺŻšäşćä¸ä¸Şĺçź <spanclass="math inline">\(a_{j}, j \in [1, i]\)</span>ďźćäťŹĺŻäťĽčżć ˇčŽŠ<span class="math inline">\(score\)</span> ćĺ¤§ĺďź?</p><ul><li><span class="math inline">\(score = a_{j}\)</span></li><li><span class="math inline">\(if a_{j-1}/2 &gt; 1ďźĺscore =\frac{a_{j} * a_{j-1}}{2}\)</span></li><li>äžćŹĄçąťć¨</li></ul><p><spanclass="math inline">\(~~~~\)</span>ĺ ć­¤ďźćäťŹĺŻäťĽäťĺĺžĺćŤďźç¨ä¸ä¸ŞéĺćĽçť´ć¤<span class="math inline">\(score\)</span>çćĺ¤§ĺźďźćŻćŹĄĺŞéčŚĺ¤ć­éĺĺé˘çćŻĺŚéčŚĺ é¤ĺłĺŻă?</p><h2 id="python-äťłç-2">python äťŁç </h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">T = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br><span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(T):<br>    n = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>    a = [<span class="hljs-built_in">int</span>(_) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>().split()]<br>    res, l, r = <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span><br>    que = [<span class="hljs-number">0</span> <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n+<span class="hljs-number">1</span>)]<br>    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> a:<br>        r += <span class="hljs-number">1</span><br>        que[r] = x<br>        res += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> que[l] &lt; res <span class="hljs-keyword">and</span> l &lt; r:<br>            l += <span class="hljs-number">1</span><br>            res -= <span class="hljs-number">1</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;%d &#x27;</span> % res, end=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <span class="hljs-built_in">print</span>()<br></code></pre></td></tr></table></figure><h1 id="d-dp">D (dp)</h1><h2 id="éć-3">é˘ć</h2><p><span class="math inline">\(~~~~\)</span>çťĺşä¸ä¸ŞéżĺşŚä¸ş <spanclass="math inline">\(2n\)</span> çć°çť? <spanclass="math inline">\(a\)</span>ďź?<spanclass="math inline">\(a\)</span> çćä¸ä¸ŞćĺćŻćä¸ä¸Şć°çč´¨ĺ ć°ĺč§Łďźĺł<span class="math display">\[f(m) = \{p_{1}, e_{1}, p_{2}, e_{2}, ..., p_{k}, e_{k}\}\]</span></p><p><span class="math inline">\(~~~~\)</span>ćąćĺ¤ĺ°ä¸Şčżć ˇçć°ďźć¨?<span class="math inline">\(998244353\)</span>ă?</p><h2 id="éčł-3">é˘č§Ł</h2><p><span class="math inline">\(~~~~\)</span>éŚĺččçšćŽćĺľďźĺ˝ <spanclass="math inline">\(a\)</span> ä¸­çç´ ć°ć°é <spanclass="math inline">\(&lt;n\)</span> ćśďźç­ćĄćžçśä¸? <spanclass="math inline">\(0\)</span>ă?</p><p><span class="math inline">\(~~~~\)</span>ćł¨ćĺ°ďźĺ˝éĺŽ <spanclass="math inline">\(n\)</span> ä¸Şć°ä¸şĺşć°ćśďźĺŠä¸ç <spanclass="math inline">\(n\)</span> ä¸Şć°ĺĺ¨ćĺăčŽž <spanclass="math inline">\(a\)</span> ĺťéĺä¸ş <spanclass="math inline">\(b\)</span>ďźçąĺ¤ééĺ¨ćĺçčŽşĺŻçĽďźĺ¨ćĺć°ä¸ş <spanclass="math display">\[\frac{n!}{cnt_{b_{1}}! * cnt_{b_{2}}! * .. cnt_{b_{m}}!}  \]</span></p><p><span class="math inline">\(~~~~\)</span>ĺśä¸­ <spanclass="math inline">\(cnt_{b_{k}}\)</span> ć? <spanclass="math inline">\(b_{k}\)</span> çć°éă?</p><p><span class="math inline">\(~~~~\)</span>ĺ˝? <spanclass="math inline">\(b_{k}\)</span>ä¸şéç´ ć°ćśďźč´ĄçŽćŻĺşĺŽçďźĺ ä¸şĺŽäťŹé˝ä¸č˝ä˝ä¸şĺşć°ăčĺ˝ <spanclass="math inline">\(b_{k}\)</span>ä¸şç´ ć°ćśďźč´ĄçŽćŻä¸ĺşĺŽçďźĺ ä¸şĺ˝ĺŽäťŹä˝ä¸şĺşć°ćśďźč´ĄçŽä¸? <spanclass="math inline">\(\frac{1}{(cnt_{b_{k}}-1)!}\)</span>ďźččżä¸Şé¨ĺĺŻäťĽç¨<span class="math inline">\(dp\)</span> ćĽćąă?</p><p><span class="math inline">\(~~~~\)</span>čŽ? <spanclass="math inline">\(f_{i, j}\)</span> ä¸şĺ¤çĺ°çŹ? <spanclass="math inline">\(i\)</span> ç§ć°ďźäťĽ <spanclass="math inline">\(j\)</span> ä¸Şć°ä˝ä¸şĺşć°ćśçč´ĄçŽăččĺŚä˝äť? <spanclass="math inline">\(f_{i-1}\)</span> č˝Źç§ťďź?</p><ul><li>ĺ˝çŹŹ <span class="math inline">\(i\)</span> ç§ć°ä¸ä˝ä¸şĺşć°ćśďźĺ$f_{i,j} = $ďźĺ ä¸şĺĺçĺşć°ć°é <span class="math inline">\(j\)</span>ćŻä¸ć ˇç</li><li>ĺ˝çŹŹ <span class="math inline">\(i\)</span> ç§ć°ä˝ä¸şĺşć°ćśďźĺ?<span class="math inline">\(f_{i,j} =\frac{f_{i-1,j-1}}{(cnt_{b_{i}}-1)!}\)</span>ďźĺ ä¸şĺ˝ĺćŻä¸ä¸ćŹĄĺ¤ä¸ä¸Şĺşć?<br /><span class="math inline">\(f_{m, n}\)</span> ĺłä¸şç´ ć°çč´ĄçŽďźĺśä¸­<span class="math inline">\(m\)</span> ćŻć°çç§çąťă?</li></ul><p><span class="math inline">\(~~~~\)</span>ćĺďźčŽ? <spanclass="math inline">\(b\)</span> ä¸­çéç´ ć°é¨ĺä¸ş <spanclass="math inline">\(c\)</span>ďźĺ <span class="math display">\[res =\frac{n}{cnt_{c_{1}}! * cnt_{c_{2}}! *...} * f_{m, n}\]</span></p><h2 id="c-äťłç">c++ äťŁç </h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> int long long</span><br><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-type">const</span> <span class="hljs-type">int</span> mod = <span class="hljs-number">998244353</span>;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">qmi</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br>    <span class="hljs-type">int</span> res = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">while</span>(b) &#123;<br>        <span class="hljs-keyword">if</span>(b &amp; <span class="hljs-number">1</span>) res = res * a % mod;<br>        a = a * a % mod;<br>        b &gt;&gt;= <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> res;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-type">signed</span> <span class="hljs-title">main</span><span class="hljs-params">()</span> </span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-type">int</span> n;<br>    <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>, &amp;n);<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">a</span><span class="hljs-params">(<span class="hljs-number">2</span> * n)</span></span>;<br>    <span class="hljs-type">int</span> mx = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span> * n; i++) &#123;<br>        <span class="hljs-built_in">scanf</span>(<span class="hljs-string">&quot;%lld&quot;</span>, &amp;a[i]);<br>        mx = <span class="hljs-built_in">max</span>(mx, a[i]);<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">primes</span><span class="hljs-params">(mx + <span class="hljs-number">1</span>)</span>, <span class="hljs-title">not_prime</span><span class="hljs-params">(mx + <span class="hljs-number">1</span>)</span></span>;<br>    not_prime[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-type">int</span> cnt_primes = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= mx; i++) &#123;<br>        <span class="hljs-keyword">if</span>(!not_prime[i]) primes[++cnt_primes] = i;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= cnt_primes <span class="hljs-keyword">and</span> i * primes[j] &lt;= mx; j++) &#123;<br>            not_prime[i * primes[j]] = <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">if</span>(i % primes[j] == <span class="hljs-number">0</span>) <span class="hljs-keyword">break</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">fac</span><span class="hljs-params">(n + <span class="hljs-number">1</span>)</span>, <span class="hljs-title">inv</span><span class="hljs-params">(n + <span class="hljs-number">1</span>)</span></span>;<br>    fac[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= n; i++) fac[i] = fac[i - <span class="hljs-number">1</span>] * i % mod;<br>    inv[<span class="hljs-number">0</span>] = inv[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt;= n; i++) inv[i] = <span class="hljs-built_in">qmi</span>(fac[i], mod - <span class="hljs-number">2</span>);<br>    vector&lt;<span class="hljs-type">int</span>&gt; p, np;<br>    map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; cnt;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">2</span> * n; i++) &#123;<br>        cnt[a[i]]++;<br>        <span class="hljs-keyword">if</span>(cnt[a[i]] == <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">if</span>(not_prime[a[i]]) np.<span class="hljs-built_in">push_back</span>(a[i]);<br>            <span class="hljs-keyword">else</span> p.<span class="hljs-built_in">push_back</span>(a[i]);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(p.<span class="hljs-built_in">size</span>() &lt; n) &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;0\n&quot;</span>);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>    <span class="hljs-type">int</span> res = fac[n];<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; np.<span class="hljs-built_in">size</span>(); i++) &#123;<br>        res = (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)res * inv[cnt[np[i]]] % mod;<br>    &#125;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">f</span>(p.<span class="hljs-built_in">size</span>() + <span class="hljs-number">1</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(n + <span class="hljs-number">1</span>));<br>    f[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= p.<span class="hljs-built_in">size</span>(); i++) &#123;<br>        f[i][<span class="hljs-number">0</span>] = (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)f[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] * inv[cnt[p[i - <span class="hljs-number">1</span>]]] % mod;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= n &amp;&amp; j &lt;= i; j++) &#123;<br>            f[i][j] = ((<span class="hljs-type">long</span> <span class="hljs-type">long</span>)f[i - <span class="hljs-number">1</span>][j] * inv[cnt[p[i - <span class="hljs-number">1</span>]]] % mod + (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)f[i - <span class="hljs-number">1</span>][j - <span class="hljs-number">1</span>] * inv[cnt[p[i - <span class="hljs-number">1</span>]] - <span class="hljs-number">1</span>] % mod) % mod;<br>        &#125;<br>    &#125;<br>    res = (<span class="hljs-type">long</span> <span class="hljs-type">long</span>)res * f[p.<span class="hljs-built_in">size</span>()][n] % mod;<br> <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%lld\n&quot;</span>, res);<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;  <br><br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>题解</category>
      
      <category>CodeForce</category>
      
    </categories>
    
    
    <tags>
      
      <tag>codeforce, Codeforces Round 856 (Div. 2) A - D</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用 Hexo 配置博客</title>
    <link href="/2023/03/09/%E4%BD%BF%E7%94%A8hexo%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2/"/>
    <url>/2023/03/09/%E4%BD%BF%E7%94%A8hexo%E9%85%8D%E7%BD%AE%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="安装-hexo">安装 hexo</h1><p><code>npm install -g hexo-cli</code></p><h1 id="配置环境变量">配置环境变量</h1><p>查看默认安装路径 <code>npm config ls</code>，找到<code>hexo-cli/bin</code>文件夹，将其添加到环境变量中</p><h1 id="创建新文件夹">创建新文件夹</h1><p><code>mkdir blog</code></p><h1 id="生成初始化文件">生成初始化文件</h1><p><code>hexo init</code></p><h1 id="下载部署插件">下载部署插件</h1><p><code>npm install hexo-deployer-git --save</code></p><h1 id="生成">生成</h1><p><code>hexo g</code></p><h1 id="本地部署">本地部署</h1><p><code>hexo s</code></p><h1 id="服务器部署">服务器部署</h1><p><code>hexo d</code></p>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo, blog</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
